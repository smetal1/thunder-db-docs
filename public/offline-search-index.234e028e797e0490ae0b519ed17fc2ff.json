[{"body":"API Reference ThunderDB exposes four API surfaces beyond its wire-protocol endpoints. This page documents every route, method, and message type with working examples.\nAPI Transport Default Port Authentication REST HTTP/1.1 + HTTP/2 8088 Bearer token, Basic Auth, mTLS gRPC HTTP/2 (Protobuf) 9090 Bearer token metadata, mTLS GraphQL HTTP (JSON) 8088 (/graphql) Bearer token, Basic Auth WebSocket WS / WSS 8088 (/ws/*) Token query param or first message All examples below assume ThunderDB is running on localhost with default ports and authentication disabled for brevity. In production, add the appropriate Authorization header or TLS configuration.\nREST API (port 8088) Base URL: http://localhost:8088\nHealth \u0026 Operations Endpoints GET /admin/health Returns overall cluster health status.\ncurl -s http://localhost:8088/admin/health | jq . Response (200 OK):\n{ \"status\": \"healthy\", \"version\": \"0.9.0\", \"cluster_id\": \"thunder-prod-01\", \"uptime_seconds\": 86421, \"node_count\": 5, \"region_count\": 3 } GET /admin/live Kubernetes-style liveness probe. Returns 200 if the process is running.\ncurl -s -o /dev/null -w \"%{http_code}\" http://localhost:8088/admin/live Response (200 OK):\n{ \"alive\": true } GET /admin/ready Kubernetes-style readiness probe. Returns 200 only when the node can accept queries (Raft leader elected, storage initialized).\ncurl -s http://localhost:8088/admin/ready | jq . Response (200 OK):\n{ \"ready\": true, \"raft_state\": \"leader\", \"storage_ready\": true, \"last_applied_index\": 148230 } Response (503 Service Unavailable):\n{ \"ready\": false, \"raft_state\": \"follower\", \"storage_ready\": true, \"reason\": \"No leader elected yet\" } GET /admin/metrics Returns Prometheus-format metrics for scraping.\ncurl -s http://localhost:8088/admin/metrics Response (200 OK — text/plain):\n# HELP thunderdb_queries_total Total number of queries executed # TYPE thunderdb_queries_total counter thunderdb_queries_total{type=\"select\"} 234892 thunderdb_queries_total{type=\"insert\"} 89210 thunderdb_queries_total{type=\"update\"} 12034 thunderdb_queries_total{type=\"delete\"} 4501 # HELP thunderdb_query_duration_seconds Query execution duration histogram # TYPE thunderdb_query_duration_seconds histogram thunderdb_query_duration_seconds_bucket{le=\"0.001\"} 180432 thunderdb_query_duration_seconds_bucket{le=\"0.01\"} 220100 thunderdb_query_duration_seconds_bucket{le=\"0.1\"} 234000 thunderdb_query_duration_seconds_bucket{le=\"1.0\"} 234800 thunderdb_query_duration_seconds_bucket{le=\"+Inf\"} 234892 # HELP thunderdb_active_connections Number of active client connections # TYPE thunderdb_active_connections gauge thunderdb_active_connections{protocol=\"postgresql\"} 42 thunderdb_active_connections{protocol=\"mysql\"} 18 thunderdb_active_connections{protocol=\"redis\"} 105 thunderdb_active_connections{protocol=\"http\"} 23 Query Endpoints POST /api/v1/query Execute a SQL statement and return results as JSON.\ncurl -s http://localhost:8088/api/v1/query \\ -H \"Content-Type: application/json\" \\ -d '{ \"sql\": \"SELECT id, name, email FROM users WHERE active = true LIMIT 5\" }' | jq . Request Body:\nField Type Required Description sql string Yes SQL statement to execute params array No Positional bind parameters ($1, $2, …) timeout_ms integer No Query timeout in milliseconds (default: 30000) consistency string No strong (default), eventual, or stale Response (200 OK):\n{ \"columns\": [\"id\", \"name\", \"email\"], \"column_types\": [\"Int64\", \"Varchar\", \"Varchar\"], \"rows\": [ [1, \"Alice Johnson\", \"alice@example.com\"], [2, \"Bob Smith\", \"bob@example.com\"], [3, \"Carol White\", \"carol@example.com\"] ], \"row_count\": 3, \"execution_time_ms\": 2.4 } Example with bind parameters:\ncurl -s http://localhost:8088/api/v1/query \\ -H \"Content-Type: application/json\" \\ -d '{ \"sql\": \"SELECT * FROM orders WHERE customer_id = $1 AND total \u003e $2\", \"params\": [1001, 50.00] }' | jq . POST /api/v1/query-explain Return the query execution plan without running the query.\ncurl -s http://localhost:8088/api/v1/query-explain \\ -H \"Content-Type: application/json\" \\ -d '{ \"sql\": \"SELECT u.name, COUNT(o.id) FROM users u JOIN orders o ON u.id = o.customer_id GROUP BY u.name\", \"analyze\": false, \"verbose\": true }' | jq . Request Body:\nField Type Required Description sql string Yes SQL statement to explain analyze boolean No If true, actually execute and report real timings verbose boolean No If true, include additional planner details format string No Output format: text (default), json, dot Response (200 OK):\n{ \"plan\": { \"node_type\": \"Projection\", \"output\": [\"u.name\", \"COUNT(o.id)\"], \"children\": [ { \"node_type\": \"HashAggregate\", \"group_by\": [\"u.name\"], \"children\": [ { \"node_type\": \"HashJoin\", \"join_type\": \"inner\", \"condition\": \"u.id = o.customer_id\", \"estimated_rows\": 15000, \"children\": [ { \"node_type\": \"SeqScan\", \"table\": \"users\", \"estimated_rows\": 5000 }, { \"node_type\": \"SeqScan\", \"table\": \"orders\", \"estimated_rows\": 50000 } ] } ] } ] }, \"planning_time_ms\": 0.8 } POST /api/v1/prepared Create, execute, or deallocate a prepared statement.\nCreate a prepared statement:\ncurl -s http://localhost:8088/api/v1/prepared \\ -H \"Content-Type: application/json\" \\ -d '{ \"action\": \"create\", \"name\": \"get_user_orders\", \"sql\": \"SELECT * FROM orders WHERE customer_id = $1 AND status = $2\" }' | jq . Response (200 OK):\n{ \"name\": \"get_user_orders\", \"param_types\": [\"Int64\", \"Varchar\"], \"created\": true } Execute a prepared statement:\ncurl -s http://localhost:8088/api/v1/prepared \\ -H \"Content-Type: application/json\" \\ -d '{ \"action\": \"execute\", \"name\": \"get_user_orders\", \"params\": [1001, \"shipped\"] }' | jq . Response (200 OK):\n{ \"columns\": [\"id\", \"customer_id\", \"product_id\", \"quantity\", \"total\", \"status\", \"created_at\"], \"rows\": [ [5012, 1001, 42, 2, 99.98, \"shipped\", \"2025-12-01T14:30:00Z\"] ], \"row_count\": 1, \"execution_time_ms\": 0.9 } Deallocate a prepared statement:\ncurl -s http://localhost:8088/api/v1/prepared \\ -H \"Content-Type: application/json\" \\ -d '{ \"action\": \"deallocate\", \"name\": \"get_user_orders\" }' | jq . Response (200 OK):\n{ \"name\": \"get_user_orders\", \"deallocated\": true } Transaction Endpoints POST /api/v1/transactions Begin a new transaction and receive a transaction ID.\ncurl -s http://localhost:8088/api/v1/transactions \\ -H \"Content-Type: application/json\" \\ -d '{ \"isolation_level\": \"serializable\", \"read_only\": false, \"timeout_ms\": 60000 }' | jq . Request Body:\nField Type Required Description isolation_level string No read_committed (default), repeatable_read, serializable read_only boolean No If true, the transaction only permits reads timeout_ms integer No Auto-rollback timeout (default: 60000) Response (200 OK):\n{ \"txn_id\": \"txn_a1b2c3d4e5f6\", \"isolation_level\": \"serializable\", \"read_only\": false, \"started_at\": \"2025-12-15T10:30:00.123Z\" } Execute within a transaction:\ncurl -s http://localhost:8088/api/v1/query \\ -H \"Content-Type: application/json\" \\ -H \"X-Thunder-Txn-Id: txn_a1b2c3d4e5f6\" \\ -d '{ \"sql\": \"UPDATE accounts SET balance = balance - 100 WHERE id = 1\" }' | jq . curl -s http://localhost:8088/api/v1/query \\ -H \"Content-Type: application/json\" \\ -H \"X-Thunder-Txn-Id: txn_a1b2c3d4e5f6\" \\ -d '{ \"sql\": \"UPDATE accounts SET balance = balance + 100 WHERE id = 2\" }' | jq . POST /api/v1/transactions/{txn_id}/commit Commit a transaction.\ncurl -s -X POST http://localhost:8088/api/v1/transactions/txn_a1b2c3d4e5f6/commit | jq . Response (200 OK):\n{ \"txn_id\": \"txn_a1b2c3d4e5f6\", \"status\": \"committed\", \"committed_at\": \"2025-12-15T10:30:01.456Z\", \"rows_affected\": 2 } POST /api/v1/transactions/{txn_id}/rollback Roll back a transaction.\ncurl -s -X POST http://localhost:8088/api/v1/transactions/txn_a1b2c3d4e5f6/rollback | jq . Response (200 OK):\n{ \"txn_id\": \"txn_a1b2c3d4e5f6\", \"status\": \"rolled_back\", \"rolled_back_at\": \"2025-12-15T10:30:01.789Z\" } Table Management Endpoints GET /api/v1/tables List all tables in the current database.\ncurl -s http://localhost:8088/api/v1/tables | jq . Query Parameters:\nParam Type Description schema string Filter by schema name (default: public) include_system boolean Include internal system tables Response (200 OK):\n{ \"tables\": [ { \"name\": \"users\", \"schema\": \"public\", \"engine\": \"row\", \"row_count\": 5200, \"size_bytes\": 1048576, \"created_at\": \"2025-11-01T00:00:00Z\" }, { \"name\": \"orders\", \"schema\": \"public\", \"engine\": \"row\", \"row_count\": 52000, \"size_bytes\": 15728640, \"created_at\": \"2025-11-01T00:00:00Z\" }, { \"name\": \"analytics_events\", \"schema\": \"public\", \"engine\": \"columnar\", \"row_count\": 12000000, \"size_bytes\": 536870912, \"created_at\": \"2025-11-05T00:00:00Z\" } ] } GET /api/v1/tables/{table} Get detailed schema information for a specific table.\ncurl -s http://localhost:8088/api/v1/tables/users | jq . Response (200 OK):\n{ \"name\": \"users\", \"schema\": \"public\", \"engine\": \"row\", \"columns\": [ {\"name\": \"id\", \"type\": \"Int64\", \"nullable\": false, \"primary_key\": true, \"default\": \"nextval('users_id_seq')\"}, {\"name\": \"name\", \"type\": \"Varchar(255)\", \"nullable\": false, \"primary_key\": false, \"default\": null}, {\"name\": \"email\", \"type\": \"Varchar(255)\", \"nullable\": false, \"primary_key\": false, \"default\": null}, {\"name\": \"active\", \"type\": \"Boolean\", \"nullable\": false, \"primary_key\": false, \"default\": \"true\"}, {\"name\": \"created_at\", \"type\": \"TimestampTz\", \"nullable\": false, \"primary_key\": false, \"default\": \"now()\"} ], \"indexes\": [ {\"name\": \"users_pkey\", \"columns\": [\"id\"], \"type\": \"btree\", \"unique\": true}, {\"name\": \"users_email_idx\", \"columns\": [\"email\"], \"type\": \"btree\", \"unique\": true} ], \"row_count\": 5200, \"size_bytes\": 1048576, \"created_at\": \"2025-11-01T00:00:00Z\", \"last_modified_at\": \"2025-12-15T10:00:00Z\" } POST /api/v1/tables Create a new table.\ncurl -s http://localhost:8088/api/v1/tables \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"products\", \"schema\": \"public\", \"engine\": \"row\", \"columns\": [ {\"name\": \"id\", \"type\": \"Int64\", \"primary_key\": true}, {\"name\": \"name\", \"type\": \"Varchar(255)\", \"nullable\": false}, {\"name\": \"description\", \"type\": \"Text\", \"nullable\": true}, {\"name\": \"price\", \"type\": \"Decimal(10,2)\", \"nullable\": false}, {\"name\": \"category\", \"type\": \"Varchar(100)\", \"nullable\": true}, {\"name\": \"embedding\", \"type\": \"Vector(768)\", \"nullable\": true}, {\"name\": \"created_at\", \"type\": \"TimestampTz\", \"default\": \"now()\"} ], \"if_not_exists\": true }' | jq . Response (201 Created):\n{ \"name\": \"products\", \"schema\": \"public\", \"created\": true, \"message\": \"Table 'public.products' created successfully\" } DELETE /api/v1/tables/{table} Drop a table.\ncurl -s -X DELETE \"http://localhost:8088/api/v1/tables/products?if_exists=true\u0026cascade=false\" | jq . Query Parameters:\nParam Type Description if_exists boolean Suppress error if table does not exist cascade boolean Drop dependent objects (indexes, foreign keys) Response (200 OK):\n{ \"name\": \"products\", \"dropped\": true, \"message\": \"Table 'public.products' dropped successfully\" } Index Endpoints GET /api/v1/indexes List all indexes, optionally filtered by table.\ncurl -s \"http://localhost:8088/api/v1/indexes?table=users\" | jq . Response (200 OK):\n{ \"indexes\": [ { \"name\": \"users_pkey\", \"table\": \"users\", \"columns\": [\"id\"], \"type\": \"btree\", \"unique\": true, \"size_bytes\": 131072 }, { \"name\": \"users_email_idx\", \"table\": \"users\", \"columns\": [\"email\"], \"type\": \"btree\", \"unique\": true, \"size_bytes\": 262144 } ] } POST /api/v1/indexes Create a new index.\ncurl -s http://localhost:8088/api/v1/indexes \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"products_embedding_idx\", \"table\": \"products\", \"columns\": [\"embedding\"], \"type\": \"hnsw\", \"options\": { \"m\": 16, \"ef_construction\": 200, \"distance_metric\": \"cosine\" }, \"if_not_exists\": true }' | jq . Supported Index Types:\nType Use Case Options btree General-purpose ordered index fillfactor hash Equality lookups only fillfactor hnsw Vector ANN search m, ef_construction, distance_metric ivf_pq Large-scale vector search nlist, nprobe, m_pq, distance_metric gin Full-text search, JSONB fastupdate brin Large ordered datasets pages_per_range Response (201 Created):\n{ \"name\": \"products_embedding_idx\", \"table\": \"products\", \"type\": \"hnsw\", \"created\": true, \"build_time_ms\": 4521 } DELETE /api/v1/indexes/{index_name} Drop an index.\ncurl -s -X DELETE \"http://localhost:8088/api/v1/indexes/products_embedding_idx?if_exists=true\" | jq . Response (200 OK):\n{ \"name\": \"products_embedding_idx\", \"dropped\": true } Vector Search Endpoint POST /api/v1/vector-search Perform an approximate nearest-neighbor search on a vector column.\ncurl -s http://localhost:8088/api/v1/vector-search \\ -H \"Content-Type: application/json\" \\ -d '{ \"table\": \"documents\", \"vector_column\": \"embedding\", \"query_vector\": [0.1, -0.23, 0.98, 0.45, 0.67], \"top_k\": 10, \"distance_metric\": \"cosine\", \"ef_search\": 100, \"filter\": \"category = '\\''science'\\'' AND published = true\", \"select_columns\": [\"id\", \"title\", \"category\"] }' | jq . Request Body:\nField Type Required Description table string Yes Table containing the vector column vector_column string Yes Name of the VECTOR column query_vector array[float] Yes Query embedding top_k integer No Number of results (default: 10) distance_metric string No cosine (default), l2, inner_product ef_search integer No HNSW search beam width (default: 64) nprobe integer No IVF-PQ number of clusters to probe (default: 10) filter string No SQL WHERE clause for pre-filtering select_columns array[string] No Columns to return (default: all) Response (200 OK):\n{ \"results\": [ {\"id\": 42, \"title\": \"Quantum Computing Basics\", \"category\": \"science\", \"distance\": 0.0312}, {\"id\": 87, \"title\": \"Introduction to Particle Physics\", \"category\": \"science\", \"distance\": 0.0587}, {\"id\": 15, \"title\": \"The Standard Model Explained\", \"category\": \"science\", \"distance\": 0.0823}, {\"id\": 103, \"title\": \"Cosmology for Beginners\", \"category\": \"science\", \"distance\": 0.0991}, {\"id\": 56, \"title\": \"String Theory Overview\", \"category\": \"science\", \"distance\": 0.1102} ], \"count\": 5, \"distance_metric\": \"cosine\", \"execution_time_ms\": 3.2 } Cluster Management Endpoints GET /api/v1/cluster/nodes List all nodes in the cluster.\ncurl -s http://localhost:8088/api/v1/cluster/nodes | jq . Response (200 OK):\n{ \"nodes\": [ { \"id\": \"node-1\", \"address\": \"10.0.1.10:5432\", \"role\": \"leader\", \"region\": \"us-east-1\", \"status\": \"healthy\", \"raft_term\": 42, \"last_heartbeat\": \"2025-12-15T10:30:00Z\", \"storage_used_bytes\": 2147483648, \"storage_total_bytes\": 107374182400 }, { \"id\": \"node-2\", \"address\": \"10.0.1.11:5432\", \"role\": \"follower\", \"region\": \"us-east-1\", \"status\": \"healthy\", \"raft_term\": 42, \"last_heartbeat\": \"2025-12-15T10:30:00Z\", \"storage_used_bytes\": 2147483648, \"storage_total_bytes\": 107374182400 }, { \"id\": \"node-3\", \"address\": \"10.0.2.10:5432\", \"role\": \"follower\", \"region\": \"us-west-2\", \"status\": \"healthy\", \"raft_term\": 42, \"last_heartbeat\": \"2025-12-15T10:29:59Z\", \"storage_used_bytes\": 1073741824, \"storage_total_bytes\": 107374182400 } ] } GET /api/v1/cluster/regions List configured regions and their properties.\ncurl -s http://localhost:8088/api/v1/cluster/regions | jq . Response (200 OK):\n{ \"regions\": [ { \"name\": \"us-east-1\", \"node_count\": 2, \"leader_count\": 1, \"total_storage_bytes\": 214748364800, \"used_storage_bytes\": 4294967296, \"status\": \"healthy\" }, { \"name\": \"us-west-2\", \"node_count\": 1, \"leader_count\": 0, \"total_storage_bytes\": 107374182400, \"used_storage_bytes\": 1073741824, \"status\": \"healthy\" } ] } POST /api/v1/cluster/rebalance Trigger a manual shard rebalance across the cluster.\ncurl -s -X POST http://localhost:8088/api/v1/cluster/rebalance \\ -H \"Content-Type: application/json\" \\ -d '{ \"strategy\": \"even_distribution\", \"max_concurrent_moves\": 4, \"dry_run\": true }' | jq . Request Body:\nField Type Required Description strategy string No even_distribution (default), minimize_moves, region_aware max_concurrent_moves integer No Max simultaneous shard transfers (default: 2) dry_run boolean No If true, return plan without executing Response (200 OK):\n{ \"dry_run\": true, \"moves\": [ { \"shard\": \"shard-007\", \"from_node\": \"node-1\", \"to_node\": \"node-3\", \"estimated_size_bytes\": 536870912, \"estimated_duration_seconds\": 120 } ], \"total_moves\": 1, \"estimated_total_duration_seconds\": 120 } CDC (Change Data Capture) Subscription Endpoints GET /api/v1/subscriptions List all active CDC subscriptions.\ncurl -s http://localhost:8088/api/v1/subscriptions | jq . Response (200 OK):\n{ \"subscriptions\": [ { \"id\": \"sub_abc123\", \"name\": \"orders_to_warehouse\", \"table\": \"orders\", \"events\": [\"insert\", \"update\"], \"delivery\": \"webhook\", \"endpoint\": \"https://warehouse.internal/api/order-events\", \"status\": \"active\", \"created_at\": \"2025-12-01T00:00:00Z\", \"last_delivered_at\": \"2025-12-15T10:29:58Z\", \"delivered_count\": 12840 } ] } POST /api/v1/subscriptions Create a new CDC subscription.\ncurl -s http://localhost:8088/api/v1/subscriptions \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"user_changes_stream\", \"table\": \"users\", \"events\": [\"insert\", \"update\", \"delete\"], \"delivery\": \"webhook\", \"endpoint\": \"https://app.internal/hooks/user-changes\", \"filter\": \"active = true\", \"include_old_values\": true, \"batch_size\": 100, \"batch_timeout_ms\": 5000, \"retry_policy\": { \"max_retries\": 5, \"backoff_ms\": 1000, \"backoff_multiplier\": 2.0 } }' | jq . Request Body:\nField Type Required Description name string Yes Human-readable subscription name table string Yes Table to watch events array[string] Yes Event types: insert, update, delete delivery string Yes webhook, websocket, or grpc_stream endpoint string Conditional URL for webhook delivery filter string No SQL WHERE clause to filter events include_old_values boolean No Include pre-update row values for updates/deletes batch_size integer No Max events per delivery batch (default: 1) batch_timeout_ms integer No Max wait before flushing batch (default: 1000) retry_policy object No Retry configuration for failed deliveries Response (201 Created):\n{ \"id\": \"sub_def456\", \"name\": \"user_changes_stream\", \"table\": \"users\", \"status\": \"active\", \"created_at\": \"2025-12-15T10:30:00Z\" } DELETE /api/v1/subscriptions/{subscription_id} Delete a CDC subscription.\ncurl -s -X DELETE http://localhost:8088/api/v1/subscriptions/sub_def456 | jq . Response (200 OK):\n{ \"id\": \"sub_def456\", \"deleted\": true, \"message\": \"Subscription 'user_changes_stream' deleted successfully\" } Error Responses All REST endpoints return errors in a consistent format:\n{ \"error\": { \"code\": \"INVALID_SQL\", \"message\": \"Syntax error at position 15: unexpected token 'FORM'\", \"detail\": \"Did you mean 'FROM'?\", \"request_id\": \"req_7f8a9b0c\" } } Common HTTP Status Codes:\nCode Meaning 200 Success 201 Resource created 400 Bad request (invalid SQL, missing params) 401 Unauthorized (missing or invalid credentials) 403 Forbidden (insufficient permissions) 404 Resource not found (table, index, subscription) 409 Conflict (table already exists, transaction conflict) 422 Unprocessable entity (valid JSON but semantic error) 429 Rate limited 500 Internal server error 503 Service unavailable (node not ready) gRPC API (port 9090) ThunderDB exposes gRPC services on port 9090 using Protocol Buffers. The proto definitions are available at thunder-proto/src/thunder.proto in the source repository.\nThunderQuery Service service ThunderQuery { // Execute a SQL statement and return results rpc Execute(QueryRequest) returns (QueryResponse); // Return the execution plan for a SQL statement rpc Explain(ExplainRequest) returns (ExplainResponse); // Begin a new transaction rpc BeginTransaction(BeginTransactionRequest) returns (BeginTransactionResponse); // Commit a transaction rpc Commit(CommitRequest) returns (CommitResponse); // Rollback a transaction rpc Rollback(RollbackRequest) returns (RollbackResponse); // Stream query results for large result sets rpc ExecuteStream(QueryRequest) returns (stream QueryRow); } Message Definitions message QueryRequest { string sql = 1; repeated Value params = 2; string txn_id = 3; // Optional: execute within a transaction uint32 timeout_ms = 4; // Optional: query timeout Consistency consistency = 5; // Optional: read consistency level } message QueryResponse { repeated string columns = 1; repeated string column_types = 2; repeated Row rows = 3; uint64 row_count = 4; double execution_time_ms = 5; } message Row { repeated Value values = 1; } message Value { oneof kind { bool bool_value = 1; int64 int_value = 2; double float_value = 3; string string_value = 4; bytes bytes_value = 5; NullValue null_value = 6; VectorValue vector_value = 7; } } message VectorValue { repeated float elements = 1; } enum Consistency { STRONG = 0; EVENTUAL = 1; STALE = 2; } message ExplainRequest { string sql = 1; bool analyze = 2; bool verbose = 3; string format = 4; // \"text\", \"json\", \"dot\" } message ExplainResponse { string plan_text = 1; bytes plan_json = 2; double planning_time_ms = 3; double execution_time_ms = 4; // Only populated when analyze = true } message BeginTransactionRequest { IsolationLevel isolation_level = 1; bool read_only = 2; uint32 timeout_ms = 3; } message BeginTransactionResponse { string txn_id = 1; IsolationLevel isolation_level = 2; google.protobuf.Timestamp started_at = 3; } enum IsolationLevel { READ_COMMITTED = 0; REPEATABLE_READ = 1; SERIALIZABLE = 2; } message CommitRequest { string txn_id = 1; } message CommitResponse { string txn_id = 1; bool success = 2; uint64 rows_affected = 3; google.protobuf.Timestamp committed_at = 4; } message RollbackRequest { string txn_id = 1; } message RollbackResponse { string txn_id = 1; bool success = 2; } gRPC Example with grpcurl # Execute a query grpcurl -plaintext -d '{ \"sql\": \"SELECT id, name FROM users LIMIT 5\" }' localhost:9090 thunder.ThunderQuery/Execute # Explain a query grpcurl -plaintext -d '{ \"sql\": \"SELECT * FROM orders WHERE customer_id = 1001\", \"analyze\": true }' localhost:9090 thunder.ThunderQuery/Explain # Begin a transaction grpcurl -plaintext -d '{ \"isolation_level\": \"SERIALIZABLE\" }' localhost:9090 thunder.ThunderQuery/BeginTransaction # Commit a transaction grpcurl -plaintext -d '{ \"txn_id\": \"txn_a1b2c3d4e5f6\" }' localhost:9090 thunder.ThunderQuery/Commit # Rollback a transaction grpcurl -plaintext -d '{ \"txn_id\": \"txn_a1b2c3d4e5f6\" }' localhost:9090 thunder.ThunderQuery/Rollback Cluster Service service Cluster { // Get all nodes in the cluster rpc GetNodes(GetNodesRequest) returns (GetNodesResponse); // Get all regions rpc GetRegions(GetRegionsRequest) returns (GetRegionsResponse); // Propose a configuration change to the Raft cluster rpc Propose(ProposeRequest) returns (ProposeResponse); // Stream cluster events (leader changes, node joins/leaves) rpc WatchEvents(WatchEventsRequest) returns (stream ClusterEvent); } Message Definitions message GetNodesRequest { string region = 1; // Optional: filter by region } message GetNodesResponse { repeated Node nodes = 1; } message Node { string id = 1; string address = 2; string role = 3; // \"leader\", \"follower\", \"learner\" string region = 4; string status = 5; // \"healthy\", \"suspect\", \"down\" uint64 raft_term = 6; google.protobuf.Timestamp last_heartbeat = 7; uint64 storage_used_bytes = 8; uint64 storage_total_bytes = 9; } message GetRegionsRequest {} message GetRegionsResponse { repeated Region regions = 1; } message Region { string name = 1; uint32 node_count = 2; uint32 leader_count = 3; uint64 total_storage_bytes = 4; uint64 used_storage_bytes = 5; string status = 6; } message ProposeRequest { oneof proposal { AddNodeProposal add_node = 1; RemoveNodeProposal remove_node = 2; TransferLeaderProposal transfer_leader = 3; } } message AddNodeProposal { string node_id = 1; string address = 2; string region = 3; bool as_learner = 4; } message RemoveNodeProposal { string node_id = 1; bool force = 2; } message TransferLeaderProposal { string target_node_id = 1; } message ProposeResponse { bool accepted = 1; string proposal_id = 2; string message = 3; } message WatchEventsRequest { repeated string event_types = 1; // Filter: \"leader_change\", \"node_join\", \"node_leave\", \"rebalance\" } message ClusterEvent { string event_type = 1; google.protobuf.Timestamp timestamp = 2; map\u003cstring, string\u003e metadata = 3; } gRPC Cluster Examples # Get all cluster nodes grpcurl -plaintext localhost:9090 thunder.Cluster/GetNodes # Get all regions grpcurl -plaintext localhost:9090 thunder.Cluster/GetRegions # Add a new node to the cluster grpcurl -plaintext -d '{ \"add_node\": { \"node_id\": \"node-4\", \"address\": \"10.0.3.10:5432\", \"region\": \"eu-west-1\", \"as_learner\": true } }' localhost:9090 thunder.Cluster/Propose # Watch cluster events grpcurl -plaintext -d '{ \"event_types\": [\"leader_change\", \"node_join\"] }' localhost:9090 thunder.Cluster/WatchEvents GraphQL API (port 8088) The GraphQL endpoint is available at http://localhost:8088/graphql. An interactive GraphiQL explorer is served at http://localhost:8088/graphiql when development mode is enabled.\nSchema Overview type Query { # List all tables in the database tables(schema: String): [Table!]! # Execute a read-only SQL query query(sql: String!, params: [JSON]): QueryResult! # Return the execution plan for a SQL query explain(sql: String!, analyze: Boolean, verbose: Boolean): ExplainResult! # Get cluster node information nodes: [Node!]! } type Mutation { # Create a new table createTable(input: CreateTableInput!): TableResult! # Drop an existing table dropTable(name: String!, ifExists: Boolean, cascade: Boolean): DropResult! # Execute a write SQL statement (INSERT, UPDATE, DELETE) execute(sql: String!, params: [JSON]): ExecuteResult! # Execute multiple statements in a transaction executeTransaction( statements: [StatementInput!]! isolationLevel: IsolationLevel ): TransactionResult! } type Subscription { # Watch for new row inserts on a table onRowInserted(table: String!, filter: String): RowEvent! # Watch for row updates on a table onRowUpdated(table: String!, filter: String): RowUpdateEvent! # Watch for row deletions on a table onRowDeleted(table: String!, filter: String): RowEvent! } Types type Table { name: String! schema: String! engine: String! columns: [Column!]! indexes: [Index!]! rowCount: Int! sizeBytes: Int! } type Column { name: String! type: String! nullable: Boolean! primaryKey: Boolean! default: String } type Index { name: String! columns: [String!]! type: String! unique: Boolean! } type QueryResult { columns: [String!]! columnTypes: [String!]! rows: [[JSON]]! rowCount: Int! executionTimeMs: Float! } type ExplainResult { plan: JSON! planningTimeMs: Float! executionTimeMs: Float } type ExecuteResult { rowsAffected: Int! executionTimeMs: Float! } type TableResult { name: String! created: Boolean! } type DropResult { name: String! dropped: Boolean! } type TransactionResult { committed: Boolean! results: [ExecuteResult!]! totalExecutionTimeMs: Float! } type RowEvent { table: String! operation: String! row: JSON! timestamp: String! lsn: String! } type RowUpdateEvent { table: String! operation: String! oldRow: JSON newRow: JSON! changedColumns: [String!]! timestamp: String! lsn: String! } type Node { id: String! address: String! role: String! region: String! status: String! } input CreateTableInput { name: String! schema: String engine: String columns: [ColumnInput!]! ifNotExists: Boolean } input ColumnInput { name: String! type: String! nullable: Boolean primaryKey: Boolean default: String } input StatementInput { sql: String! params: [JSON] } enum IsolationLevel { READ_COMMITTED REPEATABLE_READ SERIALIZABLE } Query Examples List all tables:\nquery { tables { name engine rowCount columns { name type nullable } } } curl -s http://localhost:8088/graphql \\ -H \"Content-Type: application/json\" \\ -d '{ \"query\": \"{ tables { name engine rowCount columns { name type nullable } } }\" }' | jq . Execute a query:\nquery { query(sql: \"SELECT name, email FROM users WHERE active = true LIMIT 3\") { columns rows rowCount executionTimeMs } } curl -s http://localhost:8088/graphql \\ -H \"Content-Type: application/json\" \\ -d '{ \"query\": \"{ query(sql: \\\"SELECT name, email FROM users WHERE active = true LIMIT 3\\\") { columns rows rowCount executionTimeMs } }\" }' | jq . Explain a query:\nquery { explain(sql: \"SELECT * FROM orders WHERE total \u003e 100\", analyze: true) { plan planningTimeMs executionTimeMs } } Mutation Examples Create a table:\nmutation { createTable(input: { name: \"events\" engine: \"columnar\" columns: [ { name: \"id\", type: \"Int64\", primaryKey: true } { name: \"event_type\", type: \"Varchar(50)\", nullable: false } { name: \"payload\", type: \"Jsonb\" } { name: \"created_at\", type: \"TimestampTz\", default: \"now()\" } ] ifNotExists: true }) { name created } } curl -s http://localhost:8088/graphql \\ -H \"Content-Type: application/json\" \\ -d '{ \"query\": \"mutation { createTable(input: { name: \\\"events\\\", engine: \\\"columnar\\\", columns: [{ name: \\\"id\\\", type: \\\"Int64\\\", primaryKey: true }, { name: \\\"event_type\\\", type: \\\"Varchar(50)\\\", nullable: false }, { name: \\\"payload\\\", type: \\\"Jsonb\\\" }, { name: \\\"created_at\\\", type: \\\"TimestampTz\\\", default: \\\"now()\\\" }], ifNotExists: true }) { name created } }\" }' | jq . Execute a write statement:\nmutation { execute( sql: \"INSERT INTO events (id, event_type, payload) VALUES (1, 'signup', '{\\\"user_id\\\": 42}')\" ) { rowsAffected executionTimeMs } } Execute a transaction:\nmutation { executeTransaction( statements: [ { sql: \"UPDATE accounts SET balance = balance - 500 WHERE id = 1\" } { sql: \"UPDATE accounts SET balance = balance + 500 WHERE id = 2\" } { sql: \"INSERT INTO transfers (from_id, to_id, amount) VALUES (1, 2, 500)\" } ] isolationLevel: SERIALIZABLE ) { committed results { rowsAffected } totalExecutionTimeMs } } Subscription Examples GraphQL subscriptions use WebSocket transport (graphql-ws protocol).\nSubscribe to new order inserts:\nsubscription { onRowInserted(table: \"orders\", filter: \"total \u003e 1000\") { table operation row timestamp } } Subscribe to user profile updates:\nsubscription { onRowUpdated(table: \"users\") { table oldRow newRow changedColumns timestamp } } Subscribe to deletions:\nsubscription { onRowDeleted(table: \"sessions\") { table row timestamp lsn } } JavaScript client example using graphql-ws:\nimport { createClient } from 'graphql-ws'; const client = createClient({ url: 'ws://localhost:8088/graphql', }); // Subscribe to order inserts const unsubscribe = client.subscribe( { query: `subscription { onRowInserted(table: \"orders\") { row timestamp } }`, }, { next(data) { console.log('New order:', data.data.onRowInserted); }, error(err) { console.error('Subscription error:', err); }, complete() { console.log('Subscription complete'); }, } ); WebSocket API (port 8088) ThunderDB provides raw WebSocket endpoints for streaming queries and event subscriptions without the GraphQL layer.\nWS /ws/query Stream query results row by row over a persistent WebSocket connection. Useful for large result sets or continuous queries.\nConnect:\nwscat -c ws://localhost:8088/ws/query Send a query:\n{ \"type\": \"query\", \"id\": \"q1\", \"sql\": \"SELECT * FROM orders WHERE status = 'pending'\", \"params\": [] } Receive responses:\n{\"type\": \"metadata\", \"id\": \"q1\", \"columns\": [\"id\", \"customer_id\", \"total\", \"status\", \"created_at\"], \"column_types\": [\"Int64\", \"Int64\", \"Decimal\", \"Varchar\", \"TimestampTz\"]} {\"type\": \"row\", \"id\": \"q1\", \"data\": [1001, 42, 299.99, \"pending\", \"2025-12-15T10:00:00Z\"]} {\"type\": \"row\", \"id\": \"q1\", \"data\": [1002, 87, 149.50, \"pending\", \"2025-12-15T10:05:00Z\"]} {\"type\": \"complete\", \"id\": \"q1\", \"row_count\": 2, \"execution_time_ms\": 4.2} Cancel a running query:\n{ \"type\": \"cancel\", \"id\": \"q1\" } WS /ws/events Subscribe to real-time CDC events on one or more tables.\nConnect:\nwscat -c ws://localhost:8088/ws/events Subscribe to events:\n{ \"type\": \"subscribe\", \"id\": \"sub1\", \"table\": \"orders\", \"events\": [\"insert\", \"update\", \"delete\"], \"filter\": \"total \u003e 100\" } Receive events:\n{ \"type\": \"event\", \"id\": \"sub1\", \"table\": \"orders\", \"operation\": \"insert\", \"row\": {\"id\": 1003, \"customer_id\": 55, \"total\": 520.00, \"status\": \"new\", \"created_at\": \"2025-12-15T10:30:00Z\"}, \"lsn\": \"0/1A2B3C4D\", \"timestamp\": \"2025-12-15T10:30:00.123Z\" } { \"type\": \"event\", \"id\": \"sub1\", \"table\": \"orders\", \"operation\": \"update\", \"old_row\": {\"id\": 1003, \"status\": \"new\"}, \"new_row\": {\"id\": 1003, \"status\": \"processing\"}, \"changed_columns\": [\"status\"], \"lsn\": \"0/1A2B3C5E\", \"timestamp\": \"2025-12-15T10:30:05.456Z\" } Unsubscribe:\n{ \"type\": \"unsubscribe\", \"id\": \"sub1\" } WS /ws/replication Internal replication stream used by ThunderDB nodes for WAL shipping. This endpoint is primarily for cluster-internal use but can be consumed by external tools for logical replication.\nConnect:\nwscat -c ws://localhost:8088/ws/replication Start replication from a specific LSN:\n{ \"type\": \"start_replication\", \"slot\": \"my_replication_slot\", \"start_lsn\": \"0/1A000000\", \"options\": { \"output_format\": \"json\", \"include_transaction_boundaries\": true } } Receive WAL entries:\n{\"type\": \"begin\", \"txn_id\": \"txn_001\", \"lsn\": \"0/1A000010\", \"timestamp\": \"2025-12-15T10:30:00Z\"} {\"type\": \"insert\", \"table\": \"orders\", \"lsn\": \"0/1A000020\", \"row\": {\"id\": 1003, \"total\": 520.00}} {\"type\": \"commit\", \"txn_id\": \"txn_001\", \"lsn\": \"0/1A000030\", \"timestamp\": \"2025-12-15T10:30:00.001Z\"} Acknowledge processed LSN (to advance the replication slot):\n{ \"type\": \"ack\", \"lsn\": \"0/1A000030\" } Rate Limiting ThunderDB enforces per-client rate limits on the HTTP API layer. Default limits:\nEndpoint Category Requests/sec Burst /admin/* 100 200 /api/v1/query 1000 2000 /api/v1/vector-search 500 1000 /api/v1/cluster/* 50 100 All other endpoints 500 1000 Rate-limited responses return 429 Too Many Requests with a Retry-After header:\nHTTP/1.1 429 Too Many Requests Retry-After: 1 X-RateLimit-Limit: 1000 X-RateLimit-Remaining: 0 X-RateLimit-Reset: 1702641001 Rate limits are configurable in thunderdb.toml under the [http.rate_limit] section. See the Configuration Guide for details.\nPagination For endpoints that return lists (tables, indexes, subscriptions, nodes), ThunderDB supports cursor-based pagination:\n# First page curl -s \"http://localhost:8088/api/v1/tables?limit=10\" | jq . # Next page using cursor from previous response curl -s \"http://localhost:8088/api/v1/tables?limit=10\u0026cursor=eyJvZmZzZXQiOjEwfQ==\" | jq . Response includes pagination metadata:\n{ \"tables\": [...], \"pagination\": { \"total\": 47, \"limit\": 10, \"has_more\": true, \"next_cursor\": \"eyJvZmZzZXQiOjEwfQ==\" } } ","categories":"","description":"Complete reference for ThunderDB REST, gRPC, GraphQL, and WebSocket APIs with request/response examples.","excerpt":"Complete reference for ThunderDB REST, gRPC, GraphQL, and WebSocket …","ref":"/docs/docs/developer/api-reference/","tags":"","title":"API Reference"},{"body":"Deployment This guide covers all supported methods for deploying ThunderDB, from building from source for development to running production-grade Kubernetes clusters.\nBuilding from Source Prerequisites Rust 1.75 or later (install via rustup) Cargo (included with Rust) C/C++ compiler: GCC 9+ or Clang 12+ (required for native dependencies) CMake 3.16+ (required for building RocksDB bindings) Protocol Buffers compiler (protoc) 3.15+ (required for gRPC code generation) OpenSSL development headers (for TLS support) Git (for cloning the repository) On Ubuntu/Debian:\nsudo apt-get update sudo apt-get install -y build-essential cmake protobuf-compiler libssl-dev pkg-config git curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh source $HOME/.cargo/env On macOS:\nbrew install cmake protobuf openssl pkg-config curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh source $HOME/.cargo/env Build Clone the repository and build in release mode:\ngit clone https://github.com/thunderdb/thunderdb.git cd thunderdb cargo build --release The optimized binary is produced at:\ntarget/release/thunderdb Verify the Build ./target/release/thunderdb --version # ThunderDB 0.1.0 (rustc 1.75.0, built 2026-01-15) Run ./target/release/thunderdb --config config/thunderdb.toml If no configuration file is specified, ThunderDB starts with default settings (single-node, all ports on localhost).\nBuild Options Flag Description --release Optimized build with LTO (recommended for production) --features tls Enable TLS support (enabled by default) --features simd Enable SIMD-accelerated operations --features jemalloc Use jemalloc allocator (recommended for production) --no-default-features Disable all optional features Example with all production features:\ncargo build --release --features \"tls,simd,jemalloc\" Docker Dockerfile ThunderDB uses a multi-stage build to produce a minimal production image:\n# Stage 1: Build FROM rust:1.75-bookworm AS builder RUN apt-get update \u0026\u0026 apt-get install -y \\ cmake protobuf-compiler libssl-dev pkg-config \\ \u0026\u0026 rm -rf /var/lib/apt/lists/* WORKDIR /usr/src/thunderdb COPY . . RUN cargo build --release --features \"tls,jemalloc\" # Stage 2: Runtime FROM debian:bookworm-slim RUN apt-get update \u0026\u0026 apt-get install -y \\ libssl3 ca-certificates \\ \u0026\u0026 rm -rf /var/lib/apt/lists/* \\ \u0026\u0026 groupadd -r thunder \u0026\u0026 useradd -r -g thunder thunder \\ \u0026\u0026 mkdir -p /var/lib/thunderdb/data /var/lib/thunderdb/wal /var/log/thunderdb /etc/thunderdb \\ \u0026\u0026 chown -R thunder:thunder /var/lib/thunderdb /var/log/thunderdb /etc/thunderdb COPY --from=builder /usr/src/thunderdb/target/release/thunderdb /usr/local/bin/thunderdb COPY --from=builder /usr/src/thunderdb/config/thunderdb.toml /etc/thunderdb/thunderdb.toml USER thunder EXPOSE 5432 3306 6379 8088 9090 VOLUME [\"/var/lib/thunderdb/data\", \"/var/lib/thunderdb/wal\"] ENTRYPOINT [\"thunderdb\"] CMD [\"--config\", \"/etc/thunderdb/thunderdb.toml\"] Building the Docker Image docker build -t thunderdb:latest . Running with Docker Basic single-node:\ndocker run -d \\ --name thunderdb \\ -p 5432:5432 \\ -p 3306:3306 \\ -p 6379:6379 \\ -p 8088:8088 \\ -p 9090:9090 \\ -v thunderdb-data:/var/lib/thunderdb/data \\ -v thunderdb-wal:/var/lib/thunderdb/wal \\ thunderdb:latest With custom configuration:\ndocker run -d \\ --name thunderdb \\ -p 5432:5432 \\ -p 3306:3306 \\ -p 6379:6379 \\ -p 8088:8088 \\ -p 9090:9090 \\ -v thunderdb-data:/var/lib/thunderdb/data \\ -v thunderdb-wal:/var/lib/thunderdb/wal \\ -v $(pwd)/my-config.toml:/etc/thunderdb/thunderdb.toml:ro \\ thunderdb:latest With environment variable overrides:\ndocker run -d \\ --name thunderdb \\ -p 5432:5432 \\ -p 3306:3306 \\ -p 6379:6379 \\ -p 8088:8088 \\ -p 9090:9090 \\ -e THUNDERDB_LOG_LEVEL=info \\ -e THUNDERDB_SUPERUSER_PASSWORD_HASH=\"argon2:...\" \\ -v thunderdb-data:/var/lib/thunderdb/data \\ -v thunderdb-wal:/var/lib/thunderdb/wal \\ thunderdb:latest Docker Compose Create a docker-compose.yml for a complete single-node deployment with monitoring:\nversion: \"3.8\" services: thunderdb: image: thunderdb:latest build: context: . dockerfile: Dockerfile container_name: thunderdb restart: unless-stopped ports: - \"5432:5432\" # PostgreSQL wire protocol - \"3306:3306\" # MySQL wire protocol - \"6379:6379\" # RESP (Redis) wire protocol - \"8088:8088\" # HTTP API + Admin endpoints - \"9090:9090\" # gRPC volumes: - thunderdb-data:/var/lib/thunderdb/data - thunderdb-wal:/var/lib/thunderdb/wal - ./config/thunderdb.toml:/etc/thunderdb/thunderdb.toml:ro environment: THUNDERDB_LOG_LEVEL: info THUNDERDB_DATA_DIR: /var/lib/thunderdb/data THUNDERDB_WAL_DIR: /var/lib/thunderdb/wal healthcheck: test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8088/admin/health\"] interval: 10s timeout: 5s retries: 5 start_period: 30s deploy: resources: limits: cpus: \"4\" memory: 8G reservations: cpus: \"2\" memory: 4G prometheus: image: prom/prometheus:latest container_name: thunderdb-prometheus restart: unless-stopped ports: - \"9091:9090\" volumes: - ./deploy/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro - prometheus-data:/prometheus depends_on: thunderdb: condition: service_healthy grafana: image: grafana/grafana:latest container_name: thunderdb-grafana restart: unless-stopped ports: - \"3000:3000\" volumes: - ./deploy/grafana/provisioning:/etc/grafana/provisioning:ro - ./deploy/grafana/dashboards:/var/lib/grafana/dashboards:ro - grafana-data:/var/lib/grafana environment: GF_SECURITY_ADMIN_PASSWORD: admin depends_on: - prometheus volumes: thunderdb-data: driver: local thunderdb-wal: driver: local prometheus-data: driver: local grafana-data: driver: local Start the stack:\ndocker compose up -d Verify all services are healthy:\ndocker compose ps docker compose logs thunderdb Kubernetes ThunderDB provides production-ready Kubernetes manifests for deploying a distributed cluster. All manifests are located in deploy/k8s/.\nNamespace # deploy/k8s/namespace.yaml apiVersion: v1 kind: Namespace metadata: name: thunderdb labels: app: thunderdb ConfigMap # deploy/k8s/configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: thunderdb-config namespace: thunderdb labels: app: thunderdb data: thunderdb.toml: | [node] node_id = 0 # Overridden per pod via environment variable [network] listen_addr = \"0.0.0.0\" pg_port = 5432 mysql_port = 3306 resp_port = 6379 http_port = 8088 grpc_port = 9090 [storage] data_dir = \"/var/lib/thunderdb/data\" wal_dir = \"/var/lib/thunderdb/wal\" buffer_pool_size = \"2GB\" wal_buffer_size = \"64MB\" page_size = \"16KB\" checkpoint_interval = \"60s\" compaction_threads = 4 direct_io = true compression = true compression_algorithm = \"Lz4\" max_wal_size = \"2GB\" sync_commit = true [cluster] cluster_name = \"thunderdb-k8s\" raft_election_timeout = \"1s\" raft_heartbeat_interval = \"100ms\" replication_factor = 3 max_region_size = \"256MB\" min_region_size = \"64MB\" auto_balance = true [security] authentication_enabled = true tls_enabled = false # Handled by Kubernetes service mesh or ingress [logging] level = \"info\" format = \"json\" slow_query_enabled = true slow_query_threshold = \"1s\" StatefulSet # deploy/k8s/statefulset.yaml apiVersion: apps/v1 kind: StatefulSet metadata: name: thunderdb namespace: thunderdb labels: app: thunderdb spec: serviceName: thunderdb-headless replicas: 3 podManagementPolicy: Parallel selector: matchLabels: app: thunderdb template: metadata: labels: app: thunderdb annotations: prometheus.io/scrape: \"true\" prometheus.io/port: \"8088\" prometheus.io/path: \"/admin/metrics\" spec: terminationGracePeriodSeconds: 60 securityContext: runAsUser: 1000 runAsGroup: 1000 fsGroup: 1000 initContainers: - name: init-config image: busybox:1.36 command: - sh - -c - | # Extract ordinal index from hostname (e.g., thunderdb-0 -\u003e 0) ORDINAL=$(echo $HOSTNAME | rev | cut -d'-' -f1 | rev) echo \"Node ID: $ORDINAL\" # Generate peer list PEERS=\"\" for i in $(seq 0 2); do if [ $i -ne $ORDINAL ]; then PEERS=\"${PEERS}thunderdb-${i}.thunderdb-headless.thunderdb.svc.cluster.local:9090,\" fi done PEERS=$(echo $PEERS | sed 's/,$//') echo \"THUNDERDB_NODE_ID=$ORDINAL\" \u003e /etc/thunderdb/env echo \"THUNDERDB_CLUSTER_PEERS=$PEERS\" \u003e\u003e /etc/thunderdb/env volumeMounts: - name: config-env mountPath: /etc/thunderdb containers: - name: thunderdb image: thunderdb:latest imagePullPolicy: IfNotPresent ports: - name: pg containerPort: 5432 protocol: TCP - name: mysql containerPort: 3306 protocol: TCP - name: resp containerPort: 6379 protocol: TCP - name: http containerPort: 8088 protocol: TCP - name: grpc containerPort: 9090 protocol: TCP envFrom: - configMapRef: name: thunderdb-env optional: true env: - name: THUNDERDB_DATA_DIR value: /var/lib/thunderdb/data - name: THUNDERDB_WAL_DIR value: /var/lib/thunderdb/wal - name: THUNDERDB_SUPERUSER_PASSWORD_HASH valueFrom: secretKeyRef: name: thunderdb-secrets key: superuser-password-hash readinessProbe: httpGet: path: /admin/ready port: http initialDelaySeconds: 10 periodSeconds: 5 timeoutSeconds: 3 failureThreshold: 3 livenessProbe: httpGet: path: /admin/live port: http initialDelaySeconds: 30 periodSeconds: 10 timeoutSeconds: 5 failureThreshold: 5 startupProbe: httpGet: path: /admin/health port: http initialDelaySeconds: 5 periodSeconds: 5 failureThreshold: 30 resources: requests: cpu: \"2\" memory: 4Gi limits: cpu: \"4\" memory: 8Gi volumeMounts: - name: data mountPath: /var/lib/thunderdb/data - name: wal mountPath: /var/lib/thunderdb/wal - name: config mountPath: /etc/thunderdb/thunderdb.toml subPath: thunderdb.toml readOnly: true - name: config-env mountPath: /etc/thunderdb/env subPath: env readOnly: true volumes: - name: config configMap: name: thunderdb-config - name: config-env emptyDir: {} volumeClaimTemplates: - metadata: name: data labels: app: thunderdb spec: accessModes: [\"ReadWriteOnce\"] storageClassName: fast-ssd resources: requests: storage: 100Gi - metadata: name: wal labels: app: thunderdb spec: accessModes: [\"ReadWriteOnce\"] storageClassName: fast-ssd resources: requests: storage: 50Gi Service Definitions # deploy/k8s/service.yaml # Headless service for StatefulSet DNS resolution apiVersion: v1 kind: Service metadata: name: thunderdb-headless namespace: thunderdb labels: app: thunderdb spec: clusterIP: None selector: app: thunderdb ports: - name: pg port: 5432 targetPort: pg - name: mysql port: 3306 targetPort: mysql - name: resp port: 6379 targetPort: resp - name: http port: 8088 targetPort: http - name: grpc port: 9090 targetPort: grpc --- # ClusterIP service for internal client access apiVersion: v1 kind: Service metadata: name: thunderdb namespace: thunderdb labels: app: thunderdb spec: type: ClusterIP selector: app: thunderdb ports: - name: pg port: 5432 targetPort: pg - name: mysql port: 3306 targetPort: mysql - name: resp port: 6379 targetPort: resp - name: http port: 8088 targetPort: http - name: grpc port: 9090 targetPort: grpc --- # LoadBalancer service for external client access (optional) apiVersion: v1 kind: Service metadata: name: thunderdb-external namespace: thunderdb labels: app: thunderdb annotations: service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\" spec: type: LoadBalancer selector: app: thunderdb ports: - name: pg port: 5432 targetPort: pg - name: mysql port: 3306 targetPort: mysql - name: http port: 8088 targetPort: http Deploy to Kubernetes Apply all manifests using kustomize:\nkubectl apply -k deploy/k8s/ Or apply individually:\nkubectl apply -f deploy/k8s/namespace.yaml kubectl apply -f deploy/k8s/configmap.yaml kubectl apply -f deploy/k8s/secrets.yaml kubectl apply -f deploy/k8s/statefulset.yaml kubectl apply -f deploy/k8s/service.yaml Verify the deployment:\nkubectl -n thunderdb get pods -w kubectl -n thunderdb get svc kubectl -n thunderdb logs thunderdb-0 Horizontal Scaling ThunderDB uses Raft consensus, so scaling considerations differ from stateless applications:\nScaling up: Add replicas to the StatefulSet and update the peer configuration. New nodes join the cluster automatically and begin receiving region replicas. Scaling down: Remove nodes gracefully by draining regions first. Never scale below the replication_factor (default: 3). Odd replica counts: Always use an odd number of replicas (3, 5, 7) for Raft quorum. A 3-node cluster tolerates 1 failure; a 5-node cluster tolerates 2. # Scale to 5 replicas kubectl -n thunderdb scale statefulset thunderdb --replicas=5 # Verify all pods are running and ready kubectl -n thunderdb get pods After scaling, verify cluster membership:\ncurl http://thunderdb.thunderdb.svc:8088/admin/cluster/members Debian Package Building the Package ThunderDB includes a script to build Debian packages:\n./scripts/build-deb.sh This produces a .deb file in the target/debian/ directory:\ntarget/debian/thunderdb_0.1.0_amd64.deb Installing sudo dpkg -i thunderdb_0.1.0_amd64.deb If there are dependency issues:\nsudo apt-get install -f Package Contents The Debian package installs the following:\nPath Description /usr/local/bin/thunderdb ThunderDB binary /etc/thunderdb/thunderdb.toml Default configuration file /lib/systemd/system/thunderdb.service systemd service file /var/lib/thunderdb/data/ Data directory /var/lib/thunderdb/wal/ WAL directory /var/log/thunderdb/ Log directory The package also creates the thunder system user and group.\nUninstalling sudo dpkg -r thunderdb # To also remove configuration and data: sudo dpkg -P thunderdb systemd Service ThunderDB ships with a systemd service file for production Linux deployments.\nService File # /lib/systemd/system/thunderdb.service [Unit] Description=ThunderDB Distributed HTAP Database Documentation=https://thunderdb.io/docs After=network-online.target Wants=network-online.target StartLimitIntervalSec=60 StartLimitBurst=3 [Service] Type=notify User=thunder Group=thunder ExecStart=/usr/local/bin/thunderdb --config /etc/thunderdb/thunderdb.toml ExecReload=/bin/kill -HUP $MAINPID Restart=on-failure RestartSec=5s TimeoutStartSec=120 TimeoutStopSec=60 # Security hardening NoNewPrivileges=yes ProtectSystem=strict ProtectHome=yes PrivateTmp=yes PrivateDevices=yes ProtectKernelTunables=yes ProtectKernelModules=yes ProtectControlGroups=yes ReadWritePaths=/var/lib/thunderdb /var/log/thunderdb # Resource limits LimitNOFILE=65535 LimitNPROC=65535 LimitMEMLOCK=infinity # Logging StandardOutput=journal StandardError=journal SyslogIdentifier=thunderdb [Install] WantedBy=multi-user.target Managing the Service # Reload systemd after installing or modifying the service file sudo systemctl daemon-reload # Start ThunderDB sudo systemctl start thunderdb # Stop ThunderDB sudo systemctl stop thunderdb # Restart ThunderDB sudo systemctl restart thunderdb # Enable ThunderDB to start on boot sudo systemctl enable thunderdb # Disable auto-start on boot sudo systemctl disable thunderdb # Check service status sudo systemctl status thunderdb # View logs sudo journalctl -u thunderdb -f sudo journalctl -u thunderdb --since \"1 hour ago\" Configuration Reload ThunderDB supports hot-reloading certain configuration parameters without a full restart:\nsudo systemctl reload thunderdb Hot-reloadable parameters include log level, slow query threshold, and connection limits. Changes to storage engine or cluster settings require a full restart.\nMulti-Node Cluster Setup Using the Cluster Script ThunderDB provides a convenience script for setting up multi-node clusters:\n./scripts/cluster.sh --nodes 3 --data-dir /var/lib/thunderdb This script generates configuration files for each node and provides the commands to start them.\nManual Cluster Configuration For production clusters, configure each node manually.\nNode 1 (thunderdb-1.toml):\n[node] node_id = 1 [network] listen_addr = \"10.0.1.1\" pg_port = 5432 mysql_port = 3306 resp_port = 6379 http_port = 8088 grpc_port = 9090 [storage] data_dir = \"/var/lib/thunderdb/data\" wal_dir = \"/var/lib/thunderdb/wal\" buffer_pool_size = \"4GB\" wal_buffer_size = \"64MB\" page_size = \"16KB\" checkpoint_interval = \"60s\" compaction_threads = 4 direct_io = true compression = true compression_algorithm = \"Lz4\" max_wal_size = \"2GB\" sync_commit = true [cluster] cluster_name = \"production\" peers = [ \"10.0.1.2:9090\", \"10.0.1.3:9090\" ] raft_election_timeout = \"1s\" raft_heartbeat_interval = \"100ms\" replication_factor = 3 max_region_size = \"256MB\" min_region_size = \"64MB\" auto_balance = true [security] authentication_enabled = true tls_enabled = true tls_cert_path = \"/etc/thunderdb/tls/server.crt\" tls_key_path = \"/etc/thunderdb/tls/server.key\" superuser = \"admin\" superuser_password = \"change-me-in-production\" [logging] level = \"info\" format = \"json\" slow_query_enabled = true slow_query_threshold = \"1s\" Node 2 (thunderdb-2.toml):\n[node] node_id = 2 [network] listen_addr = \"10.0.1.2\" # ... same ports as node 1 [cluster] cluster_name = \"production\" peers = [ \"10.0.1.1:9090\", \"10.0.1.3:9090\" ] # ... same cluster settings Node 3 (thunderdb-3.toml):\n[node] node_id = 3 [network] listen_addr = \"10.0.1.3\" # ... same ports as node 1 [cluster] cluster_name = \"production\" peers = [ \"10.0.1.1:9090\", \"10.0.1.2:9090\" ] # ... same cluster settings Starting the Cluster Start nodes in any order. Raft handles leader election automatically:\n# On node 1 ./thunderdb --config /etc/thunderdb/thunderdb-1.toml # On node 2 ./thunderdb --config /etc/thunderdb/thunderdb-2.toml # On node 3 ./thunderdb --config /etc/thunderdb/thunderdb-3.toml Cluster Parameters Parameter Default Description cluster_name \"default\" Cluster identifier. All nodes in a cluster must share the same name. peers [] List of peer addresses in host:grpc_port format. raft_election_timeout \"1s\" Time a follower waits before starting an election. Increase for high-latency networks. raft_heartbeat_interval \"100ms\" Interval between leader heartbeats. Must be less than raft_election_timeout. replication_factor 3 Number of replicas for each region. Cannot exceed the number of nodes. max_region_size \"256MB\" Regions are split when they exceed this size. min_region_size \"64MB\" Regions are merged when they fall below this size. auto_balance true Automatically balance regions across nodes. Verifying the Cluster After all nodes are running, verify cluster health:\n# Check cluster membership curl http://10.0.1.1:8088/admin/cluster/members # Check Raft status curl http://10.0.1.1:8088/admin/cluster/raft # Check region distribution curl http://10.0.1.1:8088/admin/cluster/regions Expected output for a healthy 3-node cluster:\n{ \"cluster_name\": \"production\", \"members\": [ {\"node_id\": 1, \"addr\": \"10.0.1.1:9090\", \"role\": \"leader\", \"status\": \"healthy\"}, {\"node_id\": 2, \"addr\": \"10.0.1.2:9090\", \"role\": \"follower\", \"status\": \"healthy\"}, {\"node_id\": 3, \"addr\": \"10.0.1.3:9090\", \"role\": \"follower\", \"status\": \"healthy\"} ], \"leader_id\": 1, \"term\": 1, \"replication_factor\": 3 } Production Deployment Checklist Before going to production, verify the following:\nHardware: SSD storage, adequate RAM (see Configuration) OS tuning: File descriptor limits (ulimit -n 65535), disable swap, set vm.swappiness=1 Storage: Separate disks/volumes for data and WAL directories Network: All required ports open between cluster nodes; firewall rules for client access Security: TLS enabled, authentication enabled, superuser password changed, audit logging on Monitoring: Prometheus scraping metrics, Grafana dashboards deployed, alerting configured Backups: Automated backup schedule configured, recovery procedure tested Configuration: sync_commit = true, direct_io = true, appropriate buffer pool size Cluster: Odd number of nodes, replication_factor matches cluster size, peers configured correctly systemd: Service enabled, resource limits set, auto-restart configured ","categories":"","description":"Deploy ThunderDB from source, Docker, Kubernetes, or system packages. Set up single-node and multi-node clusters.","excerpt":"Deploy ThunderDB from source, Docker, Kubernetes, or system packages. …","ref":"/docs/docs/administrator/deployment/","tags":"","title":"Deployment"},{"body":"Development Setup This guide walks you through setting up a complete development environment for ThunderDB. By the end, you will be able to build the project, run tests, and start a local development server.\nPrerequisites Before you begin, ensure the following tools are installed on your system.\nRequired Tool Version Purpose Rust 1.75+ (pinned in rust-toolchain.toml) Compiler and standard library Cargo Included with Rust Build system and package manager Git 2.30+ Version control Protobuf Compiler (protoc) 3.15+ Compiling .proto files for gRPC services C/C++ Compiler GCC 9+ or Clang 12+ Building native dependencies (RocksDB, etc.) CMake 3.16+ Build system for native dependencies pkg-config Any recent version Locating system libraries Optional Tool Version Purpose Docker 20.10+ Containerized development and testing Docker Compose 2.0+ Multi-container dev environment cargo-watch Latest Auto-rebuild on file changes cargo-nextest Latest Faster test runner cargo-tarpaulin Latest Code coverage cargo-criterion Latest Benchmark runner cargo-udeps Latest Detect unused dependencies Installing Prerequisites macOS (Homebrew):\n# Install Rust via rustup curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh # Install system dependencies brew install protobuf cmake pkg-config # Optional: Docker Desktop brew install --cask docker Ubuntu / Debian:\n# Install Rust via rustup curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh # Install system dependencies sudo apt update sudo apt install -y protobuf-compiler libprotobuf-dev cmake pkg-config \\ build-essential libssl-dev libclang-dev # Optional: Docker sudo apt install -y docker.io docker-compose-v2 Arch Linux:\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh sudo pacman -S protobuf cmake pkg-config base-devel openssl clang Windows (WSL2 recommended):\n# Use WSL2 with Ubuntu, then follow the Ubuntu instructions above. # Native Windows builds are not officially supported but may work. Cloning the Repository # Clone the main repository git clone https://github.com/thunderdb/thunderdb.git cd thunderdb # The rust-toolchain.toml file will automatically configure the correct # Rust version when you run any cargo command. Verify your setup:\nrustc --version # Should show 1.75.0 or later cargo --version # Should match the Rust version protoc --version # Should show libprotoc 3.15 or later Building ThunderDB Debug Build The debug build compiles quickly and includes debug symbols, but runs slower due to lack of optimizations:\ncargo build This builds all 14 crates in the workspace. The resulting binary is located at target/debug/thunder-server.\nBuild times for a clean debug build on typical hardware:\nApple M2 Pro (12 cores, 32GB RAM): ~2-3 minutes Intel i7-12700K (12 cores, 32GB RAM): ~3-4 minutes GitHub Actions runner: ~5-7 minutes Release Build The release build enables full optimizations as defined in the workspace Cargo.toml:\ncargo build --release The release profile is configured with:\nopt-level = 3 – Maximum optimization lto = \"thin\" – Thin link-time optimization for better codegen with reasonable build times codegen-units = 1 – Single codegen unit for maximum optimization panic = \"abort\" – Abort on panic (smaller binary, no unwinding overhead) The resulting binary is at target/release/thunder-server. Release builds take significantly longer (10-20 minutes) but produce binaries suitable for benchmarking and deployment.\nBuilding Individual Crates To build a specific crate without building the entire workspace:\n# Build only the storage engine cargo build -p thunder-storage # Build only the SQL layer cargo build -p thunder-sql # Build only the protocol layer cargo build -p thunder-protocol This is useful during development when you are working on a single crate and want fast iteration.\nCommon Build Issues Issue Solution protoc not found Install protobuf-compiler or set PROTOC env var RocksDB compilation fails Ensure C++ compiler and CMake are installed Out of memory during linking Use lto = \"thin\" instead of \"fat\", or increase swap Linker errors on macOS Run xcode-select --install to install command line tools OpenSSL not found Install libssl-dev (Ubuntu) or openssl (Homebrew) Running Tests Full Test Suite Run the entire test suite across all crates:\ncargo test Or use the project test script, which sets up any required test infrastructure:\n./scripts/run_tests.sh Running Tests for a Specific Crate # Test only the storage engine cargo test -p thunder-storage # Test only the transaction manager cargo test -p thunder-txn # Test only the query engine cargo test -p thunder-query Running a Specific Test # Run a test by name (partial match) cargo test test_btree_insert # Run a specific test in a specific crate cargo test -p thunder-storage test_wal_recovery # Run tests matching a pattern cargo test -p thunder-sql parser:: Using cargo-nextest (Recommended) cargo-nextest provides faster test execution through better parallelism and clearer output:\n# Install cargo install cargo-nextest # Run all tests cargo nextest run # Run tests for a specific crate cargo nextest run -p thunder-storage Test Categories ThunderDB has several categories of tests with different execution characteristics:\n# Unit tests (fast, no external dependencies) cargo test --lib # Integration tests (may require running server) cargo test --test '*' # Documentation tests cargo test --doc # Ignored tests (long-running, require special setup) cargo test -- --ignored See the Testing guide for comprehensive details.\nRunning the Development Server Using the Dev Script The simplest way to start a development server:\n./scripts/dev.sh This script:\nBuilds ThunderDB in debug mode Starts a single-node instance with default development configuration Enables verbose logging Exposes all protocol endpoints on localhost Manual Start You can also start the server directly:\n# Build and run in one step cargo run -- --config config/dev.toml # Or run the built binary cargo build ./target/debug/thunder-server --config config/dev.toml Default Development Ports Service Port Protocol PostgreSQL wire protocol 5432 TCP MySQL wire protocol 3306 TCP Redis RESP protocol 6379 TCP REST API 8080 HTTP gRPC API 50051 HTTP/2 GraphQL API 8081 HTTP WebSocket API 8082 WS Admin Dashboard 9090 HTTP Connecting to the Dev Server # PostgreSQL client psql -h localhost -p 5432 -U admin -d thunderdb # MySQL client mysql -h 127.0.0.1 -P 3306 -u admin -p thunderdb # Redis client redis-cli -h localhost -p 6379 # REST API curl http://localhost:8080/api/v1/health # Admin Dashboard open http://localhost:9090 IDE Setup VS Code (Recommended) VS Code with rust-analyzer provides the best development experience for Rust projects.\nRequired Extensions:\nrust-analyzer – Rust language support (code completion, go-to-definition, inline errors, refactoring) CodeLLDB – Debugger support for Rust Recommended Extensions:\nEven Better TOML – Syntax highlighting for Cargo.toml and other TOML files Error Lens – Inline error display crates – Dependency version management in Cargo.toml GitLens – Enhanced Git integration Workspace Settings (.vscode/settings.json):\n{ \"rust-analyzer.cargo.features\": \"all\", \"rust-analyzer.check.command\": \"clippy\", \"rust-analyzer.check.extraArgs\": [\"--all-targets\"], \"rust-analyzer.procMacro.enable\": true, \"rust-analyzer.cargo.buildScripts.enable\": true, \"rust-analyzer.inlayHints.parameterHints.enable\": true, \"rust-analyzer.inlayHints.typeHints.enable\": true, \"rust-analyzer.lens.run.enable\": true, \"rust-analyzer.lens.debug.enable\": true, \"editor.formatOnSave\": true, \"[rust]\": { \"editor.defaultFormatter\": \"rust-lang.rust-analyzer\" } } Debugging in VS Code:\nCreate a .vscode/launch.json for debugging the server:\n{ \"version\": \"0.2.0\", \"configurations\": [ { \"type\": \"lldb\", \"request\": \"launch\", \"name\": \"Debug thunder-server\", \"cargo\": { \"args\": [\"build\", \"--bin=thunder-server\", \"--package=thunder-server\"], \"filter\": { \"name\": \"thunder-server\", \"kind\": \"bin\" } }, \"args\": [\"--config\", \"config/dev.toml\"], \"cwd\": \"${workspaceFolder}\" }, { \"type\": \"lldb\", \"request\": \"launch\", \"name\": \"Debug Unit Tests\", \"cargo\": { \"args\": [\"test\", \"--no-run\", \"--lib\", \"--package=${input:crate}\"], \"filter\": { \"kind\": \"lib\" } }, \"cwd\": \"${workspaceFolder}\" } ], \"inputs\": [ { \"id\": \"crate\", \"type\": \"pickString\", \"description\": \"Select crate to debug\", \"options\": [ \"thunder-common\", \"thunder-storage\", \"thunder-txn\", \"thunder-sql\", \"thunder-query\", \"thunder-protocol\", \"thunder-api\", \"thunder-server\" ] } ] } IntelliJ IDEA / CLion JetBrains IDEs provide excellent Rust support through the Rust plugin.\nSetup:\nInstall IntelliJ IDEA (Ultimate or Community) or CLion. Install the Rust plugin from the JetBrains Marketplace. Open the ThunderDB root directory as a project. IntelliJ will detect the Cargo.toml workspace and index all crates. Recommended Settings:\nEnable “Expand macros” for proc-macro support Set “Cargo check” to use clippy for enhanced linting Enable “External linter” with cargo clippy Configure run configurations for thunder-server with dev config Neovim For Neovim users, the following setup provides a productive Rust development experience:\nnvim-lspconfig with rust-analyzer nvim-cmp for completion nvim-dap with CodeLLDB for debugging rust-tools.nvim for enhanced Rust integration Docker-Based Development For contributors who prefer containerized development or need to test multi-node clusters, Docker Compose provides a complete environment.\nStarting the Dev Environment docker-compose up This starts:\nA ThunderDB build container with all prerequisites A three-node ThunderDB cluster for integration testing Supporting services (monitoring, log aggregation) Development Inside Docker # Enter the build container docker-compose exec dev bash # Build inside the container cargo build # Run tests inside the container cargo test Multi-Node Cluster Testing # Start a three-node cluster docker-compose --profile cluster up # Connect to node 1 psql -h localhost -p 5432 -U admin -d thunderdb # Connect to node 2 psql -h localhost -p 5433 -U admin -d thunderdb # Connect to node 3 psql -h localhost -p 5434 -U admin -d thunderdb Code Formatting ThunderDB uses cargo fmt with a custom .rustfmt.toml configuration to enforce consistent code style across the entire codebase.\nRunning the Formatter # Format all code cargo fmt # Check formatting without modifying files cargo fmt -- --check The .rustfmt.toml configuration defines the project’s formatting rules. All code must be formatted before committing. The CI pipeline will reject PRs with formatting violations.\nKey Formatting Rules Maximum line width: 100 characters Use block indentation for function arguments Trailing commas in multi-line constructs Group imports by standard library, external crates, and internal crates Linting ThunderDB uses cargo clippy for static analysis and linting.\nRunning Clippy # Run clippy on all crates cargo clippy --all-targets --all-features # Run clippy on a specific crate cargo clippy -p thunder-storage # Run clippy and treat warnings as errors (same as CI) cargo clippy --all-targets --all-features -- -D warnings Clippy warnings must be resolved before merging. If a warning is a false positive, it may be suppressed with an #[allow(...)] attribute and an explanatory comment.\nPre-Commit Hooks ThunderDB provides Git pre-commit hooks to catch common issues before they reach CI.\nInstalling Hooks # Install the pre-commit hooks ./scripts/install-hooks.sh The pre-commit hook runs:\ncargo fmt -- --check – Verify formatting cargo clippy --all-targets -- -D warnings – Check for lint violations cargo test --lib – Run unit tests If any check fails, the commit is rejected with a message explaining what needs to be fixed.\nBypassing Hooks (Emergency Only) In rare cases, you may need to bypass hooks:\ngit commit --no-verify -m \"WIP: work in progress\" This should only be used for work-in-progress commits on feature branches. The CI pipeline enforces the same checks, so any violations will still be caught.\nRunning Individual Crates During development, you often want to work on and test a single crate in isolation:\n# Build a single crate cargo build -p thunder-storage # Test a single crate cargo test -p thunder-storage # Test a single crate with output cargo test -p thunder-storage -- --nocapture # Run clippy on a single crate cargo clippy -p thunder-storage # Check a single crate (faster than build, no codegen) cargo check -p thunder-storage # Generate documentation for a single crate cargo doc -p thunder-storage --open Crate Build Order Due to the dependency graph, crates build in a specific order. The leaf crate thunder-common builds first, followed by crates that depend on it. Understanding this helps you predict build times when modifying specific crates:\nthunder-common (leaf, builds first) | +-- thunder-storage | +-- thunder-txn | +-- thunder-cluster | +-- thunder-cdc | +-- thunder-sql | +-- thunder-query (also depends on storage, txn) | +-- thunder-fdw | +-- thunder-protocol (depends on sql, query, txn) +-- thunder-vector (depends on storage) +-- thunder-client +-- thunder-api (depends on sql, query, protocol, cluster) +-- thunder-server (depends on all, builds last) Changes to thunder-common trigger a rebuild of the entire workspace. Changes to thunder-server only require rebuilding that single crate.\nEnvironment Variables ThunderDB uses several environment variables for development:\nVariable Default Purpose THUNDER_LOG info Log level (trace, debug, info, warn, error) THUNDER_CONFIG config/dev.toml Path to configuration file THUNDER_DATA_DIR ./data Data directory for development RUST_BACKTRACE 0 Set to 1 for backtraces on panic RUST_LOG (unset) Fine-grained logging control (e.g., thunder_storage=debug) Troubleshooting Build Fails with “No Space Left on Device” The target/ directory can grow very large. Clean it periodically:\ncargo clean rust-analyzer Is Slow or Consuming Too Much Memory For large workspaces, configure rust-analyzer to check fewer targets:\n{ \"rust-analyzer.cargo.features\": [], \"rust-analyzer.check.extraArgs\": [\"--target-dir\", \"target/ra\"] } Using a separate target-dir for rust-analyzer prevents it from invalidating your build cache.\nTests Fail with “Address Already in Use” If a previous test run did not clean up properly, ports may still be in use:\n# Find processes using ThunderDB ports lsof -i :5432 -i :3306 -i :6379 -i :8080 # Kill orphaned processes kill $(lsof -t -i :5432) Protobuf Generation Fails Ensure protoc is on your PATH and the version is 3.15+:\nprotoc --version which protoc If you installed protoc via Homebrew on macOS with Apple Silicon, you may need:\nexport PROTOC=$(which protoc) ","categories":"","description":"How to set up your local development environment for ThunderDB, including prerequisites, building, testing, IDE configuration, and development workflows.","excerpt":"How to set up your local development environment for ThunderDB, …","ref":"/docs/docs/contributor/development-setup/","tags":"","title":"Development Setup"},{"body":"Welcome to the ThunderDB documentation. Whether you are a Developer building applications, an Administrator managing deployments, or a Contributor improving ThunderDB itself, you will find comprehensive guides here.\nWho Is This Documentation For? Developers Build applications on ThunderDB using familiar SQL, multiple wire protocols (PostgreSQL, MySQL, Redis), REST/gRPC/GraphQL APIs, and native vector search. Start with the Getting Started guide, explore the SQL Reference, and browse Examples.\nAdministrators Deploy, configure, monitor, and secure ThunderDB in production environments. See Deployment for installation options, Configuration for tuning, and Monitoring for observability.\nContributors Contribute to ThunderDB development. Learn the Codebase Structure, set up your Development Environment, and understand the Testing and Release workflows.\nQuick Navigation Section Description Getting Started Installation, first queries, quick tour Architecture System design, components, data flow Developer Guide SQL, APIs, SDKs, examples Administrator Guide Deployment, config, monitoring, security Contributor Guide Development setup, codebase, testing ","categories":"","description":"Complete documentation for ThunderDB — the distributed HTAP database for the AI era.\n","excerpt":"Complete documentation for ThunderDB — the distributed HTAP database …","ref":"/docs/docs/","tags":"","title":"Documentation"},{"body":"This guide walks you through installing ThunderDB, starting the server, connecting with multiple protocols, running your first SQL queries, performing vector similarity search, setting up Change Data Capture (CDC), and querying external databases through Foreign Data Wrappers (FDW).\nPrerequisites Before you begin, make sure you have one of the following environments ready:\nOption A: Build from Source Requirement Minimum Version Notes Rust toolchain 1.75+ Install via rustup Cargo Bundled with Rust Rust’s package manager CMake 3.20+ Required for native dependency builds Clang / GCC Clang 14+ or GCC 11+ C/C++ compiler for linked libraries OpenSSL 1.1.1+ TLS support (or use vendored-openssl feature) protoc 3.15+ Protocol Buffers compiler for gRPC Git 2.x To clone the repository Option B: Docker Requirement Minimum Version Docker 20.10+ Docker Compose 2.0+ (V2 plugin) Option C: Pre-built Packages Pre-built .deb and .rpm packages are available on the GitHub Releases page for Ubuntu 22.04+, Debian 12+, and RHEL 9+ / Fedora 38+.\nInstallation Method 1: Build from Source Clone the repository and build an optimized release binary:\n# Clone the repository git clone https://github.com/thunderdb/thunderdb.git cd thunderdb # Build a release binary (optimized, may take 5-10 minutes on first build) cargo build --release # The binary is located at: # target/release/thunderdb-server # target/release/thunderdb-cli # (Optional) Install system-wide sudo cp target/release/thunderdb-server /usr/local/bin/ sudo cp target/release/thunderdb-cli /usr/local/bin/ To build with all optional features enabled (vector search, CDC, FDW, full-text search):\ncargo build --release --features \"vector,cdc,fdw,fts\" Method 2: Docker Pull the official image and start a container:\n# Pull the latest image docker pull thunderdb/thunderdb:latest # Run with default settings, exposing all protocol ports docker run -d \\ --name thunderdb \\ -p 5432:5432 \\ -p 3306:3306 \\ -p 6379:6379 \\ -p 8088:8088 \\ -p 9090:9090 \\ -v thunderdb-data:/var/lib/thunderdb \\ thunderdb/thunderdb:latest Method 3: Docker Compose (Recommended for Development) Create a docker-compose.yml file with the full multi-port setup:\nversion: \"3.9\" services: thunderdb: image: thunderdb/thunderdb:latest container_name: thunderdb restart: unless-stopped ports: # PostgreSQL wire protocol - \"5432:5432\" # MySQL wire protocol - \"3306:3306\" # Redis / RESP protocol - \"6379:6379\" # REST / HTTP API - \"8088:8088\" # gRPC API - \"9090:9090\" # Prometheus metrics - \"9100:9100\" volumes: - thunderdb-data:/var/lib/thunderdb - ./thunderdb.toml:/etc/thunderdb/thunderdb.toml:ro environment: THUNDERDB_LOG_LEVEL: info THUNDERDB_DATA_DIR: /var/lib/thunderdb THUNDERDB_ADMIN_PASSWORD: \"${THUNDERDB_ADMIN_PASSWORD:-thunderdb}\" healthcheck: test: [\"CMD\", \"thunderdb-cli\", \"ping\"] interval: 10s timeout: 5s retries: 5 volumes: thunderdb-data: driver: local Start the stack:\ndocker-compose up -d # Check the logs docker-compose logs -f thunderdb Method 4: Debian / Ubuntu Package # Download the latest .deb package curl -LO https://github.com/thunderdb/thunderdb/releases/latest/download/thunderdb_amd64.deb # Install the package sudo dpkg -i thunderdb_amd64.deb # The package installs: # /usr/bin/thunderdb-server # /usr/bin/thunderdb-cli # /etc/thunderdb/thunderdb.toml (default config) # /lib/systemd/system/thunderdb.service # Enable and start the service sudo systemctl enable thunderdb sudo systemctl start thunderdb # Check status sudo systemctl status thunderdb Starting the Server If you built from source, start the server with the default configuration:\n# Start with default settings (listens on all default ports) thunderdb-server # Or specify a custom configuration file thunderdb-server --config /path/to/thunderdb.toml # Or set individual options via CLI flags thunderdb-server \\ --data-dir /var/lib/thunderdb \\ --pg-port 5432 \\ --mysql-port 3306 \\ --redis-port 6379 \\ --http-port 8088 \\ --grpc-port 9090 \\ --log-level info You should see output similar to:\n2026-02-05T10:00:00.000Z INFO thunderdb::server: Starting ThunderDB v0.1.0 2026-02-05T10:00:00.010Z INFO thunderdb::storage: Opening data directory: /var/lib/thunderdb 2026-02-05T10:00:00.050Z INFO thunderdb::protocol::pg: PostgreSQL protocol listening on 0.0.0.0:5432 2026-02-05T10:00:00.051Z INFO thunderdb::protocol::mysql: MySQL protocol listening on 0.0.0.0:3306 2026-02-05T10:00:00.052Z INFO thunderdb::protocol::redis: Redis/RESP protocol listening on 0.0.0.0:6379 2026-02-05T10:00:00.053Z INFO thunderdb::api::http: REST API listening on 0.0.0.0:8088 2026-02-05T10:00:00.054Z INFO thunderdb::api::grpc: gRPC API listening on 0.0.0.0:9090 2026-02-05T10:00:00.055Z INFO thunderdb::server: ThunderDB is ready to accept connections Connecting to ThunderDB ThunderDB speaks multiple wire protocols simultaneously. You can connect with whichever client you prefer.\nConnect via PostgreSQL Protocol (psql) ThunderDB implements the PostgreSQL wire protocol on port 5432 (default). Any PostgreSQL-compatible client or driver works out of the box.\n# Connect using psql psql -h localhost -p 5432 -U thunderdb -d default # You will see: # psql (16.1, server ThunderDB 0.1.0) # Type \"help\" for help. # # default=\u003e If you set a custom admin password, provide it when prompted:\npsql -h localhost -p 5432 -U thunderdb -d default -W Connect via MySQL Protocol (mysql client) ThunderDB implements the MySQL wire protocol on port 3306 (default). Standard MySQL clients and connectors work without modification.\n# Connect using the mysql client mysql -h 127.0.0.1 -P 3306 -u thunderdb -p --database=default # You will see: # Welcome to ThunderDB v0.1.0 (MySQL protocol mode) # Server version: 8.0.32-ThunderDB # # mysql\u003e Connect via Redis Protocol (redis-cli) ThunderDB implements a subset of the Redis/RESP protocol on port 6379 (default). You can use redis-cli or any Redis client library.\n# Connect using redis-cli redis-cli -h localhost -p 6379 # Test the connection 127.0.0.1:6379\u003e PING PONG # Set and get a key 127.0.0.1:6379\u003e SET greeting \"Hello from ThunderDB\" OK 127.0.0.1:6379\u003e GET greeting \"Hello from ThunderDB\" # You can also run SQL through the Redis protocol 127.0.0.1:6379\u003e THUNDERDB.QUERY \"SELECT 1 + 1 AS result\" 1) 1) \"result\" 2) \"2\" Connect via REST API (curl) ThunderDB exposes a REST API on port 8088 (default) for HTTP-based access.\n# Health check curl http://localhost:8088/api/v1/health # {\"status\":\"ok\",\"version\":\"0.1.0\",\"uptime_seconds\":42} # Run a query curl -X POST http://localhost:8088/api/v1/query \\ -H \"Content-Type: application/json\" \\ -d '{\"sql\": \"SELECT 1 + 1 AS result\"}' # Response: # { # \"columns\": [\"result\"], # \"rows\": [[2]], # \"execution_time_ms\": 0.12 # } Your First Queries Now that you are connected, let us create some tables, insert data, and run queries. The examples below use psql, but the SQL is identical across all protocols.\nCreate a Table -- Create a simple users table CREATE TABLE users ( id BIGINT PRIMARY KEY AUTO_INCREMENT, username VARCHAR(255) NOT NULL UNIQUE, email VARCHAR(255) NOT NULL, full_name VARCHAR(255), created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, is_active BOOLEAN DEFAULT TRUE ); -- Create an orders table with a foreign key CREATE TABLE orders ( id BIGINT PRIMARY KEY AUTO_INCREMENT, user_id BIGINT NOT NULL REFERENCES users(id), product VARCHAR(255) NOT NULL, quantity INT NOT NULL DEFAULT 1, price DECIMAL(10, 2) NOT NULL, status VARCHAR(50) DEFAULT 'pending', ordered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); -- Create an index for faster lookups CREATE INDEX idx_orders_user_id ON orders(user_id); CREATE INDEX idx_orders_status ON orders(status); Insert Data -- Insert users INSERT INTO users (username, email, full_name) VALUES ('alice', 'alice@example.com', 'Alice Johnson'), ('bob', 'bob@example.com', 'Bob Smith'), ('charlie', 'charlie@example.com', 'Charlie Brown'), ('diana', 'diana@example.com', 'Diana Prince'), ('eve', 'eve@example.com', 'Eve Wilson'); -- Insert orders INSERT INTO orders (user_id, product, quantity, price, status) VALUES (1, 'Mechanical Keyboard', 1, 149.99, 'shipped'), (1, 'USB-C Hub', 2, 39.99, 'delivered'), (2, '27\" Monitor', 1, 449.99, 'pending'), (3, 'Wireless Mouse', 1, 29.99, 'shipped'), (3, 'Laptop Stand', 1, 59.99, 'delivered'), (4, 'Webcam HD', 1, 79.99, 'pending'), (5, 'Noise-Cancel Headset', 1, 199.99, 'shipped'); Query Data (OLTP) -- Simple SELECT SELECT * FROM users WHERE is_active = TRUE; -- JOIN query SELECT u.username, u.full_name, o.product, o.price, o.status FROM users u JOIN orders o ON u.id = o.user_id WHERE o.status = 'shipped' ORDER BY o.price DESC; -- Result: -- +----------+---------------+------------------------+--------+---------+ -- | username | full_name | product | price | status | -- +----------+---------------+------------------------+--------+---------+ -- | eve | Eve Wilson | Noise-Cancel Headset | 199.99 | shipped | -- | alice | Alice Johnson | Mechanical Keyboard | 149.99 | shipped | -- | charlie | Charlie Brown | Wireless Mouse | 29.99 | shipped | -- +----------+---------------+------------------------+--------+---------+ Analytical Queries (OLAP) ThunderDB handles analytical workloads in the same engine. Queries that scan large volumes of data automatically use the columnar store and vectorized execution.\n-- Revenue by user SELECT u.username, COUNT(o.id) AS total_orders, SUM(o.price * o.quantity) AS total_spent, AVG(o.price) AS avg_order_value FROM users u JOIN orders o ON u.id = o.user_id GROUP BY u.username ORDER BY total_spent DESC; -- Result: -- +----------+--------------+-------------+-----------------+ -- | username | total_orders | total_spent | avg_order_value | -- +----------+--------------+-------------+-----------------+ -- | bob | 1 | 449.99 | 449.99 | -- | alice | 2 | 229.97 | 94.99 | -- | eve | 1 | 199.99 | 199.99 | -- | charlie | 2 | 89.98 | 44.99 | -- | diana | 1 | 79.99 | 79.99 | -- +----------+--------------+-------------+-----------------+ -- Order status distribution SELECT status, COUNT(*) AS order_count, SUM(price * quantity) AS total_revenue, ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 2) AS pct FROM orders GROUP BY status ORDER BY order_count DESC; Vector Search ThunderDB has built-in support for vector embeddings and similarity search, making it ideal for AI/ML workloads, RAG pipelines, and semantic search.\nCreate a Vector Table -- Create a documents table with a 384-dimensional embedding column CREATE TABLE documents ( id BIGINT PRIMARY KEY AUTO_INCREMENT, title VARCHAR(512) NOT NULL, content TEXT, embedding VECTOR(384) NOT NULL, metadata JSONB ); -- Create an HNSW index for fast approximate nearest-neighbor search CREATE INDEX idx_documents_embedding ON documents USING HNSW (embedding vector_cosine_ops) WITH (m = 16, ef_construction = 200); Insert Vector Data -- Insert documents with embeddings (truncated for readability) -- In practice, embeddings come from a model like sentence-transformers INSERT INTO documents (title, content, embedding, metadata) VALUES ( 'Introduction to ThunderDB', 'ThunderDB is a distributed HTAP database written in Rust...', '[0.12, -0.03, 0.88, 0.45, ...]'::VECTOR(384), '{\"category\": \"database\", \"author\": \"docs-team\"}' ), ( 'Vector Search Tutorial', 'Learn how to use vector similarity search in ThunderDB...', '[0.09, 0.77, -0.12, 0.33, ...]'::VECTOR(384), '{\"category\": \"tutorial\", \"author\": \"docs-team\"}' ), ( 'Rust Performance Guide', 'Understanding zero-cost abstractions and memory safety...', '[0.55, 0.01, 0.34, -0.22, ...]'::VECTOR(384), '{\"category\": \"programming\", \"author\": \"community\"}' ); Similarity Search -- Find the 5 most similar documents to a query vector -- using cosine distance SELECT id, title, content, embedding \u003c=\u003e '[0.10, 0.75, -0.08, 0.30, ...]'::VECTOR(384) AS distance FROM documents ORDER BY embedding \u003c=\u003e '[0.10, 0.75, -0.08, 0.30, ...]'::VECTOR(384) LIMIT 5; -- Result: -- +----+----------------------------+------------------------------------------+----------+ -- | id | title | content | distance | -- +----+----------------------------+------------------------------------------+----------+ -- | 2 | Vector Search Tutorial | Learn how to use vector similarity se... | 0.0312 | -- | 1 | Introduction to ThunderDB | ThunderDB is a distributed HTAP data... | 0.2145 | -- | 3 | Rust Performance Guide | Understanding zero-cost abstractions... | 0.5678 | -- +----+----------------------------+------------------------------------------+----------+ -- Filtered similarity search with metadata SELECT title, embedding \u003c=\u003e '[0.10, 0.75, -0.08, 0.30, ...]'::VECTOR(384) AS distance FROM documents WHERE metadata-\u003e\u003e'category' = 'tutorial' ORDER BY embedding \u003c=\u003e '[0.10, 0.75, -0.08, 0.30, ...]'::VECTOR(384) LIMIT 10; Vector Search via REST API curl -X POST http://localhost:8088/api/v1/query \\ -H \"Content-Type: application/json\" \\ -d '{ \"sql\": \"SELECT title, embedding \u003c=\u003e $1::VECTOR(384) AS distance FROM documents ORDER BY distance LIMIT 5\", \"params\": [\"[0.10, 0.75, -0.08, 0.30, ...]\"] }' Change Data Capture (CDC) ThunderDB can act as a CDC consumer, continuously replicating data from external databases into ThunderDB. This lets you add HTAP and vector search capabilities on top of your existing primary database without modifying your application.\nSync from an External PostgreSQL First, ensure the source PostgreSQL instance has logical replication enabled:\n# In postgresql.conf on the source database wal_level = logical max_replication_slots = 4 max_wal_senders = 4 Then, in ThunderDB, create a CDC subscription:\n-- Create a CDC source pointing to the external PostgreSQL CREATE CDC SOURCE pg_source TYPE POSTGRES CONNECTION 'host=pg-primary.example.com port=5432 dbname=myapp user=replicator password=secret' PUBLICATION 'thunderdb_pub'; -- Create a subscription that syncs specific tables CREATE CDC SUBSCRIPTION sync_users FROM SOURCE pg_source TABLES (public.users, public.orders) INTO SCHEMA synced WITH ( snapshot = TRUE, -- initial full snapshot slot_name = 'thunderdb_slot', create_slot = TRUE ); -- Check subscription status SELECT * FROM thunderdb_cdc.subscriptions; -- +------------+-----------+--------+------------------+---------------------+ -- | name | source | status | tables | last_lsn | -- +------------+-----------+--------+------------------+---------------------+ -- | sync_users | pg_source | active | users, orders | 0/16B3748 | -- +------------+-----------+--------+------------------+---------------------+ -- Query the synced data — it stays up-to-date in near real-time SELECT * FROM synced.users LIMIT 5; Monitoring CDC Lag -- Check replication lag SELECT subscription_name, source_lsn, applied_lsn, lag_bytes, lag_seconds FROM thunderdb_cdc.replication_status; Foreign Data Wrappers (FDW) ThunderDB supports Foreign Data Wrappers that let you query external databases directly from ThunderDB SQL, without copying data. This is useful for ad-hoc cross-database joins and federation.\nQuery an External MySQL Database -- Create a foreign server definition CREATE FOREIGN SERVER mysql_erp TYPE MYSQL OPTIONS ( host 'mysql-erp.example.com', port '3306', database 'erp' ); -- Create user mapping for authentication CREATE USER MAPPING FOR thunderdb SERVER mysql_erp OPTIONS ( username 'readonly_user', password 'secret' ); -- Import foreign tables from the remote schema IMPORT FOREIGN SCHEMA erp FROM SERVER mysql_erp INTO SCHEMA erp_remote; -- Now query the remote MySQL tables as if they were local SELECT p.product_name, p.sku, p.price FROM erp_remote.products p WHERE p.category = 'Electronics' ORDER BY p.price DESC LIMIT 10; -- Cross-database JOIN: local ThunderDB table + remote MySQL table SELECT o.id AS order_id, o.product, o.price AS our_price, rp.price AS erp_price, o.price - rp.price AS price_diff FROM orders o JOIN erp_remote.products rp ON o.product = rp.product_name ORDER BY price_diff DESC; Query an External PostgreSQL Database via FDW CREATE FOREIGN SERVER pg_analytics TYPE POSTGRES OPTIONS ( host 'pg-analytics.example.com', port '5432', database 'analytics' ); CREATE USER MAPPING FOR thunderdb SERVER pg_analytics OPTIONS ( username 'reader', password 'secret' ); IMPORT FOREIGN SCHEMA public FROM SERVER pg_analytics INTO SCHEMA analytics_remote; -- Federated query across ThunderDB local data and remote PostgreSQL SELECT u.username, a.page_views, a.session_duration_avg FROM users u JOIN analytics_remote.user_analytics a ON u.id = a.user_id WHERE a.page_views \u003e 100 ORDER BY a.page_views DESC; Docker Compose: Full Multi-Protocol Example Here is a complete docker-compose.yml that sets up ThunderDB alongside a source PostgreSQL (for CDC) and a source MySQL (for FDW), demonstrating the full integration capabilities:\nversion: \"3.9\" services: # ── ThunderDB ────────────────────────────────────────────── thunderdb: image: thunderdb/thunderdb:latest container_name: thunderdb restart: unless-stopped ports: - \"5432:5432\" # PostgreSQL protocol - \"3306:3306\" # MySQL protocol - \"6379:6379\" # Redis / RESP protocol - \"8088:8088\" # REST API - \"9090:9090\" # gRPC API - \"9100:9100\" # Prometheus metrics volumes: - thunderdb-data:/var/lib/thunderdb environment: THUNDERDB_LOG_LEVEL: info THUNDERDB_ADMIN_PASSWORD: thunderdb depends_on: pg-source: condition: service_healthy mysql-source: condition: service_healthy healthcheck: test: [\"CMD\", \"thunderdb-cli\", \"ping\"] interval: 10s timeout: 5s retries: 5 # ── Source PostgreSQL (for CDC demo) ─────────────────────── pg-source: image: postgres:16 container_name: pg-source restart: unless-stopped ports: - \"5433:5432\" environment: POSTGRES_USER: appuser POSTGRES_PASSWORD: appsecret POSTGRES_DB: myapp command: - \"postgres\" - \"-c\" - \"wal_level=logical\" - \"-c\" - \"max_replication_slots=4\" - \"-c\" - \"max_wal_senders=4\" healthcheck: test: [\"CMD-SHELL\", \"pg_isready -U appuser -d myapp\"] interval: 5s timeout: 3s retries: 5 # ── Source MySQL (for FDW demo) ──────────────────────────── mysql-source: image: mysql:8.0 container_name: mysql-source restart: unless-stopped ports: - \"3307:3306\" environment: MYSQL_ROOT_PASSWORD: rootsecret MYSQL_DATABASE: erp MYSQL_USER: readonly_user MYSQL_PASSWORD: secret healthcheck: test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\"] interval: 5s timeout: 3s retries: 5 volumes: thunderdb-data: driver: local Start everything:\n# Start the full stack docker-compose up -d # Wait for all services to be healthy docker-compose ps # Connect to ThunderDB via psql psql -h localhost -p 5432 -U thunderdb -d default # Connect to ThunderDB via mysql client mysql -h 127.0.0.1 -P 3306 -u thunderdb -p --database=default # Connect to ThunderDB via redis-cli redis-cli -h localhost -p 6379 # Hit the REST API curl http://localhost:8088/api/v1/health Verifying Your Installation Run the built-in self-check to make sure everything is working:\n# Using the CLI tool thunderdb-cli doctor # Expected output: # [OK] Storage engine initialized # [OK] PostgreSQL protocol on :5432 # [OK] MySQL protocol on :3306 # [OK] Redis protocol on :6379 # [OK] REST API on :8088 # [OK] gRPC API on :9090 # [OK] Vector index support available # [OK] CDC module loaded # [OK] FDW module loaded # All checks passed. Or via SQL:\n-- Show server version and build info SELECT thunderdb_version(); -- ThunderDB 0.1.0 (rustc 1.78.0, release, linux-x86_64) -- Show enabled features SELECT * FROM thunderdb_features(); -- +----------------+---------+ -- | feature | enabled | -- +----------------+---------+ -- | vector_search | true | -- | cdc | true | -- | fdw | true | -- | full_text | true | -- | columnar_store | true | -- +----------------+---------+ Next Steps Now that you have ThunderDB running and have executed your first queries, explore the rest of the documentation:\nArchitecture – Understand how ThunderDB’s distributed engine, storage layers, consensus protocol, and query optimizer work together. SQL Reference – Complete reference for all supported SQL statements, data types, functions, and operators. API Reference – REST, gRPC, GraphQL, and WebSocket API documentation with request/response examples. SDK Guide – Client libraries for Python, Go, Java, Node.js, and Rust with code samples. Configuration – Tune ThunderDB for your workload with detailed configuration reference. Deployment – Production deployment guides for Kubernetes, bare-metal, and cloud-managed environments. Monitoring – Set up Prometheus metrics, Grafana dashboards, and alerting for your ThunderDB cluster. Examples – End-to-end application examples including RAG pipelines, real-time dashboards, and multi-protocol microservices. ","categories":"","description":"Get ThunderDB up and running in minutes. Install, connect, and run your first queries.\n","excerpt":"Get ThunderDB up and running in minutes. Install, connect, and run …","ref":"/docs/docs/getting-started/","tags":"","title":"Getting Started"},{"body":"1. System Overview ThunderDB is a distributed Hybrid Transactional/Analytical Processing (HTAP) database written entirely in Rust. The codebase spans approximately 75,600 lines of code organized across 14 crates, each responsible for a distinct subsystem. ThunderDB is designed to serve both OLTP and OLAP workloads from a single system, eliminating the need for separate databases and the ETL pipelines that connect them.\nThe system follows a layered architecture where each layer has well-defined responsibilities and communicates with adjacent layers through clean interfaces. The following diagram illustrates the complete stack:\n+===========================================================================+ | CLIENT LAYER | | +------------------+ +------------------+ +-------------------------+ | | | PostgreSQL/MySQL | | Native Driver | | MCP (Model Context | | | | Compatible Tools | | (Rust Client) | | Protocol) | | | +--------+---------+ +--------+---------+ +------------+------------+ | +===========|======================|=========================|==============+ | | | +===========v======================v=========================v==============+ | PROTOCOL LAYER | | +----------------+ +----------------+ +-----------+ +------------------+ | | | PostgreSQL v3 | | MySQL 4.1+ | | RESP2/3 | | Session Mgmt | | | | Wire Protocol | | Wire Protocol | | (Redis) | | Auth \u0026 TLS | | | | (54KB) | | (36KB) | | (105KB) | | (41KB) | | | +-------+--------+ +-------+--------+ +-----+-----+ +--------+--------+ | +=========================================================================--+ | | | | +===========v======================v================v==============v========+ | API LAYER | | +----------+ +----------+ +-----------+ +------------+ +---------------+ | | | REST | | gRPC | | GraphQL | | WebSocket | | Web Dashboard | | | | (axum) | | (tonic) | | (async- | | (live | | (40KB) | | | | | | | | graphql) | | queries) | | | | | +----+-----+ +----+-----+ +-----+-----+ +-----+------+ +------+-------+ | +=======|============|==============|=============|===============|=========+ | | | | | +=======v============v==============v=============v===============v=========+ | INTEGRATION LAYER | | +-----------------------------------+ +--------------------------------+ | | | CDC (Change Data Capture) | | FDW (Foreign Data Wrappers) | | | | - PostgreSQL (logical repl.) | | - Query external PostgreSQL | | | | - MySQL (binlog) | | - Query external MySQL | | | | - MongoDB (change streams) | | - Query external MongoDB | | | | - Redis (keyspace notifications) | | - Query external Redis | | | +-----------------------------------+ | - Predicate pushdown | | | +--------------------------------+ | +===========================================================================+ | | +===========v==========================================v====================+ | SQL LAYER | | +----------+ +-----------+ +-----------+ +----------+ +-----------+ | | | Parser | | Analyzer | | Optimizer | | Planner | | NLP / LLM | | | | (sqlpar- | | (semantic | | (cost- | | (logical | | (llama. | | | | ser) | | valid.) | | based) | | -\u003e phys)| | cpp) | | | +----+-----+ +-----+-----+ +-----+-----+ +----+-----+ +-----+-----+ | +=======|==============|===============|==============|==============|======+ | | | | | +=======v==============v===============v==============v==============v======+ | EXECUTION LAYER | | +------------------------+ +---------------------+ +-------------------+ | | | Vectorized Execution | | Parallel Execution | | Physical Plan | | | | (33KB, 1024+ batches) | | (35KB, multi-thread)| | Operators (38KB) | | | +------------------------+ +---------------------+ +-------------------+ | +===========================================================================+ | +===========v===============================================================+ | TRANSACTION LAYER | | +---------+ +----------+ +----------+ +-------------+ +---------------+ | | | MVCC | | CCP | | 2PC | | Deadlock | | Lock Manager | | | | Snapshot | | Optimis- | | Distrib. | | Detection | | (row/table/ | | | | Isolat. | | tic CC | | Coord. | | (wait-for) | | intent) | | | +---------+ +----------+ +----------+ +-------------+ +---------------+ | +===========================================================================+ | +===========v===============================================================+ | STORAGE LAYER | | +-----------+ +------------+ +-------------+ +-----------+ +-----------+ | | | Row Store | | Column | | Vector | | Buffer | | WAL | | | | (OLTP) | | Store | | Store | | Pool | | (ARIES) | | | | | | (OLAP) | | (HNSW/IVF) | | (LRU) | | | | | +-----------+ +------------+ +-------------+ +-----------+ +-----------+ | | +-----------+ +--------------+ +--------------------+ | | | B+Tree | | Page Manager | | Compression | | | | Indexes | | (16KB pages) | | (LZ4/Snappy/Zstd) | | | +-----------+ +--------------+ +--------------------+ | +===========================================================================+ | +===========v===============================================================+ | CLUSTER LAYER | | +----------+ +-------------+ +-------------+ +-----------+ +-----------+ | | | Raft | | Region- | | Replication | | Auto- | | gRPC | | | | Consen- | | Based | | (config. | | Rebalance | | Transport | | | | sus | | Sharding | | factor) | | | | | | | +----------+ +-------------+ +-------------+ +-----------+ +-----------+ | +===========================================================================+ 2. Crate Architecture ThunderDB is organized into 14 Rust crates within a Cargo workspace. Each crate encapsulates a distinct subsystem with explicit dependency boundaries. This modularity allows independent development, testing, and potential future extraction of components.\nCrate Purpose Key Details thunder-common Shared types and infrastructure DatabaseId, TableId, ColumnId, RowId, PageId, TxnId, and other strongly-typed identifiers. Configuration management, error hierarchy, RBAC (role-based access control), audit logging, and metrics collection (Prometheus-compatible). thunder-storage Storage engine WAL with ARIES-style recovery (67KB), flash-optimized B+Tree with 256+ fanout (29KB), LRU buffer pool, row store, column store, compression (LZ4, Snappy, Zstd, RLE, Delta, Dictionary encoding), and page management with 16KB pages. thunder-txn Transaction management MVCC snapshot isolation, CCP (Cooperative Concurrency Protocol) for optimistic concurrency, 2PC distributed transaction coordinator, hierarchical lock manager, and wait-for graph deadlock detection. thunder-sql SQL processing PostgreSQL dialect parser via sqlparser crate, semantic analyzer, cost-based optimizer with rule transformations, logical and physical planner, NLP integration (38KB), LLM integration via llama.cpp (23KB), ML operations (28KB), UDF support, multi-dialect support (45KB). thunder-query Query execution Executor engine (60KB), physical plan operators (38KB), vectorized execution with 1024+ row batches (33KB), parallel execution across multiple threads (35KB). thunder-cluster Distributed clustering Raft consensus protocol, region-based sharding with range partitioning, membership management, health checking via heartbeats, configurable replication, gRPC-based inter-node transport. thunder-protocol Wire protocols PostgreSQL v3 extended query protocol (54KB), MySQL 4.1+ binary protocol (36KB), RESP2/3 Redis protocol (105KB), session management (41KB), authentication (MD5, SCRAM-SHA-256, MySQL native password), TLS termination. thunder-vector Vector indexing HNSW (Hierarchical Navigable Small World) and IVF (Inverted File Index) algorithms, multiple distance metrics (L2, cosine, inner product), scalar/product quantization, SIMD acceleration via simsimd. thunder-api API servers REST via axum, gRPC via tonic, GraphQL via async-graphql, WebSocket for live query subscriptions, embedded web dashboard (40KB), JWT/API-key authentication, token-bucket rate limiting. thunder-cdc Change Data Capture PostgreSQL logical replication decoding, MySQL binlog parsing, MongoDB change stream consumption, Redis keyspace notification listeners. Real-time ingestion from external sources. thunder-fdw Foreign Data Wrappers Query federation across external PostgreSQL, MySQL, MongoDB, and Redis instances. Supports predicate pushdown, projection pruning, and cost estimation for remote tables. thunder-server Main server binary Engine coordination, background workers (vacuum, checkpoint, statistics collection, region balancing), signal handling, graceful shutdown orchestration. thunder-client Native Rust client Async connection pool (bb8-based), prepared statement caching, transaction helpers, automatic retry with exponential backoff, connection health monitoring. Dependency Graph thunder-server +-- thunder-api | +-- thunder-sql | +-- thunder-query | +-- thunder-common +-- thunder-protocol | +-- thunder-sql | +-- thunder-common +-- thunder-sql | +-- thunder-query | +-- thunder-txn | +-- thunder-common +-- thunder-query | +-- thunder-storage | +-- thunder-txn | +-- thunder-vector | +-- thunder-common +-- thunder-txn | +-- thunder-storage | +-- thunder-common +-- thunder-storage | +-- thunder-common +-- thunder-cluster | +-- thunder-storage | +-- thunder-txn | +-- thunder-common +-- thunder-cdc | +-- thunder-storage | +-- thunder-common +-- thunder-fdw | +-- thunder-sql | +-- thunder-common +-- thunder-vector +-- thunder-storage +-- thunder-common 3. Storage Engine The storage engine is the foundation of ThunderDB, responsible for durable, efficient data storage and retrieval. It implements a page-based architecture with both row-oriented and column-oriented storage, unified through the fractured mirror design.\n3.1 Page-Based Storage All data in ThunderDB is organized into fixed-size 16KB (16,384 byte) pages. Using a fixed page size simplifies buffer pool management, aligns with common OS page sizes and SSD block sizes, and allows direct I/O.\nPage Header Format (25 bytes):\n+----------+----------+------+----------+----------------+------------+ | PageId | LSN | Type | Checksum | Free Space Ptr | Slot Count | | (8B) | (8B) | (1B) | (4B) | (2B) | (2B) | +----------+----------+------+----------+----------------+------------+ 0 8 16 17 21 23 25 PageId (8 bytes) - Unique identifier for the page within the tablespace LSN (8 bytes) - Log Sequence Number of the last modification Type (1 byte) - Page type: 0x01=Data, 0x02=Index, 0x03=Overflow, 0x04=FreeSpaceMap, 0x05=ColumnSegment Checksum (4 bytes) - CRC32 checksum of the page contents for corruption detection Free Space Ptr (2 bytes) - Offset to the start of free space within the page Slot Count (2 bytes) - Number of active slots (row pointers) in the page 3.2 Row Store (OLTP-Optimized) The row store is the primary storage format for transactional workloads. It uses a slotted page layout where each page contains a header, a slot directory growing forward, and tuple data growing backward.\n+-----------------------------------------------------------------------+ | Page Header (25B) | +-----------------------------------------------------------------------+ | Slot 0 | Slot 1 | Slot 2 | ... | Slot N | ---\u003e free space \u003c--- | | (off, | (off, | (off, | | (off, | | | len, | len, | len, | | len, | | | flags)| flags)| flags)| | flags)| | +-----------------------------------------------------------------------+ | FREE SPACE | +-----------------------------------------------------------------------+ | Tuple N | ... | Tuple 2 | Tuple 1 | Tuple 0 | | | (data) | | (data) | (data) | (data) | | +-----------------------------------------------------------------------+ Each slot directory entry is 6 bytes: offset (2B) + length (2B) + flags (2B). Flags encode the tuple’s visibility and state.\nTuple Header (per row):\nField Size Description xmin 8B Transaction ID that created this tuple version xmax 8B Transaction ID that deleted/updated this tuple (0 if alive) t_ctid 6B Current tuple ID (page + slot), points to newer version on update t_infomask 2B Visibility flags, null bitmap indicator, HOT update flag t_hoff 1B Offset to user data (accounts for null bitmap) Key operations:\nIn-place update: When possible (same-size or smaller tuple), the row is updated directly in the same slot, avoiding HOT chain creation. Tombstone deletion: Rather than physically removing data, xmax is set to the deleting transaction’s ID. The tuple becomes invisible to new snapshots. Free space map (FSM): A secondary structure tracks free space per page, enabling efficient insertion without scanning every page. Vacuum: Background process reclaims space from dead tuples (those invisible to all active transactions), compacts pages, and updates the FSM. 3.3 Column Store (OLAP-Optimized) The column store is designed for analytical queries that scan large numbers of rows but only a few columns. Data is organized into column segments, each storing values for a single column of a row group.\n+----------------------------------------------------------------------+ | Column Segment Header | | - Column ID, Row Group ID, Row Count, Compression Type | | - Min/Max values (zone map), Null Count, Distinct Count | +----------------------------------------------------------------------+ | Null Bitmap (1 bit per row, RLE-compressed) | +----------------------------------------------------------------------+ | Compressed Data | | (LZ4 / Snappy / Zstd / RLE / Delta / Dictionary) | +----------------------------------------------------------------------+ | Optional: Dictionary Page (for dictionary encoding) | +----------------------------------------------------------------------+ Compression strategies are chosen automatically based on column statistics:\nStrategy Best For Ratio LZ4 General purpose, fast decompression 2-4x Snappy Low-latency reads 1.5-3x Zstd High compression archival data 3-10x RLE (Run-Length Encoding) Low cardinality, sorted columns 10-100x Delta Encoding Timestamps, sequential integers 5-20x Dictionary Encoding String columns with \u003c 64K distinct values 3-15x Column statistics (zone maps) are maintained per segment and include min/max values, null count, and distinct count. These allow the query engine to skip entire segments during scans (segment elimination).\n3.4 Fractured Mirror (HTAP Design) ThunderDB achieves HTAP by maintaining both row-oriented and column-oriented copies of data through a fractured mirror architecture. This avoids the traditional approach of ETL pipelines between separate OLTP and OLAP systems.\n+------ WRITE PATH ------+ | | v | +-----------+ | | Row Store | \u003c-- primary | | (OLTP) | for writes | +-----+-----+ | | | async propagation | (background worker) | | | v | +--------------+ | | Column Store | \u003c-- derived | | (OLAP) | from rows | +--------------+ | | OLTP queries ---\u003e Row Store (latest data) | OLAP queries ---\u003e Column Store (near-real-time, seconds of lag) Propagation mechanism:\nWrites always go to the row store first (the source of truth for transactions). A background worker reads committed changes from the WAL. Changes are batched into row groups (typically 64K-128K rows). Row groups are compressed column-by-column and written to the column store. Column statistics (zone maps) are updated. The propagation LSN is advanced, allowing old WAL segments to be recycled. Consistency guarantee: The column store may lag behind the row store by a small window (typically seconds). OLAP queries that require absolute freshness can opt to fall back to the row store or merge results from both stores.\n3.5 B+Tree Indexes ThunderDB uses flash-optimized B+Tree indexes with a high fanout of 256+ keys per node, minimizing tree height and random I/O on SSDs.\n+------------------+ | Root Node | | [K50 | K150] | +--/-------|---\\---+ / | \\ +-----------+ +-------+-----+ +------------+ | Internal | | Internal | | Internal | | [K10|K30] | | [K80|K120] | | [K180|K220]| +--/---|--\\-+ +--/---|---\\--+ +--/---|---\\-+ / | \\ / | \\ / | \\ +--+ +--+ +--+ +--+ +--+ +--+ +--+ +--+ +--+ |L1| |L2| |L3| |L4| |L5| |L6| |L7| |L8| |L9| +--+-+--+-+--+--+--+-+--+--+--+--+--+-+--+--+--+ \u003c-\u003e \u003c-\u003e \u003c-\u003e \u003c-\u003e \u003c-\u003e \u003c-\u003e \u003c-\u003e \u003c-\u003e \u003c-\u003e Doubly-linked leaf node chain Key features:\nHigh fanout (256+): Reduces tree height to 2-3 levels for most datasets, meaning most lookups require at most 2-3 page reads. Linked leaf nodes: Enable efficient range scans by following sibling pointers without traversing back up the tree. Latch coupling (crabbing): Concurrent access uses a top-down latch coupling protocol: acquire child latch before releasing parent latch, ensuring structural consistency without holding the root latch during the entire operation. Prefix compression: Common key prefixes within a node are stored once, increasing the effective fanout for string keys. Bulk loading: Sorted data can be loaded bottom-up, constructing the tree from leaf level to root for optimal space utilization and minimal I/O. 3.6 Buffer Pool The buffer pool is an in-memory cache of disk pages that sits between the execution engine and the file system. All page accesses go through the buffer pool.\n+---------------------------------------------------------------------+ | Buffer Pool | | +--------+ +--------+ +--------+ +--------+ +--------+ | | | Frame | | Frame | | Frame | | Frame | | Frame | ... | | | Page:5 | | Page:12| | Page:3 | | Page:42| | Page:7 | | | | Pin:2 | | Pin:0 | | Pin:1 | | Pin:0 | | Pin:3 | | | | Dirty:N| | Dirty:Y| | Dirty:N| | Dirty:Y| | Dirty:N| | | +--------+ +--------+ +--------+ +--------+ +--------+ | | | | Page Table (HashMap\u003cPageId, FrameId\u003e) | | LRU List: [Frame 1] \u003c-\u003e [Frame 3] \u003c-\u003e ... \u003c-\u003e [Frame N] | | Free List: [Frame 6, Frame 9, ...] | +---------------------------------------------------------------------+ Property Description Eviction Policy LRU (Least Recently Used); pinned pages are never evicted Page Pinning Reference-counted; a page is pinned while any thread holds a reference Dirty Tracking Pages modified in memory are marked dirty; flushed on eviction or checkpoint Configurable Size Default 256MB; tunable via buffer_pool_size in configuration Pre-fetching Sequential scan detection triggers asynchronous pre-fetch of upcoming pages 3.7 WAL (Write-Ahead Log) The WAL implements ARIES-style (Algorithm for Recovery and Isolation Exploiting Semantics) recovery to guarantee durability and atomicity. Every modification is first recorded in the WAL before being applied to data pages.\nWAL Record Types:\nRecord Type Code Description BeginTxn 0x01 Transaction started Insert 0x02 Row inserted (contains full tuple) Update 0x03 Row updated (contains before/after images) Delete 0x04 Row deleted (contains before image) Commit 0x05 Transaction committed Abort 0x06 Transaction aborted Checkpoint 0x07 Fuzzy checkpoint marker with dirty page table and active txn table CLR 0x08 Compensation Log Record (undo of an undo, prevents repeated undo) PageSplit 0x09 B+Tree page split operation PageMerge 0x0A B+Tree page merge operation CreateTable 0x0B DDL: table creation DropTable 0x0C DDL: table deletion WAL file structure:\nWAL Directory +-- segment_000000000001.wal (64MB) +-- segment_000000000002.wal (64MB) +-- segment_000000000003.wal (64MB, active) +-- checkpoint.meta Each segment: +---------------------------------------------------------------+ | Segment Header: magic(4B), version(2B), segment_id(8B) | +---------------------------------------------------------------+ | Record 1: LSN(8B) | TxnId(8B) | Type(1B) | Len(4B) | Data | | Record 2: LSN(8B) | TxnId(8B) | Type(1B) | Len(4B) | Data | | ... | +---------------------------------------------------------------+ Group commit: Multiple transactions waiting to commit are batched into a single fsync call, amortizing the cost of durable writes across many transactions. This dramatically improves throughput under concurrent workloads.\nThree-Phase Recovery:\nAnalysis Phase: Scan the WAL forward from the last checkpoint. Reconstruct the dirty page table (which pages had uncommitted modifications) and the active transaction table (which transactions were in-flight).\nRedo Phase: Scan the WAL forward again, re-applying all logged operations to bring pages up to date. For each record, compare the page’s LSN with the record’s LSN; skip if the page is already current. This restores the database to its exact state at the moment of the crash.\nUndo Phase: Scan the WAL backward, undoing all operations from transactions that were active (uncommitted) at crash time. CLR records are written during undo to ensure idempotency if the system crashes again during recovery.\n4. Transaction Processing 4.1 MVCC (Multi-Version Concurrency Control) ThunderDB implements MVCC to provide lock-free reads. Each row may have multiple versions, identified by xmin (creating transaction) and xmax (deleting transaction). A read transaction takes a snapshot at its start time and sees only versions committed before that snapshot.\nSnapshot at T=100 sees: Version 1: xmin=50 xmax=80 -\u003e INVISIBLE (deleted before snapshot) Version 2: xmin=80 xmax=0 -\u003e VISIBLE (created before snapshot, not deleted) Version 3: xmin=110 xmax=0 -\u003e INVISIBLE (created after snapshot) Visibility rules (simplified):\nA tuple is visible if xmin is committed AND xmin \u003c snapshot_txn_id AND (xmax is zero OR xmax is not committed OR xmax \u003e snapshot_txn_id). 4.2 CCP (Cooperative Concurrency Protocol) For write-write conflicts, ThunderDB implements an optimistic concurrency control protocol called CCP. Transactions proceed without acquiring locks during their execution phase. At commit time, a validation phase checks whether any read-write or write-write conflicts occurred.\nCCP phases:\nRead Phase: Transaction reads from its snapshot and writes to a private workspace. Validation Phase: At commit time, check if any tuple read by this transaction was modified by a concurrent committed transaction. Write Phase: If validation succeeds, apply all writes atomically. If it fails, abort and retry. 4.3 Distributed Transactions (2PC) For transactions that span multiple nodes (regions), ThunderDB uses Two-Phase Commit (2PC) with an elected coordinator.\nCoordinator Participant A Participant B | | | |--- PREPARE --------------\u003e| | |--- PREPARE ----------------------------------------\u003e| | | | |\u003c-- VOTE YES --------------| | |\u003c-- VOTE YES ----------------------------------------| | | | |--- COMMIT ---------------\u003e| | |--- COMMIT -----------------------------------------\u003e| | | | |\u003c-- ACK -------------------| | |\u003c-- ACK --------------------------------------------| Failure handling:\nIf any participant votes NO, the coordinator sends ABORT to all. If the coordinator crashes after PREPARE but before COMMIT, participants hold locks until the coordinator recovers (or a new coordinator is elected via Raft). WAL records are written at each phase boundary for crash recovery. 4.4 Deadlock Detection The lock manager maintains a wait-for graph where nodes represent transactions and edges represent “waits for” relationships. A background thread periodically traverses this graph looking for cycles.\nVictim selection criteria (in priority order):\nTransaction with the least amount of work done (fewest WAL records). Transaction that holds the fewest locks. Youngest transaction (highest TxnId). 4.5 Isolation Levels Level Dirty Read Non-Repeatable Read Phantom Implementation Read Committed No Possible Possible New snapshot per statement Repeatable Read No No Possible Single snapshot for entire transaction Serializable No No No Snapshot + predicate locks (SSI) 4.6 TxnId Format Transaction IDs are 64-bit values with embedded metadata for distributed coordination:\n+---------------------------------------------------+----------+----------+ | Timestamp (48 bits) | Node ID | Sequence | | Milliseconds since epoch | (8 bits) | (8 bits) | +---------------------------------------------------+----------+----------+ 63 16 15 8 7 0 - 48-bit timestamp: ~8,900 years of unique timestamps - 8-bit node ID: Up to 256 nodes in the cluster - 8-bit sequence: Up to 256 transactions per millisecond per node This format allows global ordering of transactions without centralized coordination. Any node can generate unique, monotonically increasing TxnIds independently.\n5. Query Processing Pipeline Every SQL query in ThunderDB passes through a five-stage pipeline before results are returned to the client.\nSQL Text | v +----------+ AST +-----------+ Bound AST +-----------+ | Parser | ------------\u003e | Analyzer | ------------\u003e | Optimizer | | (sqlpar- | | (semantic | | (cost- | | ser) | | checks) | | based) | +----------+ +-----------+ +-----------+ | Logical Plan | v +-----------+ | Planner | | (physical | | plan) | +-----------+ | Physical Plan | v +-----------+ | Executor | ---\u003e Results | (vector- | | ized) | +-----------+ 5.1 Parser The parser uses the sqlparser crate configured for the PostgreSQL dialect. It tokenizes the SQL input and constructs an Abstract Syntax Tree (AST). Multi-dialect support (45KB) enables alternative syntax acceptance for MySQL and Redis-style commands.\n5.2 Analyzer The semantic analyzer resolves table and column references against the catalog, performs type checking and implicit type coercion, validates function signatures, resolves aliases, and checks permissions against the RBAC policy.\n5.3 Optimizer The cost-based optimizer transforms logical plans to minimize estimated execution cost.\nRule-based transformations:\nPredicate pushdown (push filters below joins) Projection pruning (eliminate unused columns early) Constant folding (evaluate constant expressions at compile time) Subquery decorrelation (convert correlated subqueries to joins) Common subexpression elimination Cost-based decisions:\nJoin ordering: Dynamic programming for small join counts (\u003c 10 tables), greedy heuristic for large join graphs. Index selection: Compare sequential scan cost vs. index scan cost using selectivity estimates from column statistics (histograms, distinct counts, null fractions). Join algorithm selection: Nested loop (small inner), hash join (equi-joins), sort-merge join (sorted inputs or large datasets). Scan type: Row store scan for point queries and small ranges, column store scan for full-table analytics. 5.4 Planner The planner converts the optimized logical plan into a physical plan by selecting concrete operator implementations. For example, a logical “Join” becomes a physical “HashJoin” or “MergeSortJoin”.\n5.5 Execution The executor implements a Volcano-style iterator model enhanced with vectorized processing:\nBatch size: 1024+ rows per batch (configurable). Processing data in batches amortizes function call overhead and enables SIMD optimizations. Parallel execution: The executor can partition work across multiple threads. Parallel hash joins, parallel scans, and parallel aggregations are supported. The degree of parallelism is auto-tuned based on available CPU cores and data size. Physical operators: SeqScan, IndexScan, Filter, Project, HashJoin, MergeSortJoin, NestedLoopJoin, HashAggregate, SortAggregate, Sort, Limit, TopN, Union, Intersect, Except, Insert, Update, Delete, CreateTable, and more. 5.6 NLP \u0026 LLM Integration ThunderDB optionally supports natural language queries through an embedded LLM (llama.cpp integration, 23KB of glue code). Users can submit queries in plain English, which are translated to SQL via a retrieval-augmented generation (RAG) approach that incorporates schema context. The NLP layer (38KB) handles tokenization, intent classification, and entity extraction. ML operations (28KB) enable in-database inference for registered models.\n6. Distributed Architecture 6.1 Raft Consensus ThunderDB uses the Raft consensus protocol for leader election and replicated state machine consistency. Each cluster has one Raft group for metadata and one Raft group per region for data.\nRaft roles:\nLeader: Handles all client requests, replicates log entries to followers. Follower: Replicates the leader’s log, responds to read requests (with lease-based reads). Candidate: Temporarily during leader election. Key parameters:\nElection timeout: 150-300ms (randomized) Heartbeat interval: 50ms Log compaction: Snapshot when log exceeds 10,000 entries 6.2 Region-Based Sharding Data is partitioned into regions, each responsible for a contiguous range of the primary key space.\nKey Space: [0 ................................................... MAX] | | | | | | Region1 | Region2 | Region3 | Region4 | | [0, 100)| [100, 500) | [500, 800) | [800, MAX) | | Node A | Node B | Node A | Node C | Property Value Max Region Size 256MB Split Trigger Region exceeds 256MB Split Strategy Midpoint of key range based on sampled keys Merge Trigger Two adjacent regions on the same node both below 64MB Replication Configurable factor (default 3) 6.3 Auto-Rebalancing A background scheduler on the cluster leader continuously monitors region sizes and node loads. When imbalance is detected:\nSplit: Over-sized regions are split at a sampled midpoint key. Transfer: Regions are moved from overloaded nodes to underloaded nodes using Raft learner mechanism (add learner, replicate, promote, remove old replica). Merge: Under-sized adjacent regions are merged to reduce metadata overhead. 6.4 gRPC Transport All inter-node communication uses gRPC with Protocol Buffers serialization. Key RPC services:\nRaftService: AppendEntries, RequestVote, InstallSnapshot RegionService: Get, Put, Delete, Scan, BatchGet AdminService: SplitRegion, MergeRegion, TransferLeader, AddNode, RemoveNode Connection pooling and multiplexing minimize connection overhead. TLS is mandatory for inter-node traffic in production configurations.\n7. Protocol Compatibility 7.1 PostgreSQL v3 Wire Protocol (54KB) ThunderDB implements the full PostgreSQL v3 extended query protocol, allowing connections from psql, pgAdmin, any PostgreSQL driver (JDBC, psycopg2, node-pg, etc.), and ORMs (SQLAlchemy, Hibernate, Prisma).\nSupported message types:\nStartup, Authentication (MD5, SCRAM-SHA-256), ParameterStatus SimpleQuery, Parse, Bind, Describe, Execute, Sync (extended query protocol) COPY IN/OUT for bulk data transfer LISTEN/NOTIFY for real-time event channels Prepared statements with parameter binding Portal-based cursors for large result sets 7.2 MySQL 4.1+ Wire Protocol (36KB) Full binary protocol support for MySQL client compatibility:\nHandshake with capability negotiation COM_QUERY, COM_STMT_PREPARE, COM_STMT_EXECUTE, COM_STMT_CLOSE MySQL native password authentication Server-side prepared statements Binary result set encoding 7.3 RESP2/3 Protocol (105KB) ThunderDB implements the Redis Serialization Protocol, enabling compatibility with all Redis clients and tools (redis-cli, Jedis, ioredis, etc.).\nSupported data structures and commands:\nStrings: GET, SET, MGET, MSET, INCR, DECR, APPEND, STRLEN, SETEX, SETNX Hashes: HGET, HSET, HMGET, HMSET, HDEL, HGETALL, HKEYS, HVALS, HINCRBY Lists: LPUSH, RPUSH, LPOP, RPOP, LRANGE, LLEN, LINDEX, LSET, LREM Sets: SADD, SREM, SMEMBERS, SISMEMBER, SCARD, SUNION, SINTER, SDIFF Sorted Sets: ZADD, ZREM, ZRANGE, ZRANGEBYSCORE, ZRANK, ZSCORE, ZCARD Pub/Sub: SUBSCRIBE, UNSUBSCRIBE, PUBLISH, PSUBSCRIBE Transactions: MULTI, EXEC, DISCARD, WATCH Server: PING, INFO, DBSIZE, FLUSHDB, SELECT RESP commands are internally translated to SQL operations against the storage engine, providing full ACID guarantees that standard Redis does not offer.\n8. Integration Layer 8.1 CDC Architecture (Change Data Capture) CDC enables real-time data ingestion from external databases into ThunderDB. This is a key component of the companion deployment strategy, allowing ThunderDB to shadow an existing database during migration.\n+----------------+ +--------------------+ +-----------+ | External DB | | CDC Connector | | ThunderDB | | (PostgreSQL/ | ------\u003e | - Reads change log | ------\u003e | Storage | | MySQL/Mongo/ | | - Transforms data | | Engine | | Redis) | | - Applies to target | | | +----------------+ +--------------------+ +-----------+ PostgreSQL: Logical replication slots + output plugins (pgoutput/wal2json) MySQL: Binary log (ROW format) parsing via binlog protocol MongoDB: Change streams (oplog tailing) via aggregation pipeline Redis: Keyspace notifications (__keyevent@*__ channels) CDC guarantees:\nAt-least-once delivery: Connectors track their position in the source change log and resume from the last acknowledged position after restart. Ordering: Changes are applied in the same order they were committed in the source database. Schema evolution: DDL changes in the source are detected and propagated (add column, rename column). 8.2 FDW Architecture (Foreign Data Wrappers) FDW enables ThunderDB to query external databases as if they were local tables, without importing the data.\n-- Register an external PostgreSQL database CREATE FOREIGN TABLE remote_users SERVER pg_production OPTIONS (schema 'public', table 'users'); -- Query spans local and remote data SELECT u.name, o.total FROM remote_users u JOIN local_orders o ON u.id = o.user_id WHERE u.country = 'US'; Predicate pushdown: Filters and projections are pushed down to the remote database to minimize data transfer. In the example above, WHERE u.country = 'US' is executed on the remote PostgreSQL server, and only matching rows are transferred to ThunderDB for the join.\nCost estimation: The FDW layer estimates the cost of remote operations based on table statistics (row count, average row size, network latency), allowing the optimizer to make informed decisions about join ordering between local and remote tables.\n8.3 Zero-Downtime Migration CDC and FDW together enable a zero-downtime migration path:\nShadow phase: Deploy ThunderDB alongside the existing database. CDC replicates all data and changes in real-time. Validation phase: Use FDW to run comparison queries between the two databases, verifying data consistency. Cutover phase: Redirect application traffic to ThunderDB. CDC ensures no data is lost during the switch. Cleanup phase: Decommission the old database and CDC connectors. 9. Data Flow Diagrams 9.1 Query Execution Flow (Read Path) Client ThunderDB | | |--- SQL Query -------\u003e| | +---\u003e Protocol Layer (decode wire format) | +---\u003e SQL Parser (text -\u003e AST) | +---\u003e Analyzer (AST -\u003e bound plan) | +---\u003e Optimizer (bound plan -\u003e optimized logical plan) | +---\u003e Planner (logical plan -\u003e physical plan) | +---\u003e Executor | | +---\u003e Buffer Pool (check cache) | | +---\u003e Storage (row store or column store) | | +---\u003e MVCC visibility check | | +---\u003e Vectorized batch assembly | +---\u003e Protocol Layer (encode result set) |\u003c-- Result Set -------| 9.2 Write Path Client ThunderDB | | |--- INSERT/UPDATE ---\u003e| | +---\u003e Protocol Layer (decode) | +---\u003e SQL Parser -\u003e Analyzer -\u003e Optimizer -\u003e Planner | +---\u003e Transaction Manager | | +---\u003e Acquire locks (if pessimistic) | | +---\u003e Write WAL record (force to disk) | | +---\u003e Modify page in buffer pool (dirty) | | +---\u003e Update indexes | +---\u003e COMMIT | | +---\u003e Write Commit WAL record | | +---\u003e Group commit (fsync) | | +---\u003e Release locks | | +---\u003e Notify CDC propagation worker | +---\u003e Protocol Layer (encode OK/error) |\u003c-- OK ---------------| | | | [Background] | +---\u003e Column Store propagation worker | | +---\u003e Read committed rows from WAL | | +---\u003e Batch into row groups | | +---\u003e Compress and write column segments | +---\u003e Checkpoint worker (periodic) | +---\u003e Flush dirty pages | +---\u003e Write checkpoint WAL record | +---\u003e Advance recycle LSN 9.3 CDC Flow External Database ThunderDB +----------------+ +--------------------------------------+ | PostgreSQL | | | | Logical Repl. |--- WAL ---\u003e| CDC Connector (PostgreSQL) | | Slot | Stream | +-\u003e Decode pgoutput messages | +----------------+ | +-\u003e Transform to ThunderDB ops | | +-\u003e Begin transaction | +----------------+ | +-\u003e Apply INSERT/UPDATE/DELETE | | MySQL | | +-\u003e Commit transaction | | Binlog |--- ROW ---\u003e| CDC Connector (MySQL) | | Events | Events | +-\u003e Parse binlog events | +----------------+ | +-\u003e Map columns and types | | +-\u003e Apply changes | +----------------+ | | | MongoDB |--- Change | CDC Connector (MongoDB) | | Oplog | Stream---\u003e| +-\u003e Consume change stream docs | +----------------+ | +-\u003e BSON -\u003e row conversion | | | +----------------+ | CDC Connector (Redis) | | Redis |--- Key ---\u003e| +-\u003e Subscribe to keyspace events | | Keyspace | Events | +-\u003e Capture key mutations | +----------------+ +--------------------------------------+ 9.4 Distributed Query Flow Client | v Coordinator Node | +---\u003e Parse \u0026 Optimize query +---\u003e Identify involved regions +---\u003e Route sub-queries to region leaders | +----------+----------+----------+ | | | | v v v v Region 1 Region 2 Region 3 Region 4 (Node A) (Node B) (Node A) (Node C) | | | | +--- partial results ---+ | | | | v v v Coordinator Node | +---\u003e Merge/Aggregate partial results +---\u003e Apply final LIMIT/ORDER BY +---\u003e Return to client | v Client 10. Design Decisions 10.1 Why Rust? ThunderDB is written entirely in Rust for three fundamental reasons:\nMemory safety without garbage collection: Rust’s ownership model and borrow checker eliminate entire classes of bugs (use-after-free, double-free, data races) at compile time. For a database that manages raw memory (buffer pool, page cache), this prevents corruption bugs that are notoriously difficult to diagnose.\nZero-cost abstractions: Rust’s trait system, generics, and iterators compile down to the same machine code as hand-written C/C++. The database pays no runtime overhead for its modular architecture.\nNo garbage collector: Database engines require predictable latency. GC pauses in Java or Go can introduce multi-millisecond stalls during critical operations (transaction commit, WAL flush). Rust’s deterministic memory management guarantees consistent tail latencies.\nFearless concurrency: Rust’s type system enforces thread safety at compile time. The Send and Sync traits ensure that concurrent access to shared data structures (buffer pool, lock tables, Raft state) is always correct.\n10.2 Why HTAP? Traditional architectures require separate OLTP and OLAP databases connected by ETL pipelines:\nTraditional: App --\u003e OLTP DB --\u003e ETL (hours) --\u003e OLAP DB --\u003e Dashboard ThunderDB: App --\u003e ThunderDB (row + column store) --\u003e Dashboard Eliminates data movement: No ETL pipelines to build, maintain, debug, and monitor. Real-time analytics: The column store lags the row store by seconds, not hours. Reduced operational complexity: One database to deploy, backup, monitor, and scale. Consistent data: Analytics and transactions read from the same source of truth. 10.3 Why Multi-Protocol? Supporting PostgreSQL, MySQL, and Redis wire protocols means:\nZero application changes: Existing applications connect to ThunderDB using their current database drivers. Existing tooling works: pgAdmin, MySQL Workbench, redis-cli, Grafana, Metabase, and thousands of other tools work without modification. Gradual migration: Teams can switch one service at a time, using the protocol that service already speaks. 10.4 Why Companion Approach? ThunderDB is designed to run alongside an existing database during migration:\nLower adoption barrier: No big-bang migration required. Start by deploying ThunderDB as a read replica via CDC. Validation period: Run both databases in parallel, compare query results via FDW, and build confidence before cutover. Rollback safety: If issues arise, traffic can be redirected back to the original database instantly since CDC keeps both in sync. Incremental feature adoption: Teams can adopt ThunderDB features (vector search, real-time analytics, Redis compatibility) incrementally without disrupting existing workloads. Summary of Key Metrics Metric Value Total Lines of Code ~75,600 Number of Crates 14 Page Size 16KB WAL Segment Size 64MB B+Tree Fanout 256+ keys/node Vectorized Batch Size 1024+ rows Max Region Size 256MB TxnId Width 64 bits (48 timestamp + 8 node + 8 sequence) Max Cluster Size 256 nodes Supported Wire Protocols 3 (PostgreSQL v3, MySQL 4.1+, RESP2/3) CDC Sources 4 (PostgreSQL, MySQL, MongoDB, Redis) FDW Targets 4 (PostgreSQL, MySQL, MongoDB, Redis) API Interfaces 5 (REST, gRPC, GraphQL, WebSocket, Web Dashboard) Compression Algorithms 6 (LZ4, Snappy, Zstd, RLE, Delta, Dictionary) Authentication Methods 3 (MD5, SCRAM-SHA-256, MySQL native password) ","categories":"","description":"Deep dive into ThunderDB's system architecture, components, and design decisions.\n","excerpt":"Deep dive into ThunderDB's system architecture, components, and design …","ref":"/docs/docs/architecture/","tags":"","title":"Architecture"},{"body":"Codebase Guide This guide provides a comprehensive tour of the ThunderDB codebase. ThunderDB is organized as a Cargo workspace with 14 crates totaling approximately 75,600 lines of Rust code. Understanding the structure, dependencies, and patterns used throughout the codebase is essential for effective contribution.\nWorkspace Structure ThunderDB uses a single Cargo workspace defined in the root Cargo.toml. All crates live in the workspace and share a common Cargo.lock file, ensuring consistent dependency versions across the project.\nRoot Cargo.toml The root Cargo.toml defines the workspace members, shared dependency versions, and build profiles:\n[workspace] members = [ \"thunder-common\", \"thunder-storage\", \"thunder-txn\", \"thunder-sql\", \"thunder-query\", \"thunder-cluster\", \"thunder-protocol\", \"thunder-vector\", \"thunder-api\", \"thunder-cdc\", \"thunder-fdw\", \"thunder-server\", \"thunder-client\", ] resolver = \"2\" [workspace.dependencies] # Shared dependency versions are defined here and inherited by crates tokio = { version = \"1.35\", features = [\"full\"] } serde = { version = \"1.0\", features = [\"derive\"] } tracing = \"0.1\" # ... additional shared dependencies [profile.release] opt-level = 3 lto = \"thin\" codegen-units = 1 panic = \"abort\" [profile.dev] opt-level = 0 debug = true Build Profiles ThunderDB defines two primary build profiles:\nDevelopment Profile (cargo build):\nSetting Value Rationale opt-level 0 No optimization – fastest compilation debug true Full debug information – enables debugger use Release Profile (cargo build --release):\nSetting Value Rationale opt-level 3 Maximum optimization – best runtime performance lto \"thin\" Thin link-time optimization – cross-crate inlining with reasonable build times codegen-units 1 Single codegen unit – enables maximum optimization at the cost of parallelism panic \"abort\" Abort on panic – smaller binary, no stack unwinding overhead, better for server software The release profile produces binaries suitable for production deployment and accurate benchmarking. Development builds are optimized for fast iteration.\nDirectory Layout thunderdb/ +-- Cargo.toml # Workspace root +-- Cargo.lock # Locked dependency versions +-- rust-toolchain.toml # Rust version (1.75+) +-- .rustfmt.toml # Formatting configuration +-- .clippy.toml # Clippy configuration +-- config/ | +-- dev.toml # Development configuration | +-- test.toml # Test configuration | +-- prod.toml # Production configuration template +-- scripts/ | +-- dev.sh # Start development server | +-- run_tests.sh # Run full test suite | +-- build-deb.sh # Build Debian package | +-- install-hooks.sh # Install git hooks +-- docker/ | +-- Dockerfile # Production container image | +-- Dockerfile.dev # Development container image +-- docker-compose.yml # Multi-container dev environment +-- thunder-common/ # Shared types, errors, utilities +-- thunder-storage/ # Storage engine (WAL, B+Tree, buffer pool) +-- thunder-txn/ # Transaction management (MVCC, 2PC) +-- thunder-sql/ # SQL parsing, analysis, optimization +-- thunder-query/ # Query execution engine +-- thunder-cluster/ # Distributed cluster management +-- thunder-protocol/ # Wire protocols (PostgreSQL, MySQL, Redis) +-- thunder-vector/ # Vector search and embeddings +-- thunder-api/ # REST, gRPC, GraphQL, WebSocket APIs +-- thunder-cdc/ # Change data capture +-- thunder-fdw/ # Foreign data wrappers +-- thunder-server/ # Main server binary +-- thunder-client/ # Client library Crate Dependency Graph Understanding the dependency relationships between crates is critical for navigating the codebase and understanding the impact of changes. The crates form a directed acyclic graph (DAG) with thunder-common at the base and thunder-server at the top.\nVisual Dependency Graph thunder-server / | | | \\ / | | | \\ / | | | \\ thunder-api | | | thunder-cdc / | | \\ | | | | / | | \\ | | | | / | | \\ | | | | t-protocol t-cluster | | t-vector t-fdw / | | \\ | | | | / | / | | \\ | | | | / | / | | \\ | | | | / | t-sql t-query t-txn | | | t-sql | | /|\\ / \\ | | | | | / | \\ / \\ | | | | | / | \\ / \\ | | | | |/ | \\/ \\ | | | | t-storage t-sql | | | | | | | | | | | | | | | | | | | +-------+-----+--+--+----+----------+ | thunder-common Crate Dependency Details Each crate’s internal dependencies are listed below, along with its role in the system:\nthunder-common (Leaf Crate) Internal dependencies: None\nThis is the foundational crate with zero internal dependencies. It defines the core types, error types, configuration structures, and shared utilities used throughout the entire system. Changes to this crate trigger a rebuild of every other crate in the workspace.\nthunder-storage Internal dependencies: thunder-common\nThe storage engine layer. Manages persistent data through the write-ahead log (WAL), B+Tree indexes, buffer pool, row-oriented and columnar storage formats, system catalog, and compression.\nthunder-txn Internal dependencies: thunder-common, thunder-storage\nThe transaction management layer. Implements multi-version concurrency control (MVCC), optimistic concurrency control, distributed transaction coordination via two-phase commit (2PC), lock management, and deadlock detection.\nthunder-sql Internal dependencies: thunder-common\nThe SQL processing layer. Handles SQL parsing, semantic analysis, query optimization, and query plan generation. Also includes dialect support for multiple SQL dialects, natural language processing, LLM integration, ML operations, and user-defined functions.\nthunder-query Internal dependencies: thunder-common, thunder-sql, thunder-storage, thunder-txn\nThe query execution engine. Takes optimized query plans from thunder-sql and executes them against the storage engine within transaction contexts. Implements physical operators, vectorized batch processing, and parallel multi-threaded execution.\nthunder-cluster Internal dependencies: thunder-common, thunder-storage\nThe distributed cluster management layer. Handles node discovery, Raft consensus, data partitioning, replication, and cluster membership changes.\nthunder-protocol Internal dependencies: thunder-common, thunder-sql, thunder-query, thunder-txn\nThe wire protocol layer. Implements compatibility with existing database clients through the PostgreSQL v3 wire protocol, MySQL wire protocol, and Redis RESP protocol. Also manages sessions, authentication, and TLS.\nthunder-vector Internal dependencies: thunder-common, thunder-storage\nThe vector search engine. Provides vector indexing (HNSW, IVF), similarity search, and embedding storage for AI/ML workloads.\nthunder-api Internal dependencies: thunder-common, thunder-sql, thunder-query, thunder-protocol, thunder-cluster\nThe API gateway layer. Exposes ThunderDB through REST, gRPC, GraphQL, and WebSocket APIs. Includes the web admin dashboard, request handlers, authentication, and rate limiting.\nthunder-cdc Internal dependencies: thunder-common, thunder-storage\nChange data capture. Reads the WAL to produce a stream of data change events for downstream consumers, enabling real-time data replication and event-driven architectures.\nthunder-fdw Internal dependencies: thunder-common, thunder-sql\nForeign data wrappers. Enables ThunderDB to query external data sources (PostgreSQL, MySQL, CSV, Parquet, S3) as if they were local tables.\nthunder-client Internal dependencies: thunder-common\nThe official Rust client library for connecting to ThunderDB. Provides a type-safe API for executing queries, managing transactions, and subscribing to change streams.\nthunder-server (Top-Level Binary) Internal dependencies: All crates\nThe main server binary that wires everything together. Parses CLI arguments, loads configuration, initializes all subsystems, and starts the server. This is the only crate that produces an executable binary.\nKey Source Files This section documents the most important source files in each crate, describing their purpose, size, and key abstractions.\nthunder-common The shared foundation crate containing types, errors, and utilities used across the entire system.\ntypes.rs – Core Type Definitions This file defines the fundamental identifier types and data representations used throughout ThunderDB:\nIdentifier Types:\n// Each ID type is a newtype wrapper for type safety pub struct DatabaseId(pub u64); pub struct TableId(pub u64); pub struct ColumnId(pub u32); pub struct IndexId(pub u64); pub struct RowId(pub u64); pub struct PageId(pub u64); pub struct TxnId(pub u64); pub struct RegionId(pub u32); pub struct NodeId(pub u64); pub struct Lsn(pub u64); // Log Sequence Number Data Types:\npub enum DataType { Boolean, Int8, Int16, Int32, Int64, UInt8, UInt16, UInt32, UInt64, Float32, Float64, Decimal(u8, u8), // precision, scale Varchar(usize), Text, Blob, Date, Time, Timestamp, TimestampTz, Interval, Uuid, Json, Jsonb, Vector(usize), // dimensionality Array(Box\u003cDataType\u003e), } Value Representation:\npub enum Value { Null, Boolean(bool), Int64(i64), Float64(f64), Decimal(rust_decimal::Decimal), String(String), Bytes(Vec\u003cu8\u003e), Date(chrono::NaiveDate), Timestamp(chrono::NaiveDateTime), Uuid(uuid::Uuid), Json(serde_json::Value), Vector(Vec\u003cf32\u003e), Array(Vec\u003cValue\u003e), } Core Structures:\npub struct Row { pub id: RowId, pub values: Vec\u003cValue\u003e, } pub struct Schema { pub columns: Vec\u003cColumnDef\u003e, pub primary_key: Vec\u003cColumnId\u003e, pub indexes: Vec\u003cIndexDef\u003e, } config.rs – Configuration Parsing Handles loading and validating configuration from TOML files and environment variables. Defines the hierarchical configuration structure covering storage, networking, cluster, security, and logging settings. Uses serde for deserialization with default values.\nerror.rs – Error Types Defines the unified error hierarchy for the entire system:\npub enum ThunderError { Sql(SqlError), Storage(StorageError), Transaction(TransactionError), Io(std::io::Error), Config(ConfigError), Cluster(ClusterError), Protocol(ProtocolError), Internal(String), } Each variant has a corresponding detailed error enum. All errors implement std::error::Error and Display. Error propagation uses the ? operator with From trait implementations.\nrbac.rs – Role-Based Access Control Defines roles, permissions, and access control policies. Supports hierarchical roles with privilege inheritance and fine-grained permissions at database, table, and column levels.\naudit.rs – Audit Logging Structured audit logging for security-relevant events (authentication, authorization decisions, DDL operations, data access). Events are serialized and written to a dedicated audit log.\nmetrics.rs – Prometheus Metrics Defines and registers Prometheus metrics for monitoring. Includes counters, gauges, and histograms for query latency, throughput, storage utilization, connection counts, and more.\nthunder-storage The storage engine crate, responsible for all persistent data management.\nwal.rs (~67KB) – Write-Ahead Log The largest file in the storage crate, implementing a high-performance write-ahead log:\nARIES-style recovery: Supports analysis, redo, and undo phases for crash recovery Segment management: WAL is divided into fixed-size segments that are rotated and archived Group commit: Batches multiple transaction commits into a single fsync() call for throughput Log record types: Insert, Update, Delete, Commit, Abort, Checkpoint, CompensationLogRecord (CLR) Checkpointing: Periodic fuzzy checkpoints to bound recovery time Log sequence numbers (LSN): Monotonically increasing sequence numbers for ordering Key types: WalManager, WalWriter, WalReader, LogRecord, WalSegment, CheckpointManager\nbtree.rs (~29KB) – B+Tree Indexes Implements concurrent B+Tree indexes, the primary index structure for row-oriented data:\nLatch coupling (crabbing): Lock-coupling protocol for concurrent access without coarse-grained locking Prefix compression: Reduces key storage overhead in leaf and internal nodes Leaf page chaining: Doubly-linked leaf pages for efficient range scans Bulk loading: Optimized bottom-up construction for initial data load Split and merge: Page splits and merges maintain tree balance Iterator interface: BTreeIterator for sequential and reverse scanning Key types: BTree, BTreeNode, InternalNode, LeafNode, BTreeIterator, BTreeBuilder\nbuffer.rs – Buffer Pool Manages a fixed-size pool of in-memory page frames:\nLRU eviction: Least-recently-used eviction policy with clock approximation Page pinning: Prevents eviction of actively used pages Dirty page tracking: Tracks modified pages for write-back Read/write latching: Per-page read-write locks for concurrent access Prefetching: Sequential scan detection and asynchronous prefetching Key types: BufferPool, BufferFrame, PageHandle, EvictionPolicy\nrow_store.rs – Row-Oriented Storage Implements the row-oriented storage format optimized for OLTP workloads:\nHeap file organization: Pages organized as a heap with free space tracking Slot directory: Each page has a slot directory mapping slot numbers to row offsets Row format: Fixed-size header followed by column values with null bitmap Free space map: Tracks available space per page for fast insertion Key types: RowStore, HeapFile, SlotPage, RowHeader, FreeSpaceMap\ncolumn_store.rs – Columnar Storage Implements the columnar storage format optimized for OLAP workloads:\nColumn groups: Columns are stored in groups based on access patterns Row groups: Data is divided into row groups (typically 64K-128K rows) for batch processing Encoding: Type-specific encodings (dictionary, RLE, delta, bit-packing) Statistics: Min/max/null count per column chunk for predicate pushdown Apache Arrow integration: Native Arrow columnar format for zero-copy analytics Key types: ColumnStore, ColumnGroup, RowGroup, ColumnChunk, ColumnEncoder\ncatalog.rs – System Catalog Manages metadata about databases, tables, columns, indexes, users, and other database objects:\nIn-memory cache: Frequently accessed metadata is cached in memory Persistent storage: Catalog data is stored in system tables Versioning: Catalog changes are versioned for DDL transactional support Schema evolution: Supports adding/removing columns, changing types (with restrictions) Key types: Catalog, DatabaseMeta, TableMeta, ColumnMeta, IndexMeta\ncompression.rs – Compression Algorithms Implements multiple compression algorithms with a unified interface:\nAlgorithm Best For Ratio Speed LZ4 General purpose, hot data Moderate Very fast Snappy General purpose, balanced Moderate Fast Zstd Cold data, archival High Moderate RLE (Run-Length Encoding) Columns with many repeated values Variable Very fast Delta Monotonically increasing values (timestamps, sequences) High Very fast Dictionary Low-cardinality string columns High Fast Key types: Compressor, CompressionAlgorithm, CompressedBlock\npage.rs – Page Management Defines the 16KB page format used throughout the storage engine:\n+------------------+ | Page Header | (fixed size: 64 bytes) | - page_id | | - page_type | | - lsn | | - checksum | | - free_space | +------------------+ | Page Content | (variable, depends on page type) | ... | +------------------+ | Page Footer | (checksum validation) +------------------+ Page types: Data, Index, Overflow, FreeSpaceMap, Undo, System\nKey types: Page, PageHeader, PageType, PageManager\ndisk.rs – Disk I/O Low-level disk I/O layer with direct I/O support:\nAsynchronous I/O: Uses tokio::fs for non-blocking file operations Direct I/O: Optional O_DIRECT support to bypass OS page cache I/O scheduling: Request merging and prioritization File management: Tablespace and data file management Key types: DiskManager, FileHandle, IoRequest, IoScheduler\nthunder-txn Transaction management, ensuring ACID properties across the distributed system.\nmvcc.rs – Multi-Version Concurrency Control Implements MVCC for snapshot isolation and serializable isolation levels:\nVersion chains: Each row maintains a chain of versions tagged with transaction IDs Visibility rules: A version is visible to a transaction if it was committed before the transaction’s snapshot Garbage collection: Old versions that are no longer visible to any active transaction are reclaimed Snapshot management: Efficient tracking of active transactions and their snapshots Key types: MvccManager, Version, VersionChain, Snapshot, VisibilityChecker\nccp.rs – Optimistic Concurrency Control Implements optimistic concurrency control (OCC) for low-contention workloads:\nRead phase: Transaction reads are tracked without acquiring locks Validation phase: At commit time, the transaction validates that no conflicts occurred Write phase: If validation succeeds, changes are applied atomically Conflict detection: Tracks read and write sets for intersection checking Key types: OccManager, ReadSet, WriteSet, ValidationResult\ncoordinator.rs – 2PC Distributed Transaction Coordinator Coordinates distributed transactions across multiple nodes using two-phase commit:\nPrepare phase: Coordinator sends prepare request to all participants; each participant votes commit or abort Commit/abort phase: Based on unanimous votes, coordinator sends global commit or abort decision Recovery: Handles coordinator and participant failures using persistent log Timeout handling: Configurable timeouts with automatic abort on expiry Key types: TxnCoordinator, Participant, PrepareResult, TxnLog\nlock_manager.rs – Lock Management Fine-grained locking for pessimistic concurrency control:\nLock modes: Shared (S), Exclusive (X), Intent Shared (IS), Intent Exclusive (IX), Shared Intent Exclusive (SIX) Lock granularity: Database, table, page, row level locks Lock escalation: Automatic escalation from row to page to table when lock count exceeds threshold Wait-for graph: Maintained for deadlock detection Key types: LockManager, LockMode, LockRequest, LockTable\ndeadlock.rs – Deadlock Detection Implements deadlock detection and resolution:\nWait-for graph: Directed graph of transaction dependencies Cycle detection: Periodic cycle detection using DFS Victim selection: Chooses the youngest transaction (lowest cost) as the deadlock victim Automatic abort: Victim transaction is automatically aborted and retried Key types: DeadlockDetector, WaitForGraph, DeadlockVictim\nthunder-sql SQL processing pipeline from text to optimized logical plan.\nparser.rs – SQL Parser Parses SQL text into an abstract syntax tree (AST). Built on the sqlparser crate with ThunderDB-specific extensions:\nStandard SQL parsing (SELECT, INSERT, UPDATE, DELETE, CREATE, ALTER, DROP) ThunderDB extensions (VECTOR SEARCH, CREATE ML MODEL, NLP QUERY) Error recovery with helpful diagnostics Key types: Parser, Statement, Expr, SelectStatement, ParseError\nanalyzer.rs – Semantic Analyzer Performs semantic analysis on the parsed AST:\nName resolution: Resolves table names, column references, and aliases against the catalog Type checking: Validates and infers types for expressions, function calls, and operators Privilege checking: Verifies the current user has permissions for the requested operations Validation: Checks constraints, foreign key references, and schema compatibility Key types: Analyzer, AnalyzedStatement, NameResolver, TypeChecker\noptimizer.rs – Query Optimizer Transforms logical query plans into optimized forms using cost-based optimization:\nPredicate pushdown: Moves filter predicates closer to data sources Projection pushdown: Eliminates unnecessary columns early Join reordering: Explores join orders using dynamic programming for small join counts, greedy for large Cost model: Estimates I/O cost, CPU cost, and memory usage based on catalog statistics Rule-based optimization: Applies heuristic transformations (constant folding, predicate simplification) Subquery decorrelation: Converts correlated subqueries to joins where possible Key types: Optimizer, LogicalPlan, OptimizationRule, CostModel, Statistics\nplanner.rs – Query Planner Converts optimized logical plans to physical execution plans:\nPhysical operator selection: Chooses between hash join vs. merge join vs. nested loop based on cost Index selection: Determines when to use index scans vs. full table scans Parallelism planning: Determines degree of parallelism and data partitioning strategy Memory budgeting: Allocates memory among operators for sort, hash, and aggregation buffers Key types: Planner, PhysicalPlan, PhysicalOperator, ExecutionStrategy\ndialect.rs (~45KB) – Multi-Dialect SQL Support Implements compatibility with multiple SQL dialects:\nPostgreSQL dialect: Compatible with PostgreSQL-specific syntax and functions MySQL dialect: MySQL-specific syntax, quoting rules, and function names SQLite dialect: SQLite compatibility for lightweight use cases Standard SQL: ANSI SQL:2016 compliance Each dialect defines parsing rules, type mappings, function mappings, and behavioral differences.\nKey types: Dialect, PostgresDialect, MySqlDialect, SqliteDialect, StandardDialect\nnlp.rs (~38KB) – Natural Language Processing Enables querying ThunderDB using natural language:\nIntent recognition: Classifies user intent (query, insert, update, schema modification) Entity extraction: Identifies table names, column names, and values from natural language SQL generation: Converts structured intent into executable SQL Disambiguation: Interactive clarification when intent is ambiguous Context management: Maintains conversation context for follow-up queries Key types: NlpEngine, Intent, Entity, NlpContext, Disambiguation\nllm.rs (~23KB) – LLM Integration Integrates with large language models for advanced query generation:\nProvider abstraction: Pluggable LLM providers (OpenAI, Anthropic, local models) Prompt engineering: Schema-aware prompts for accurate SQL generation Output validation: Validates LLM-generated SQL against the schema before execution Caching: Caches LLM responses for repeated query patterns Rate limiting: Configurable rate limits per provider Key types: LlmEngine, LlmProvider, LlmRequest, LlmResponse, PromptTemplate\nml.rs (~28KB) – ML Operations SQL-integrated machine learning operations:\nModel management: CREATE, TRAIN, EVALUATE, PREDICT SQL extensions Feature engineering: Built-in transformations (normalization, one-hot encoding, binning) Algorithms: Linear regression, logistic regression, decision trees, k-means clustering Model storage: Trained models stored in the catalog for persistence Batch prediction: Efficient batch inference using vectorized execution Key types: MlEngine, Model, TrainingConfig, Prediction, FeatureTransform\nudf.rs – User-Defined Functions Framework for registering and executing user-defined functions:\nScalar UDFs: Functions that operate on a single row Aggregate UDFs: Functions that aggregate across multiple rows Table UDFs: Functions that return a table (table-valued functions) WebAssembly UDFs: Sandboxed execution of user-provided WASM modules Key types: UdfRegistry, ScalarUdf, AggregateUdf, TableUdf, WasmRuntime\nthunder-query The query execution engine that runs physical plans against the storage engine.\nexecutor.rs (~60KB) – Main Query Executor The largest file in the codebase, implementing the core query execution framework:\nVolcano model: Iterator-based pull model for row-at-a-time execution Vectorized execution: Batch processing mode for analytical queries Adaptive execution: Runtime switching between row and batch modes based on query characteristics Memory management: Per-operator memory tracking with spill-to-disk capability Cancellation: Cooperative cancellation support for long-running queries Progress tracking: Real-time query progress reporting Key types: Executor, ExecutionContext, OperatorState, QueryResult, ExecutionStats\nphysical_plan.rs (~38KB) – Physical Operators Defines all physical operators available for query execution:\nScan operators: SeqScan, IndexScan, IndexOnlyScan, BitmapScan Join operators: NestedLoopJoin, HashJoin, MergeJoin, IndexNestedLoopJoin Aggregation operators: HashAggregate, SortAggregate, StreamingAggregate Sort operators: ExternalSort (with spill-to-disk), TopN Set operators: Union, Intersect, Except DML operators: Insert, Update, Delete Utility operators: Limit, Offset, Project, Filter, Materialize Each operator implements the PhysicalOperator trait:\npub trait PhysicalOperator: Send + Sync { fn open(\u0026mut self, ctx: \u0026ExecutionContext) -\u003e Result\u003c()\u003e; fn next(\u0026mut self) -\u003e Result\u003cOption\u003cRow\u003e\u003e; fn next_batch(\u0026mut self) -\u003e Result\u003cOption\u003cRecordBatch\u003e\u003e; fn close(\u0026mut self) -\u003e Result\u003c()\u003e; fn estimated_cost(\u0026self) -\u003e OperatorCost; fn children(\u0026self) -\u003e \u0026[Box\u003cdyn PhysicalOperator\u003e]; } vectorized.rs (~33KB) – Vectorized Batch Processing Implements vectorized execution for analytical workloads:\nArrow-based: Uses Apache Arrow RecordBatch as the internal batch format SIMD acceleration: Leverages SIMD intrinsics for filter evaluation, aggregation, and comparison Batch size tuning: Adaptive batch sizes based on available memory and cache characteristics Late materialization: Defers tuple construction until necessary Filter pushdown: Evaluates filters on compressed/encoded data where possible Key types: VectorizedExecutor, BatchOperator, FilterMask, AggregateAccumulator\nparallel.rs (~35KB) – Multi-Threaded Execution Implements intra-query and inter-query parallelism:\nExchange operators: HashPartition, RoundRobin, Broadcast for data redistribution Pipeline parallelism: Multiple operators execute concurrently in a pipeline Partition-parallel execution: Same operator runs on multiple partitions simultaneously Work stealing: Idle threads steal work from busy threads for load balancing Resource management: Per-query thread pools with configurable limits Key types: ParallelExecutor, Exchange, Pipeline, WorkerPool, PartitionState\nthunder-protocol Wire protocol implementations for client compatibility.\npostgres.rs (~54KB) – PostgreSQL Wire Protocol Full implementation of the PostgreSQL v3 frontend/backend protocol:\nStartup sequence: SSL negotiation, authentication (password, MD5, SCRAM-SHA-256), parameter exchange Simple query: Parse, execute, and return results for text queries Extended query: Prepare, bind, describe, execute flow for parameterized queries Copy protocol: COPY IN/OUT for bulk data loading and extraction Type system mapping: PostgreSQL OID to ThunderDB type mapping Error and notice messages: PostgreSQL-compatible error codes and messages Cancellation: Query cancellation via cancel key Compatible with psql, libpq, JDBC (pgjdbc), Python (psycopg2, asyncpg), Go (pgx), and other PostgreSQL client libraries.\nKey types: PostgresProtocol, PostgresMessage, PostgresSession, PostgresTypeMap\nmysql.rs (~36KB) – MySQL Wire Protocol Implementation of the MySQL client/server protocol:\nHandshake: Capability negotiation, authentication (native password, caching SHA2) Command phase: COM_QUERY, COM_STMT_PREPARE, COM_STMT_EXECUTE, COM_STMT_CLOSE Result set protocol: Column definitions, row data, EOF markers Type system mapping: MySQL type codes to ThunderDB types Character set handling: UTF-8 and other MySQL character set negotiations Compatible with the mysql CLI, MySQL Connector/J, Python (mysql-connector-python, PyMySQL), and other MySQL client libraries.\nKey types: MysqlProtocol, MysqlPacket, MysqlSession, MysqlCapabilities\nresp.rs (~105KB) – Redis RESP Protocol The largest file in the entire codebase, implementing the Redis Serialization Protocol (RESP) for key-value and cache workloads:\nRESP2 and RESP3: Full support for both protocol versions Command parsing: Parses and dispatches all supported Redis commands Data structure commands: String, Hash, List, Set, Sorted Set, Stream operations Pub/Sub: Publish/Subscribe messaging Lua scripting: EVAL and EVALSHA commands with embedded Lua interpreter Transaction commands: MULTI/EXEC/DISCARD for Redis-style transactions Cluster commands: CLUSTER INFO, CLUSTER NODES for cluster-aware clients Pipeline support: Multiple commands in a single round trip SQL bridge: Translates Redis operations to underlying SQL/KV operations Compatible with redis-cli, redis-py, ioredis, jedis, and other Redis client libraries.\nKey types: RespProtocol, RespValue, RespCommand, RedisSession, CommandDispatcher\nsession.rs (~41KB) – Session Management Manages client sessions across all protocols:\nSession lifecycle: Creation, authentication, parameter setting, query execution, disconnection Session state: Current database, transaction state, prepared statements, portal cursors Connection pooling: Efficient session reuse for high-concurrency workloads Idle timeout: Automatic cleanup of idle sessions Session variables: Per-session configuration overrides Key types: SessionManager, Session, SessionState, SessionConfig\nauth.rs – Authentication Multi-method authentication:\nPassword-based authentication (bcrypt, Argon2) SCRAM-SHA-256 (PostgreSQL SASL) X.509 certificate authentication LDAP integration JWT token validation Key types: Authenticator, AuthMethod, Credential, AuthResult\ntls.rs – TLS/SSL TLS transport security:\nTLS 1.2 and 1.3 support Certificate management and rotation SNI (Server Name Indication) support Mutual TLS (mTLS) for client certificate verification Key types: TlsConfig, TlsAcceptor, CertificateManager\nthunder-api HTTP-based API servers and the web administration dashboard.\nrest.rs – REST API Server RESTful API built on axum:\nCRUD operations for databases, tables, and data Query execution endpoint Bulk import/export OpenAPI/Swagger documentation Content negotiation (JSON, CSV, Parquet) Pagination and cursor-based navigation grpc.rs – gRPC API Server gRPC API built on tonic:\nProtobuf-defined service interfaces Streaming query results (server-side streaming) Bi-directional streaming for live data feeds Health checking service Reflection service for dynamic clients graphql.rs – GraphQL API Server Auto-generated GraphQL API:\nSchema introspection Query, mutation, and subscription support Automatic schema generation from database tables N+1 query prevention with DataLoader pattern Depth and complexity limiting websocket.rs – WebSocket API Server Real-time WebSocket API:\nLive query subscriptions (receive updates when query results change) Change stream subscriptions Binary and text message support Heartbeat and automatic reconnection dashboard.rs (~40KB) – Web Admin Dashboard Embedded web administration interface:\nCluster overview: Node health, topology, resource utilization Query console: Interactive SQL editor with syntax highlighting and autocomplete Performance monitoring: Real-time query latency, throughput, and resource metrics Slow query log: Identify and analyze slow queries Schema browser: Navigate databases, tables, indexes, and views User management: Create and manage users, roles, and permissions Configuration editor: View and modify server configuration Backup management: Initiate and monitor backup and restore operations handlers.rs – Request Handlers Shared request handling logic for all API endpoints. Includes request parsing, parameter validation, result serialization, and error response formatting.\nauth.rs – API Authentication API-specific authentication middleware:\nAPI key authentication OAuth 2.0 / OpenID Connect JWT bearer token validation Session-based authentication rate_limit.rs – Rate Limiting Token bucket rate limiter:\nPer-user and per-IP rate limits Configurable burst and sustained rates Rate limit headers in responses (X-RateLimit-*) Distributed rate limiting via shared state in cluster mode thunder-server The top-level binary crate that ties everything together.\nmain.rs – Server Entry Point The application entry point:\nCLI argument parsing: Uses clap for command-line interface: thunder-server [OPTIONS] --config \u003cPATH\u003e Path to configuration file --data-dir \u003cPATH\u003e Data directory --log-level \u003cLEVEL\u003e Log level (trace, debug, info, warn, error) --bind \u003cADDR\u003e Bind address --cluster-join \u003cADDR\u003e Join an existing cluster --init Initialize a new database --version Print version information Signal handling: Graceful shutdown on SIGTERM/SIGINT Panic handling: Custom panic hook for logging and crash reporting Tokio runtime setup: Configures the async runtime with appropriate thread counts engine.rs – Core Engine Coordination The central coordination layer that initializes and connects all subsystems:\nStartup sequence: Catalog recovery, WAL replay, buffer pool initialization, cluster join Shutdown sequence: Graceful client disconnection, WAL flush, checkpoint, resource cleanup Health monitoring: Periodic health checks of all subsystems Configuration reloading: Dynamic configuration changes without restart Key types: Engine, EngineConfig, SubsystemHandle\nworkers.rs – Background Tasks Long-running background tasks:\nCheckpoint worker: Periodic fuzzy checkpointing Compaction worker: Background compaction of storage files Statistics worker: Periodic collection of table and index statistics for the query optimizer WAL archival worker: Archiving old WAL segments Garbage collection worker: MVCC version garbage collection Monitoring worker: Metrics collection and export Key types: WorkerManager, Worker, WorkerConfig\nthunder-cdc Key Files cdc.rs: Core CDC engine that reads WAL records and converts them to change events publisher.rs: Publishes change events to downstream consumers (Kafka, Pulsar, webhooks) filter.rs: Table and column-level filtering for selective replication format.rs: Change event serialization (JSON, Avro, Protobuf) thunder-vector Key Files index.rs: Vector index implementations (HNSW, IVF-Flat, IVF-PQ) search.rs: k-NN and approximate nearest neighbor search distance.rs: Distance functions (Euclidean, cosine, dot product, Hamming) with SIMD acceleration via simsimd embedding.rs: Embedding storage and retrieval thunder-fdw Key Files wrapper.rs: Foreign data wrapper trait and registry postgres_fdw.rs: Foreign data wrapper for PostgreSQL mysql_fdw.rs: Foreign data wrapper for MySQL csv_fdw.rs: Foreign data wrapper for CSV files parquet_fdw.rs: Foreign data wrapper for Parquet files s3_fdw.rs: Foreign data wrapper for S3-compatible object storage thunder-client Key Files client.rs: Main client API with builder pattern (ClientBuilder) connection.rs: Connection management and pooling query.rs: Query building and execution transaction.rs: Transaction lifecycle management stream.rs: Change stream subscription Key External Dependencies ThunderDB relies on a curated set of high-quality external crates:\nAsync Runtime and Networking Crate Purpose tokio Async runtime (multi-threaded scheduler, I/O, timers, channels) axum HTTP framework for REST and WebSocket APIs tonic gRPC framework (client and server) tower Service abstractions and middleware (rate limiting, timeout, retry) hyper Low-level HTTP implementation (used by axum and tonic) SQL and Data Processing Crate Purpose sqlparser SQL parsing into AST arrow Apache Arrow columnar memory format datafusion Analytical query engine components Storage Crate Purpose rocksdb Embedded key-value store (used for metadata and auxiliary storage) Distributed Systems Crate Purpose raft Raft consensus protocol implementation Concurrency Crate Purpose crossbeam Lock-free data structures and utilities dashmap Concurrent hash map parking_lot Fast mutex and RwLock implementations Vector and SIMD Crate Purpose simsimd SIMD-accelerated vector distance functions Serialization Crate Purpose serde Serialization/deserialization framework serde_json JSON serialization prost Protocol Buffers (used by tonic for gRPC) bincode Compact binary serialization for internal use Observability Crate Purpose tracing Structured, async-aware logging and instrumentation tracing-subscriber Log formatting and filtering prometheus Metrics collection and export Utilities Crate Purpose clap CLI argument parsing chrono Date and time handling uuid UUID generation and parsing rust_decimal Arbitrary-precision decimal arithmetic bytes Efficient byte buffer management thiserror Derive macro for std::error::Error anyhow Flexible error type (used in tests and CLI) Design Patterns ThunderDB follows established Rust design patterns throughout the codebase. Understanding these patterns helps you write consistent, idiomatic contributions.\nBuilder Pattern Used extensively for constructing complex objects with many optional parameters:\n// thunder-client/src/client.rs let client = ClientBuilder::new() .host(\"localhost\") .port(5432) .username(\"admin\") .password(\"secret\") .database(\"mydb\") .pool_size(10) .connect_timeout(Duration::from_secs(5)) .build() .await?; The builder pattern is used for ClientBuilder, ServerConfig, QueryBuilder, IndexBuilder, and many other configuration objects.\nRAII for Resource Management Resources are tied to object lifetimes, ensuring cleanup on drop:\n// Buffer pool page handles automatically release the page on drop { let page = buffer_pool.fetch_page(page_id).await?; // page is pinned in the buffer pool // ... use the page ... } // page is automatically unpinned when dropped // Transaction handles automatically abort on drop if not committed { let txn = engine.begin_transaction().await?; // ... perform operations ... txn.commit().await?; // explicit commit } // if commit was not called, txn aborts on drop Interior Mutability Shared mutable state is managed through interior mutability patterns:\n// Arc\u003cRwLock\u003cT\u003e\u003e for shared state with read-heavy access let catalog: Arc\u003cRwLock\u003cCatalog\u003e\u003e = Arc::new(RwLock::new(Catalog::new())); // DashMap for concurrent hash maps (lock-free reads) let sessions: DashMap\u003cSessionId, Session\u003e = DashMap::new(); // Arc\u003cMutex\u003cT\u003e\u003e for exclusive-access shared state let wal_writer: Arc\u003cMutex\u003cWalWriter\u003e\u003e = Arc::new(Mutex::new(WalWriter::new())); DashMap is preferred over RwLock\u003cHashMap\u003e when the map is accessed from many concurrent tasks and contention needs to be minimized.\nType-State Pattern for Transactions Transactions use the type-state pattern to enforce correct lifecycle at compile time:\n// Transaction states are encoded in the type system pub struct Transaction\u003cS: TxnState\u003e { id: TxnId, state: PhantomData\u003cS\u003e, // ... } pub struct Active; // Transaction is active pub struct Prepared; // Transaction has been prepared (2PC) impl Transaction\u003cActive\u003e { pub fn read(\u0026self, key: \u0026[u8]) -\u003e Result\u003cValue\u003e { /* ... */ } pub fn write(\u0026mut self, key: \u0026[u8], value: Value) -\u003e Result\u003c()\u003e { /* ... */ } pub fn commit(self) -\u003e Result\u003c()\u003e { /* consumes self */ } pub fn abort(self) -\u003e Result\u003c()\u003e { /* consumes self */ } pub fn prepare(self) -\u003e Result\u003cTransaction\u003cPrepared\u003e\u003e { /* state transition */ } } impl Transaction\u003cPrepared\u003e { pub fn commit(self) -\u003e Result\u003c()\u003e { /* ... */ } pub fn abort(self) -\u003e Result\u003c()\u003e { /* ... */ } // Cannot call read() or write() on a Prepared transaction -- compile error! } This prevents misuse like writing to a prepared transaction or preparing a transaction twice.\nVisitor Pattern in SQL Optimizer The SQL optimizer uses the visitor pattern to traverse and transform query plan trees:\npub trait PlanVisitor { fn pre_visit(\u0026mut self, plan: \u0026LogicalPlan) -\u003e Result\u003cbool\u003e; fn post_visit(\u0026mut self, plan: \u0026LogicalPlan) -\u003e Result\u003cbool\u003e; } pub trait PlanRewriter { fn rewrite(\u0026mut self, plan: LogicalPlan) -\u003e Result\u003cLogicalPlan\u003e; } // Example: Predicate pushdown implemented as a visitor struct PredicatePushdown; impl PlanRewriter for PredicatePushdown { fn rewrite(\u0026mut self, plan: LogicalPlan) -\u003e Result\u003cLogicalPlan\u003e { match plan { LogicalPlan::Filter { predicate, input } =\u003e { // Try to push predicate down into the input node self.push_predicate_down(predicate, *input) } _ =\u003e Ok(plan), } } } Each optimization rule is implemented as a separate visitor/rewriter, making it easy to add new optimizations independently.\nError Propagation Pattern Errors use the thiserror crate for derived Error implementations and the ? operator for propagation:\nuse thiserror::Error; #[derive(Error, Debug)] pub enum StorageError { #[error(\"page {0} not found\")] PageNotFound(PageId), #[error(\"WAL write failed: {0}\")] WalWriteFailed(#[from] std::io::Error), #[error(\"checksum mismatch on page {page_id}: expected {expected}, got {actual}\")] ChecksumMismatch { page_id: PageId, expected: u32, actual: u32, }, } // Errors propagate cleanly with ? fn read_page(\u0026self, page_id: PageId) -\u003e Result\u003cPage, StorageError\u003e { let data = self.disk.read(page_id)?; // io::Error -\u003e StorageError via From let page = Page::from_bytes(\u0026data)?; page.verify_checksum()?; Ok(page) } Where to Start If you are new to the codebase, here is a recommended exploration path:\nStart with thunder-common/src/types.rs to understand the fundamental types. Read thunder-common/src/error.rs to see how errors are structured. Explore thunder-storage/src/page.rs to understand the page format. Read thunder-storage/src/wal.rs (at least the public API) to understand durability. Trace a simple query from thunder-sql/src/parser.rs through analyzer.rs, optimizer.rs, planner.rs, and into thunder-query/src/executor.rs. Read thunder-protocol/src/postgres.rs to see how client connections are handled. Finally, read thunder-server/src/main.rs and engine.rs to see how everything is wired together. This path takes you from the foundations through the storage engine, query processing pipeline, protocol handling, and finally the server orchestration layer.\n","categories":"","description":"A detailed walkthrough of the ThunderDB codebase -- workspace structure, crate dependency graph, key source files, external dependencies, and design patterns used throughout the project.","excerpt":"A detailed walkthrough of the ThunderDB codebase -- workspace …","ref":"/docs/docs/contributor/codebase-guide/","tags":"","title":"Codebase Guide"},{"body":"Configuration ThunderDB is configured through a TOML configuration file, typically located at /etc/thunderdb/thunderdb.toml. Every setting can also be overridden via environment variables, making it easy to customize behavior in containerized deployments.\nConfiguration File Format The configuration file is organized into the following sections:\n[node] [network] [storage] [cluster] [security] [logging] Complete Reference Configuration Below is a fully annotated configuration file with all available settings and their defaults:\n# ============================================================================= # ThunderDB Configuration File # ============================================================================= # ----------------------------------------------------------------------------- # Node Settings # ----------------------------------------------------------------------------- [node] # Unique identifier for this node in the cluster. # Must be unique across all nodes. In Kubernetes, this is typically derived # from the pod ordinal index. node_id = 1 # ----------------------------------------------------------------------------- # Network Settings # ----------------------------------------------------------------------------- [network] # Address to bind all listeners to. # Use \"0.0.0.0\" to listen on all interfaces, or a specific IP to restrict. listen_addr = \"0.0.0.0\" # PostgreSQL wire protocol port. # Compatible with psql, pgcli, and all PostgreSQL client libraries. pg_port = 5432 # MySQL wire protocol port. # Compatible with mysql CLI and all MySQL client libraries. mysql_port = 3306 # RESP (Redis Serialization Protocol) port. # Compatible with redis-cli and all Redis client libraries. resp_port = 6379 # HTTP API port. # Used for REST API, admin endpoints, metrics, and health checks. http_port = 8088 # gRPC port. # Used for inter-node communication and the native gRPC client API. grpc_port = 9090 # ----------------------------------------------------------------------------- # Storage Settings # ----------------------------------------------------------------------------- [storage] # Directory for storing data files (pages, indexes, metadata). data_dir = \"/var/lib/thunderdb/data\" # Directory for write-ahead log (WAL) files. # For best performance, place on a separate disk from data_dir. wal_dir = \"/var/lib/thunderdb/wal\" # Size of the buffer pool (in-memory page cache). # This is the single most important tuning parameter. Larger values improve # read performance by keeping more pages in memory. # Supports suffixes: KB, MB, GB. buffer_pool_size = \"128MB\" # Size of the WAL write buffer. # Larger values improve write throughput by batching WAL writes. wal_buffer_size = \"16MB\" # Size of each data page. # Changing this after initialization requires a full data migration. # Valid values: 4KB, 8KB, 16KB, 32KB. page_size = \"16KB\" # Interval between automatic checkpoints. # Checkpoints flush dirty pages to disk, reducing recovery time. # Lower values reduce recovery time but increase I/O. checkpoint_interval = \"60s\" # Number of threads dedicated to background compaction. # More threads speed up compaction but consume CPU. compaction_threads = 2 # Enable direct I/O to bypass the OS page cache. # Recommended for production to avoid double-caching. direct_io = false # Enable compression for data pages on disk. # Reduces storage requirements at a small CPU cost. compression = true # Compression algorithm to use when compression is enabled. # Options: \"Lz4\" (fast), \"Snappy\" (balanced), \"Zstd\" (high ratio). compression_algorithm = \"Lz4\" # Maximum WAL size before forcing a checkpoint. # When the WAL reaches this size, a checkpoint is triggered regardless # of the checkpoint_interval. max_wal_size = \"1GB\" # Whether to flush WAL to disk on every commit. # true: Guarantees durability (no data loss on crash). Recommended for production. # false: Better write performance but risks losing the last few transactions on crash. sync_commit = true # ----------------------------------------------------------------------------- # Cluster Settings # ----------------------------------------------------------------------------- [cluster] # Cluster name. All nodes in the same cluster must use the same name. cluster_name = \"default\" # List of peer node addresses (host:grpc_port). # Exclude the current node's address. peers = [] # Raft election timeout. # If a follower doesn't hear from the leader within this duration, # it starts a new election. Must be greater than raft_heartbeat_interval. # For WAN deployments, increase to 3-5s. raft_election_timeout = \"1s\" # Raft heartbeat interval. # The leader sends heartbeats at this interval. # Must be significantly less than raft_election_timeout (typically 1/10th). raft_heartbeat_interval = \"100ms\" # Number of copies of each data region. # 3 is recommended for production (tolerates 1 node failure). # Cannot exceed the number of nodes in the cluster. replication_factor = 3 # Maximum size of a single data region before it is split. # Smaller regions enable finer-grained load balancing. max_region_size = \"256MB\" # Minimum size of a single data region before it is merged. # Prevents excessive fragmentation from many small regions. min_region_size = \"64MB\" # Enable automatic region balancing across nodes. # When enabled, the leader periodically rebalances regions # to maintain even distribution. auto_balance = true # ----------------------------------------------------------------------------- # Security Settings # ----------------------------------------------------------------------------- [security] # Enable client authentication. # When false, all connections are accepted without credentials. authentication_enabled = false # Enable TLS for all client-facing protocols. tls_enabled = false # Path to the TLS certificate file (PEM format). tls_cert_path = \"\" # Path to the TLS private key file (PEM format). tls_key_path = \"\" # Superuser account name. superuser = \"admin\" # Superuser password (plaintext, for initial setup only). # In production, use THUNDERDB_SUPERUSER_PASSWORD_HASH environment variable # with an Argon2 hash instead. superuser_password = \"\" # ----------------------------------------------------------------------------- # Logging Settings # ----------------------------------------------------------------------------- [logging] # Log level. Options: \"trace\", \"debug\", \"info\", \"warn\", \"error\". # Use \"info\" for production, \"debug\" for development, \"trace\" for deep debugging. level = \"info\" # Log output format. Options: \"text\" (human-readable), \"json\" (structured). # Use \"json\" for production environments with log aggregation. format = \"text\" # Enable slow query logging. # Queries exceeding the threshold are logged at WARN level. slow_query_enabled = true # Threshold for slow query logging. # Queries taking longer than this are logged. slow_query_threshold = \"1s\" Section Reference [node] Parameter Type Default Description node_id integer 1 Unique node identifier within the cluster. [network] Parameter Type Default Description listen_addr string \"0.0.0.0\" Bind address for all listeners. pg_port integer 5432 PostgreSQL wire protocol port. mysql_port integer 3306 MySQL wire protocol port. resp_port integer 6379 RESP (Redis) wire protocol port. http_port integer 8088 HTTP API and admin endpoint port. grpc_port integer 9090 gRPC port for inter-node and client communication. [storage] Parameter Type Default Description data_dir string \"/var/lib/thunderdb/data\" Data file storage directory. wal_dir string \"/var/lib/thunderdb/wal\" WAL file storage directory. buffer_pool_size size \"128MB\" In-memory page cache size. wal_buffer_size size \"16MB\" WAL write buffer size. page_size size \"16KB\" Data page size. Immutable after initialization. checkpoint_interval duration \"60s\" Automatic checkpoint interval. compaction_threads integer 2 Background compaction thread count. direct_io boolean false Bypass OS page cache with direct I/O. compression boolean true Enable on-disk page compression. compression_algorithm string \"Lz4\" Compression algorithm: Lz4, Snappy, or Zstd. max_wal_size size \"1GB\" Maximum WAL size before forced checkpoint. sync_commit boolean true Flush WAL to disk on every commit. [cluster] Parameter Type Default Description cluster_name string \"default\" Cluster name shared by all nodes. peers array [] Peer node addresses in \"host:port\" format. raft_election_timeout duration \"1s\" Raft follower election timeout. raft_heartbeat_interval duration \"100ms\" Raft leader heartbeat interval. replication_factor integer 3 Number of region replicas. max_region_size size \"256MB\" Region split threshold. min_region_size size \"64MB\" Region merge threshold. auto_balance boolean true Enable automatic region rebalancing. [security] Parameter Type Default Description authentication_enabled boolean false Require client authentication. tls_enabled boolean false Enable TLS encryption. tls_cert_path string \"\" Path to TLS certificate (PEM). tls_key_path string \"\" Path to TLS private key (PEM). superuser string \"admin\" Superuser account name. superuser_password string \"\" Superuser password (plaintext). [logging] Parameter Type Default Description level string \"info\" Log level: trace, debug, info, warn, error. format string \"text\" Log format: text or json. slow_query_enabled boolean true Enable slow query logging. slow_query_threshold duration \"1s\" Slow query time threshold. Environment Variable Overrides Every configuration parameter can be overridden by an environment variable. This is especially useful for Docker and Kubernetes deployments where secrets and per-instance values should not be baked into configuration files.\nEnvironment Variable Overrides Example THUNDERDB_DATA_DIR storage.data_dir /mnt/ssd/thunderdb/data THUNDERDB_WAL_DIR storage.wal_dir /mnt/ssd/thunderdb/wal THUNDERDB_LOG_LEVEL logging.level debug THUNDERDB_SUPERUSER_PASSWORD_HASH security.superuser_password argon2:$argon2id$v=19$... THUNDERDB_NODE_ID node.node_id 2 THUNDERDB_LISTEN_ADDR network.listen_addr 0.0.0.0 THUNDERDB_PG_PORT network.pg_port 15432 THUNDERDB_MYSQL_PORT network.mysql_port 13306 THUNDERDB_RESP_PORT network.resp_port 16379 THUNDERDB_HTTP_PORT network.http_port 18088 THUNDERDB_GRPC_PORT network.grpc_port 19090 Precedence: Environment variables take precedence over values in the configuration file. Command-line flags (if any) take precedence over both.\nUsing Environment Variables with Docker docker run -d \\ -e THUNDERDB_NODE_ID=1 \\ -e THUNDERDB_LISTEN_ADDR=0.0.0.0 \\ -e THUNDERDB_LOG_LEVEL=info \\ -e THUNDERDB_SUPERUSER_PASSWORD_HASH='argon2:$argon2id$v=19$m=65536,t=3,p=4$...' \\ -e THUNDERDB_DATA_DIR=/var/lib/thunderdb/data \\ -e THUNDERDB_WAL_DIR=/var/lib/thunderdb/wal \\ thunderdb:latest Using Environment Variables with systemd Add an override file:\nsudo systemctl edit thunderdb [Service] Environment=\"THUNDERDB_LOG_LEVEL=debug\" Environment=\"THUNDERDB_SUPERUSER_PASSWORD_HASH=argon2:$argon2id$v=19$...\" Performance Tuning Guide ThunderDB’s HTAP architecture means it must be tuned differently depending on whether your workload leans toward OLTP (transactional), OLAP (analytical), or a mix of both.\nOLTP-Optimized Configuration For workloads dominated by short, high-frequency transactions (point lookups, inserts, updates):\n[storage] # Large buffer pool to keep hot rows in memory. # Aim for 60-70% of available system RAM. buffer_pool_size = \"8GB\" # Moderate WAL buffer -- OLTP writes are typically small. wal_buffer_size = \"32MB\" # Ensure every commit is durable. sync_commit = true # Frequent checkpoints reduce recovery time after crashes. checkpoint_interval = \"30s\" # Fewer compaction threads needed; OLTP generates less bulk data. compaction_threads = 2 # Bypass OS cache to avoid double-buffering. direct_io = true # Lz4 for minimal CPU overhead on the write path. compression = true compression_algorithm = \"Lz4\" # Smaller max WAL keeps recovery time bounded. max_wal_size = \"512MB\" Key principles:\nMaximize buffer pool size to serve reads from memory. Use sync_commit = true to guarantee durability. Lower checkpoint_interval to reduce crash recovery time. Use Lz4 compression for its speed advantage on the write path. OLAP-Optimized Configuration For workloads dominated by large scans, aggregations, and batch processing:\n[storage] # Moderate buffer pool -- OLAP scans are sequential and don't benefit # as much from caching random pages. buffer_pool_size = \"4GB\" # Large WAL buffer to handle bulk writes efficiently. wal_buffer_size = \"128MB\" # Async commit is acceptable if some data loss on crash is tolerable. sync_commit = false # Less frequent checkpoints to reduce I/O during long-running queries. checkpoint_interval = \"300s\" # More compaction threads for faster background processing of bulk data. compaction_threads = 8 # Direct I/O is still beneficial for large sequential reads. direct_io = true # Zstd compression for maximum space savings on large datasets. compression = true compression_algorithm = \"Zstd\" # Larger max WAL to avoid checkpoint storms during bulk loads. max_wal_size = \"4GB\" Key principles:\nAllocate more to WAL buffer for batch write throughput. Use more compaction threads to keep up with bulk data ingestion. Use Zstd compression to minimize storage costs for large datasets. Larger max_wal_size and checkpoint_interval reduce I/O interference with queries. Mixed HTAP Configuration For workloads with both transactional and analytical queries (the most common ThunderDB use case):\n[storage] # Balance between caching hot transactional data and leaving room # for analytical query memory needs. buffer_pool_size = \"6GB\" # Balanced WAL buffer. wal_buffer_size = \"64MB\" # Durability is important for the transactional component. sync_commit = true # Moderate checkpoint interval balances recovery time and I/O. checkpoint_interval = \"60s\" # Moderate compaction thread count. compaction_threads = 4 # Direct I/O recommended. direct_io = true # Lz4 is a good default balance of speed and compression. compression = true compression_algorithm = \"Lz4\" # Moderate max WAL size. max_wal_size = \"1GB\" Memory Sizing Guide Use the following guidelines to size ThunderDB’s memory parameters based on available system RAM:\nAvailable RAM Buffer Pool WAL Buffer Recommended For 8 GB 4 GB 32 MB Development / Small production 16 GB 10 GB 64 MB Medium OLTP workloads 32 GB 20 GB 128 MB Large OLTP / Mixed HTAP 64 GB 40 GB 256 MB Heavy HTAP workloads 128 GB 80 GB 512 MB Large-scale analytics General rules:\nAllocate 50-70% of total RAM to buffer_pool_size. Reserve at least 2-4 GB for the OS, file system cache, and other processes. The WAL buffer should be 0.5-1% of the buffer pool size. For Kubernetes, set resource requests to the sum of buffer pool + WAL buffer + 2 GB overhead, and limits to 1.5x the requests. Compression Algorithm Comparison Algorithm Compression Ratio Compression Speed Decompression Speed Best For Lz4 Low-Medium Very Fast Very Fast OLTP, low-latency reads Snappy Medium Fast Fast General purpose Zstd High Moderate Fast OLAP, storage-constrained OS-Level Tuning For optimal performance, apply these OS-level settings on Linux:\n# Increase file descriptor limits echo \"thunder soft nofile 65535\" \u003e\u003e /etc/security/limits.conf echo \"thunder hard nofile 65535\" \u003e\u003e /etc/security/limits.conf # Reduce swappiness (prefer keeping data in RAM) echo \"vm.swappiness=1\" \u003e\u003e /etc/sysctl.conf # Increase the number of memory map areas echo \"vm.max_map_count=262144\" \u003e\u003e /etc/sysctl.conf # Increase network buffer sizes for high-throughput workloads echo \"net.core.somaxconn=65535\" \u003e\u003e /etc/sysctl.conf echo \"net.ipv4.tcp_max_syn_backlog=65535\" \u003e\u003e /etc/sysctl.conf # Apply changes sysctl -p Disk I/O Tuning For SSD-backed storage:\n# Use noop or none scheduler for SSDs echo \"none\" \u003e /sys/block/sda/queue/scheduler # Set readahead to 256 KB for SSDs (reduce for random I/O workloads) blockdev --setra 512 /dev/sda For best results, place data_dir and wal_dir on separate physical disks or volumes. WAL writes are sequential and benefit from dedicated I/O bandwidth.\n","categories":"","description":"Complete configuration reference for ThunderDB including TOML settings, environment variable overrides, and performance tuning guides.","excerpt":"Complete configuration reference for ThunderDB including TOML …","ref":"/docs/docs/administrator/configuration/","tags":"","title":"Configuration"},{"body":"SQL Reference ThunderDB implements a rich SQL dialect that is largely compatible with PostgreSQL. This reference documents every statement, data type, operator, and function available in ThunderDB.\nData Types ThunderDB supports the following data types:\nNumeric Types Type Size Range Description BOOLEAN 1 byte true / false Logical boolean INT8 (alias TINYINT) 1 byte -128 to 127 8-bit signed integer INT16 (alias SMALLINT) 2 bytes -32,768 to 32,767 16-bit signed integer INT32 (alias INT, INTEGER) 4 bytes -2^31 to 2^31-1 32-bit signed integer INT64 (alias BIGINT) 8 bytes -2^63 to 2^63-1 64-bit signed integer FLOAT32 (alias REAL, FLOAT) 4 bytes IEEE 754 single 32-bit floating point FLOAT64 (alias DOUBLE PRECISION, DOUBLE) 8 bytes IEEE 754 double 64-bit floating point DECIMAL(p, s) (alias NUMERIC) variable Up to 38 digits Exact decimal with precision p and scale s String Types Type Max Size Description STRING (alias TEXT) 2 GB Variable-length unlimited string CHAR(n) n bytes Fixed-length string, blank-padded VARCHAR(n) n bytes Variable-length string with max length Binary Types Type Max Size Description BINARY (alias BYTEA) 2 GB Variable-length binary data Date \u0026 Time Types Type Size Description DATE 4 bytes Calendar date (year, month, day) TIME 8 bytes Time of day without timezone TIMESTAMP 8 bytes Date and time without timezone TIMESTAMPTZ (alias TIMESTAMP WITH TIME ZONE) 8 bytes Date and time with timezone INTERVAL 16 bytes Time duration Other Types Type Size Description UUID 16 bytes Universally unique identifier JSON variable JSON data stored as text JSONB variable JSON data stored in decomposed binary format (indexable) ARRAY variable One-dimensional array of any scalar type VECTOR(dim) dim * 4 bytes Fixed-dimension vector of FLOAT32 elements Type Casting ThunderDB supports explicit casting with CAST() and the :: operator:\nSELECT CAST('2025-01-15' AS DATE); SELECT '42'::INT64; SELECT '[1.0, 2.0, 3.0]'::VECTOR(3); DDL (Data Definition Language) CREATE TABLE Create a new table with specified columns, constraints, and storage engine.\nSyntax:\nCREATE TABLE [IF NOT EXISTS] [schema.]table_name ( column_name data_type [NOT NULL] [DEFAULT expr] [PRIMARY KEY], ... [CONSTRAINT name PRIMARY KEY (col1, col2, ...)], [CONSTRAINT name UNIQUE (col1, col2, ...)], [CONSTRAINT name FOREIGN KEY (col) REFERENCES other_table(col) [ON DELETE CASCADE|SET NULL|RESTRICT] [ON UPDATE CASCADE|SET NULL|RESTRICT]], [CONSTRAINT name CHECK (expression)] ) [ENGINE = ROW | COLUMNAR] [PARTITION BY RANGE|HASH|LIST (column)] [WITH (option = value, ...)]; Storage Engines:\nEngine Best For Description ROW (default) OLTP, transactional Row-oriented storage, optimized for point lookups and writes COLUMNAR OLAP, analytics Column-oriented storage, optimized for scans and aggregations Examples:\n-- Basic table CREATE TABLE users ( id BIGINT PRIMARY KEY, name VARCHAR(255) NOT NULL, email VARCHAR(255) NOT NULL UNIQUE, active BOOLEAN DEFAULT true, created_at TIMESTAMPTZ DEFAULT now() ); -- Table with composite primary key CREATE TABLE order_items ( order_id BIGINT NOT NULL, product_id BIGINT NOT NULL, quantity INT32 NOT NULL CHECK (quantity \u003e 0), unit_price DECIMAL(10,2) NOT NULL, PRIMARY KEY (order_id, product_id), FOREIGN KEY (order_id) REFERENCES orders(id) ON DELETE CASCADE ); -- Columnar table for analytics CREATE TABLE analytics_events ( event_id BIGINT PRIMARY KEY, user_id BIGINT, event_type VARCHAR(50) NOT NULL, properties JSONB, occurred_at TIMESTAMPTZ NOT NULL ) ENGINE = COLUMNAR; -- Partitioned table CREATE TABLE logs ( id BIGINT PRIMARY KEY, level VARCHAR(10), message TEXT, created_at TIMESTAMPTZ NOT NULL ) PARTITION BY RANGE (created_at); -- Table with vector column CREATE TABLE documents ( id BIGINT PRIMARY KEY, title VARCHAR(500), body TEXT, embedding VECTOR(1536), metadata JSONB ); -- Table with array columns CREATE TABLE tags ( id BIGINT PRIMARY KEY, name VARCHAR(100), labels ARRAY\u003cVARCHAR(50)\u003e ); -- Conditional creation CREATE TABLE IF NOT EXISTS sessions ( id UUID PRIMARY KEY DEFAULT gen_random_uuid(), user_id BIGINT NOT NULL REFERENCES users(id), token VARCHAR(255) NOT NULL, expires_at TIMESTAMPTZ NOT NULL ); DROP TABLE Remove a table and its data.\nSyntax:\nDROP TABLE [IF EXISTS] [schema.]table_name [CASCADE | RESTRICT]; Examples:\n-- Drop a table (error if it does not exist) DROP TABLE sessions; -- Drop only if it exists DROP TABLE IF EXISTS sessions; -- Drop and cascade to dependent objects (indexes, foreign keys) DROP TABLE users CASCADE; ALTER TABLE Modify an existing table structure.\nSyntax:\nALTER TABLE [schema.]table_name ADD COLUMN column_name data_type [constraints] | DROP COLUMN column_name [CASCADE] | ALTER COLUMN column_name SET DATA TYPE data_type | ALTER COLUMN column_name SET DEFAULT expr | ALTER COLUMN column_name DROP DEFAULT | ALTER COLUMN column_name SET NOT NULL | ALTER COLUMN column_name DROP NOT NULL | ADD CONSTRAINT constraint_def | DROP CONSTRAINT constraint_name | RENAME TO new_table_name | RENAME COLUMN old_name TO new_name; Examples:\n-- Add a column ALTER TABLE users ADD COLUMN phone VARCHAR(20); -- Drop a column ALTER TABLE users DROP COLUMN phone; -- Change column type ALTER TABLE users ALTER COLUMN name SET DATA TYPE VARCHAR(500); -- Add a check constraint ALTER TABLE orders ADD CONSTRAINT positive_total CHECK (total \u003e= 0); -- Rename a table ALTER TABLE users RENAME TO customers; -- Rename a column ALTER TABLE orders RENAME COLUMN total TO order_total; CREATE INDEX Create an index on one or more columns for faster lookups.\nSyntax:\nCREATE [UNIQUE] INDEX [IF NOT EXISTS] index_name ON [schema.]table_name USING method (column_name [ASC|DESC] [NULLS FIRST|LAST], ...) [WITH (option = value, ...)] [WHERE predicate]; Supported Index Methods:\nMethod Use Case Description BTREE (default) Equality, range, ordering Balanced tree, supports \u003c, \u003c=, =, \u003e=, \u003e HASH Equality only Hash table, supports only = HNSW Vector ANN search Hierarchical navigable small world graph IVF_PQ Large-scale vector search Inverted file with product quantization GIN Full-text, JSONB, arrays Generalized inverted index BRIN Large ordered datasets Block range index, very compact Examples:\n-- B-tree index (default) CREATE INDEX idx_orders_customer ON orders (customer_id); -- Unique index CREATE UNIQUE INDEX idx_users_email ON users (email); -- Composite index CREATE INDEX idx_orders_customer_date ON orders (customer_id, created_at DESC); -- Partial index (conditional) CREATE INDEX idx_orders_pending ON orders (created_at) WHERE status = 'pending'; -- HNSW vector index CREATE INDEX idx_docs_embedding ON documents USING HNSW (embedding) WITH (m = 16, ef_construction = 200, distance_metric = 'cosine'); -- IVF-PQ vector index for large datasets CREATE INDEX idx_docs_embedding_ivf ON documents USING IVF_PQ (embedding) WITH (nlist = 1024, m_pq = 64, distance_metric = 'l2'); -- GIN index for JSONB CREATE INDEX idx_events_properties ON analytics_events USING GIN (properties); -- GIN index for full-text search CREATE INDEX idx_docs_body_fts ON documents USING GIN (to_tsvector('english', body)); -- BRIN index for time-series data CREATE INDEX idx_logs_created ON logs USING BRIN (created_at) WITH (pages_per_range = 32); DROP INDEX Remove an index.\nSyntax:\nDROP INDEX [IF EXISTS] index_name [CASCADE | RESTRICT]; Examples:\nDROP INDEX idx_orders_customer; DROP INDEX IF EXISTS idx_docs_embedding; DML (Data Manipulation Language) INSERT Insert one or more rows into a table.\nSyntax:\nINSERT INTO [schema.]table_name [(column1, column2, ...)] VALUES (value1, value2, ...) [, (value1, value2, ...), ...] [ON CONFLICT (column) DO NOTHING | DO UPDATE SET col = expr, ...] [RETURNING column1, column2, ...]; Examples:\n-- Insert a single row INSERT INTO users (id, name, email) VALUES (1, 'Alice Johnson', 'alice@example.com'); -- Insert multiple rows INSERT INTO users (id, name, email) VALUES (2, 'Bob Smith', 'bob@example.com'), (3, 'Carol White', 'carol@example.com'), (4, 'Dave Brown', 'dave@example.com'); -- Insert with default values INSERT INTO users (id, name, email) VALUES (5, 'Eve Green', 'eve@example.com'); -- active defaults to true, created_at defaults to now() -- Upsert (insert or update on conflict) INSERT INTO users (id, name, email) VALUES (1, 'Alice J. Updated', 'alice@example.com') ON CONFLICT (id) DO UPDATE SET name = EXCLUDED.name; -- Insert and return the inserted row INSERT INTO orders (customer_id, product_id, quantity, total) VALUES (1, 42, 3, 149.97) RETURNING id, created_at; -- Insert from a SELECT INSERT INTO order_archive (id, customer_id, total, created_at) SELECT id, customer_id, total, created_at FROM orders WHERE created_at \u003c '2025-01-01'; -- Insert a vector INSERT INTO documents (id, title, embedding) VALUES (1, 'Quantum Computing', '[0.1, -0.23, 0.98, ...]'::VECTOR(1536)); UPDATE Modify existing rows in a table.\nSyntax:\nUPDATE [schema.]table_name SET column1 = expr1, column2 = expr2, ... [FROM other_table] [WHERE condition] [RETURNING column1, column2, ...]; Examples:\n-- Update a single row UPDATE users SET name = 'Alice Johnson-Smith' WHERE id = 1; -- Update multiple columns UPDATE orders SET status = 'shipped', shipped_at = now() WHERE id = 5012; -- Update with expression UPDATE products SET price = price * 1.10 WHERE category = 'electronics'; -- Update with subquery UPDATE orders SET status = 'vip' WHERE customer_id IN ( SELECT id FROM users WHERE membership = 'gold' ); -- Update with FROM clause (join-based update) UPDATE order_items oi SET unit_price = p.price FROM products p WHERE oi.product_id = p.id AND p.price_updated_at \u003e oi.created_at; -- Update and return modified rows UPDATE users SET active = false WHERE last_login \u003c now() - INTERVAL '90 days' RETURNING id, name, email; DELETE Remove rows from a table.\nSyntax:\nDELETE FROM [schema.]table_name [USING other_table] [WHERE condition] [RETURNING column1, column2, ...]; Examples:\n-- Delete a single row DELETE FROM users WHERE id = 42; -- Delete with condition DELETE FROM sessions WHERE expires_at \u003c now(); -- Delete with subquery DELETE FROM orders WHERE customer_id IN ( SELECT id FROM users WHERE active = false ); -- Delete with USING (join-based delete) DELETE FROM order_items oi USING orders o WHERE oi.order_id = o.id AND o.status = 'cancelled'; -- Delete all rows (truncate-like) DELETE FROM temp_imports; -- Delete and return removed rows DELETE FROM users WHERE active = false RETURNING id, name, email; SELECT Query data from one or more tables.\nSyntax:\nSELECT [DISTINCT] column_expr [AS alias], ... FROM [schema.]table_name [AS alias] [JOIN type join_table ON condition] [WHERE condition] [GROUP BY column_or_expr, ...] [HAVING condition] [ORDER BY column_or_expr [ASC|DESC] [NULLS FIRST|LAST], ...] [LIMIT count] [OFFSET count]; Basic Queries -- Select all columns SELECT * FROM users; -- Select specific columns SELECT name, email FROM users; -- Select with alias SELECT name AS customer_name, email AS customer_email FROM users; -- Select with expression SELECT name, price, price * 0.9 AS discounted_price FROM products; -- Distinct values SELECT DISTINCT category FROM products; -- Count rows SELECT COUNT(*) FROM orders; WHERE Clause -- Comparison operators SELECT * FROM products WHERE price \u003e 100; SELECT * FROM products WHERE price BETWEEN 50 AND 200; SELECT * FROM users WHERE name LIKE 'A%'; SELECT * FROM users WHERE name ILIKE '%smith%'; -- case-insensitive SELECT * FROM users WHERE email IS NOT NULL; -- Logical operators SELECT * FROM products WHERE category = 'electronics' AND price \u003c 500; SELECT * FROM products WHERE category = 'electronics' OR category = 'books'; -- IN operator SELECT * FROM orders WHERE status IN ('pending', 'processing', 'shipped'); -- NOT operator SELECT * FROM orders WHERE status NOT IN ('cancelled', 'refunded'); -- EXISTS subquery SELECT * FROM users u WHERE EXISTS ( SELECT 1 FROM orders o WHERE o.customer_id = u.id ); -- ANY / ALL SELECT * FROM products WHERE price \u003e ALL (SELECT price FROM products WHERE category = 'books'); -- JSONB operators SELECT * FROM analytics_events WHERE properties-\u003e\u003e'source' = 'mobile'; SELECT * FROM analytics_events WHERE properties @\u003e '{\"os\": \"ios\"}'::JSONB; JOIN Types -- INNER JOIN SELECT u.name, o.id AS order_id, o.total FROM users u INNER JOIN orders o ON u.id = o.customer_id; -- LEFT JOIN SELECT u.name, COUNT(o.id) AS order_count FROM users u LEFT JOIN orders o ON u.id = o.customer_id GROUP BY u.name; -- RIGHT JOIN SELECT u.name, o.id AS order_id FROM orders o RIGHT JOIN users u ON u.id = o.customer_id; -- FULL OUTER JOIN SELECT u.name, o.id AS order_id FROM users u FULL OUTER JOIN orders o ON u.id = o.customer_id; -- CROSS JOIN SELECT u.name, p.name AS product_name FROM users u CROSS JOIN products p; -- Self-join SELECT e.name AS employee, m.name AS manager FROM employees e LEFT JOIN employees m ON e.manager_id = m.id; -- Multiple joins SELECT u.name AS customer, p.name AS product, oi.quantity, oi.unit_price FROM orders o JOIN users u ON o.customer_id = u.id JOIN order_items oi ON o.id = oi.order_id JOIN products p ON oi.product_id = p.id WHERE o.status = 'shipped'; GROUP BY and HAVING -- Basic aggregation SELECT category, COUNT(*) AS product_count, AVG(price) AS avg_price FROM products GROUP BY category; -- Group by with HAVING SELECT customer_id, SUM(total) AS lifetime_value FROM orders GROUP BY customer_id HAVING SUM(total) \u003e 10000 ORDER BY lifetime_value DESC; -- Group by with expressions SELECT date_trunc('month', created_at) AS month, COUNT(*) AS order_count, SUM(total) AS revenue FROM orders WHERE created_at \u003e= '2025-01-01' GROUP BY date_trunc('month', created_at) ORDER BY month; -- Multiple aggregations SELECT category, COUNT(*) AS count, MIN(price) AS min_price, MAX(price) AS max_price, AVG(price) AS avg_price, SUM(price) AS total_value FROM products GROUP BY category ORDER BY total_value DESC; ORDER BY, LIMIT, and OFFSET -- Order ascending (default) SELECT * FROM products ORDER BY price; -- Order descending SELECT * FROM products ORDER BY price DESC; -- Multiple order columns SELECT * FROM products ORDER BY category ASC, price DESC; -- Null handling SELECT * FROM products ORDER BY discount NULLS LAST; -- Pagination SELECT * FROM products ORDER BY id LIMIT 20 OFFSET 40; -- Page 3, 20 items per page -- Top-N query SELECT * FROM orders ORDER BY total DESC LIMIT 10; Subqueries and CTEs -- Scalar subquery SELECT name, (SELECT COUNT(*) FROM orders o WHERE o.customer_id = u.id) AS order_count FROM users u; -- Derived table (subquery in FROM) SELECT top_customers.name, top_customers.total_spent FROM ( SELECT u.name, SUM(o.total) AS total_spent FROM users u JOIN orders o ON u.id = o.customer_id GROUP BY u.name ORDER BY total_spent DESC LIMIT 100 ) AS top_customers; -- Common Table Expression (CTE) WITH monthly_revenue AS ( SELECT date_trunc('month', created_at) AS month, SUM(total) AS revenue FROM orders GROUP BY 1 ) SELECT month, revenue, LAG(revenue) OVER (ORDER BY month) AS prev_month_revenue, revenue - LAG(revenue) OVER (ORDER BY month) AS revenue_change FROM monthly_revenue ORDER BY month; -- Recursive CTE (hierarchical data) WITH RECURSIVE org_tree AS ( -- Base case: top-level managers SELECT id, name, manager_id, 0 AS depth FROM employees WHERE manager_id IS NULL UNION ALL -- Recursive step SELECT e.id, e.name, e.manager_id, t.depth + 1 FROM employees e JOIN org_tree t ON e.manager_id = t.id ) SELECT * FROM org_tree ORDER BY depth, name; Window Functions -- Row number SELECT name, category, price, ROW_NUMBER() OVER (PARTITION BY category ORDER BY price DESC) AS rank FROM products; -- Running total SELECT id, created_at, total, SUM(total) OVER (ORDER BY created_at ROWS UNBOUNDED PRECEDING) AS running_total FROM orders; -- Moving average SELECT date, revenue, AVG(revenue) OVER ( ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW ) AS seven_day_avg FROM daily_revenue; -- Rank and Dense Rank SELECT name, category, price, RANK() OVER (PARTITION BY category ORDER BY price DESC) AS rank, DENSE_RANK() OVER (PARTITION BY category ORDER BY price DESC) AS dense_rank FROM products; -- Lead and Lag SELECT month, revenue, LAG(revenue, 1) OVER (ORDER BY month) AS prev_month, LEAD(revenue, 1) OVER (ORDER BY month) AS next_month FROM monthly_revenue; -- NTILE (buckets) SELECT name, price, NTILE(4) OVER (ORDER BY price) AS price_quartile FROM products; -- First/Last value SELECT DISTINCT category, FIRST_VALUE(name) OVER (PARTITION BY category ORDER BY price ASC) AS cheapest, FIRST_VALUE(name) OVER (PARTITION BY category ORDER BY price DESC) AS most_expensive FROM products; Set Operations -- UNION (deduplicated) SELECT name, email FROM users UNION SELECT name, email FROM archived_users; -- UNION ALL (keep duplicates) SELECT id, total FROM orders_2024 UNION ALL SELECT id, total FROM orders_2025; -- INTERSECT SELECT customer_id FROM orders INTERSECT SELECT id FROM users WHERE active = true; -- EXCEPT SELECT id FROM users EXCEPT SELECT customer_id FROM orders; Transactions ThunderDB supports full ACID transactions with multiple isolation levels.\nBEGIN Start a new transaction.\nBEGIN; -- or BEGIN TRANSACTION; -- or with isolation level BEGIN TRANSACTION ISOLATION LEVEL SERIALIZABLE; COMMIT Commit the current transaction, making all changes permanent.\nCOMMIT; -- or COMMIT TRANSACTION; ROLLBACK Roll back the current transaction, discarding all changes.\nROLLBACK; -- or ROLLBACK TRANSACTION; SAVEPOINT Create a savepoint within a transaction for partial rollback.\n-- Create a savepoint SAVEPOINT my_savepoint; -- Roll back to savepoint (undo changes since savepoint, but keep transaction open) ROLLBACK TO SAVEPOINT my_savepoint; -- Release a savepoint (no longer needed) RELEASE SAVEPOINT my_savepoint; SET TRANSACTION ISOLATION LEVEL Set the isolation level for the current transaction.\nSET TRANSACTION ISOLATION LEVEL READ COMMITTED; SET TRANSACTION ISOLATION LEVEL REPEATABLE READ; SET TRANSACTION ISOLATION LEVEL SERIALIZABLE; Isolation Levels:\nLevel Dirty Read Non-Repeatable Read Phantom Read Write Skew READ COMMITTED No Possible Possible Possible REPEATABLE READ No No Possible Possible SERIALIZABLE No No No No Transaction Examples -- Simple transaction BEGIN; UPDATE accounts SET balance = balance - 100 WHERE id = 1; UPDATE accounts SET balance = balance + 100 WHERE id = 2; INSERT INTO transfers (from_id, to_id, amount) VALUES (1, 2, 100); COMMIT; -- Transaction with savepoint BEGIN; INSERT INTO orders (customer_id, total) VALUES (42, 299.99); SAVEPOINT before_items; INSERT INTO order_items (order_id, product_id, quantity) VALUES (1, 10, 2); -- Oops, wrong product ROLLBACK TO SAVEPOINT before_items; INSERT INTO order_items (order_id, product_id, quantity) VALUES (1, 15, 2); COMMIT; -- Read-only transaction for consistent analytics BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ; SET TRANSACTION READ ONLY; SELECT COUNT(*) FROM orders WHERE status = 'pending'; SELECT SUM(total) FROM orders WHERE status = 'pending'; -- Both queries see the same snapshot COMMIT; -- Serializable transaction for inventory check BEGIN TRANSACTION ISOLATION LEVEL SERIALIZABLE; SELECT quantity FROM inventory WHERE product_id = 42; -- Application checks if quantity \u003e= requested amount UPDATE inventory SET quantity = quantity - 5 WHERE product_id = 42; INSERT INTO orders (customer_id, product_id, quantity) VALUES (1, 42, 5); COMMIT; -- If another transaction modified inventory concurrently, this will -- fail with a serialization error and should be retried Vector Operations ThunderDB natively supports vector embeddings for similarity search, enabling AI/ML workloads alongside traditional SQL.\nCreating Tables with Vector Columns -- 1536-dimensional vectors (OpenAI text-embedding-3-small) CREATE TABLE documents ( id BIGINT PRIMARY KEY, title VARCHAR(500), body TEXT, embedding VECTOR(1536) ); -- 768-dimensional vectors (sentence-transformers) CREATE TABLE products ( id BIGINT PRIMARY KEY, name VARCHAR(255), description TEXT, image_embed VECTOR(512), text_embed VECTOR(768) ); Inserting Vectors -- Insert with array literal INSERT INTO documents (id, title, embedding) VALUES (1, 'Hello World', '[0.1, -0.2, 0.3, ...]'::VECTOR(1536)); -- Insert from application (using bind parameter) INSERT INTO documents (id, title, embedding) VALUES ($1, $2, $3); -- where $3 is a float array of length 1536 Similarity Operators Operator Distance Metric Description \u003c-\u003e L2 (Euclidean) Euclidean distance between two vectors \u003c=\u003e Cosine Cosine distance (1 - cosine similarity) \u003c#\u003e Inner Product Negative inner product (for max inner product search) Vector Search Queries -- K-nearest neighbors with L2 distance SELECT id, title, embedding \u003c-\u003e $1 AS distance FROM documents ORDER BY embedding \u003c-\u003e $1 LIMIT 10; -- Cosine similarity search SELECT id, title, 1 - (embedding \u003c=\u003e $1) AS similarity FROM documents ORDER BY embedding \u003c=\u003e $1 LIMIT 10; -- Inner product search (for normalized vectors) SELECT id, title, embedding \u003c#\u003e $1 AS score FROM documents ORDER BY embedding \u003c#\u003e $1 LIMIT 10; -- Filtered vector search (hybrid search) SELECT id, title, embedding \u003c-\u003e $1 AS distance FROM documents WHERE category = 'science' AND published = true ORDER BY embedding \u003c-\u003e $1 LIMIT 10; -- Vector search with metadata join SELECT d.id, d.title, d.embedding \u003c-\u003e $1 AS distance, a.name AS author FROM documents d JOIN authors a ON d.author_id = a.id WHERE d.embedding \u003c-\u003e $1 \u003c 0.5 ORDER BY d.embedding \u003c-\u003e $1 LIMIT 20; Creating Vector Indexes -- HNSW index (recommended for most use cases) CREATE INDEX idx_docs_embed ON documents USING HNSW (embedding) WITH ( m = 16, -- Max connections per node ef_construction = 200, -- Build-time beam width distance_metric = 'cosine' -- 'l2', 'cosine', or 'inner_product' ); -- IVF-PQ index (for datasets \u003e 1M vectors) CREATE INDEX idx_docs_embed_ivf ON documents USING IVF_PQ (embedding) WITH ( nlist = 1024, -- Number of clusters m_pq = 64, -- Number of PQ sub-quantizers distance_metric = 'l2' ); Tuning ANN Search -- Set HNSW search beam width for the current session SET hnsw.ef_search = 128; -- Higher = more accurate but slower -- Set IVF-PQ probe count SET ivf.nprobe = 20; -- Higher = more accurate but slower -- Then run your query SELECT id, title, embedding \u003c-\u003e $1 AS distance FROM documents ORDER BY embedding \u003c-\u003e $1 LIMIT 10; Foreign Data Wrappers (FDW) ThunderDB can query data stored in external systems and join it with local tables. This enables data federation without ETL.\nCREATE SERVER Define a connection to an external data source.\n-- PostgreSQL server CREATE SERVER pg_production TYPE 'postgresql' OPTIONS ( host '10.0.1.50', port '5432', dbname 'production', user 'readonly', password 'secret' ); -- MySQL server CREATE SERVER mysql_legacy TYPE 'mysql' OPTIONS ( host '10.0.2.50', port '3306', dbname 'legacy_app', user 'reader', password 'secret' ); -- MongoDB server CREATE SERVER mongo_logs TYPE 'mongodb' OPTIONS ( connection_string 'mongodb://10.0.3.50:27017/logs', auth_database 'admin', user 'reader', password 'secret' ); -- Amazon S3 (Parquet files) CREATE SERVER s3_data_lake TYPE 's3' OPTIONS ( region 'us-east-1', bucket 'my-data-lake', access_key_id 'AKIAIOSFODNN7EXAMPLE', secret_access_key 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY' ); CREATE FOREIGN TABLE Map a remote table or collection to a local table definition.\n-- From PostgreSQL CREATE FOREIGN TABLE remote_users ( id BIGINT, name VARCHAR(255), email VARCHAR(255), active BOOLEAN ) SERVER pg_production OPTIONS (schema 'public', table 'users'); -- From MySQL CREATE FOREIGN TABLE legacy_orders ( order_id INT32, customer VARCHAR(100), total DECIMAL(10,2), order_date DATE ) SERVER mysql_legacy OPTIONS (table 'orders'); -- From MongoDB CREATE FOREIGN TABLE mongo_access_logs ( _id VARCHAR(24), user_id BIGINT, endpoint VARCHAR(255), status INT32, timestamp TIMESTAMPTZ ) SERVER mongo_logs OPTIONS (collection 'access_logs'); -- From S3 Parquet files CREATE FOREIGN TABLE s3_events ( event_id BIGINT, event_type VARCHAR(50), payload JSONB, created_at TIMESTAMPTZ ) SERVER s3_data_lake OPTIONS (path 'events/year=2025/', format 'parquet'); Querying Foreign Tables Foreign tables behave like regular tables in queries. ThunderDB pushes down predicates and projections to minimize data transfer.\n-- Query a foreign table directly SELECT * FROM remote_users WHERE active = true LIMIT 100; -- Join local and foreign tables SELECT u.name, u.email, COUNT(o.order_id) AS total_orders, SUM(o.total) AS lifetime_value FROM remote_users u JOIN legacy_orders o ON u.name = o.customer GROUP BY u.name, u.email ORDER BY lifetime_value DESC LIMIT 20; -- Cross-database federation: PostgreSQL + MySQL + MongoDB in one query SELECT u.name, o.total AS order_total, COUNT(l._id) AS access_count FROM remote_users u JOIN legacy_orders o ON u.name = o.customer LEFT JOIN mongo_access_logs l ON u.id = l.user_id GROUP BY u.name, o.total ORDER BY access_count DESC; -- Query S3 Parquet files SELECT event_type, COUNT(*) AS event_count, MIN(created_at) AS first_seen, MAX(created_at) AS last_seen FROM s3_events WHERE created_at \u003e= '2025-12-01' GROUP BY event_type ORDER BY event_count DESC; DROP SERVER and DROP FOREIGN TABLE -- Drop a foreign table DROP FOREIGN TABLE IF EXISTS remote_users; -- Drop a server (must drop foreign tables first, or use CASCADE) DROP SERVER IF EXISTS pg_production CASCADE; Built-in Functions Aggregate Functions Function Description COUNT(*) Count of rows COUNT(expr) Count of non-null values COUNT(DISTINCT expr) Count of distinct non-null values SUM(expr) Sum of values AVG(expr) Average of values MIN(expr) Minimum value MAX(expr) Maximum value ARRAY_AGG(expr) Collect values into an array STRING_AGG(expr, delimiter) Concatenate strings with delimiter BOOL_AND(expr) True if all values are true BOOL_OR(expr) True if any value is true STDDEV(expr) Sample standard deviation VARIANCE(expr) Sample variance PERCENTILE_CONT(fraction) Continuous percentile PERCENTILE_DISC(fraction) Discrete percentile String Functions Function Description Example LENGTH(s) String length LENGTH('hello') = 5 UPPER(s) Uppercase UPPER('hello') = 'HELLO' LOWER(s) Lowercase LOWER('HELLO') = 'hello' TRIM(s) Remove whitespace TRIM(' hi ') = 'hi' LTRIM(s) Left trim LTRIM(' hi') = 'hi' RTRIM(s) Right trim RTRIM('hi ') = 'hi' SUBSTRING(s, start, len) Extract substring SUBSTRING('hello', 2, 3) = 'ell' REPLACE(s, from, to) Replace occurrences REPLACE('hello', 'l', 'r') = 'herro' CONCAT(s1, s2, ...) Concatenate strings CONCAT('a', 'b', 'c') = 'abc' SPLIT_PART(s, delim, n) Split and extract SPLIT_PART('a.b.c', '.', 2) = 'b' REGEXP_MATCH(s, pattern) Regex match REGEXP_MATCH('abc123', '\\d+') = {'123'} REGEXP_REPLACE(s, p, r) Regex replace REGEXP_REPLACE('abc', '[a-z]', 'X', 'g') = 'XXX' STARTS_WITH(s, prefix) Prefix check STARTS_WITH('hello', 'he') = true MD5(s) MD5 hash MD5('hello') = '5d41402abc4b2a76...' Date \u0026 Time Functions Function Description Example now() Current timestamp with timezone 2025-12-15 10:30:00+00 current_date Current date 2025-12-15 current_time Current time 10:30:00+00 date_trunc(field, ts) Truncate to precision date_trunc('month', ts) date_part(field, ts) Extract field date_part('year', ts) = 2025 EXTRACT(field FROM ts) Extract field (SQL standard) EXTRACT(MONTH FROM ts) = 12 age(ts1, ts2) Interval between timestamps age(now(), created_at) ts + INTERVAL '...' Add interval now() + INTERVAL '7 days' ts - INTERVAL '...' Subtract interval now() - INTERVAL '1 hour' to_char(ts, format) Format timestamp to_char(now(), 'YYYY-MM-DD') to_timestamp(str, fmt) Parse timestamp to_timestamp('2025-01-15', 'YYYY-MM-DD') generate_series(start, stop, step) Generate time series See example below -- Generate a time series SELECT ts::DATE AS day FROM generate_series( '2025-01-01'::TIMESTAMP, '2025-01-31'::TIMESTAMP, '1 day'::INTERVAL ) AS ts; JSON / JSONB Functions Function / Operator Description Example -\u003e Get JSON element by key (returns JSON) data-\u003e'name' -\u003e\u003e Get JSON element by key (returns text) data-\u003e\u003e'name' #\u003e Get JSON element by path (returns JSON) data#\u003e'{address,city}' #\u003e\u003e Get JSON element by path (returns text) data#\u003e\u003e'{address,city}' @\u003e Contains data @\u003e '{\"active\": true}' \u003c@ Contained by '{\"a\":1}' \u003c@ data ? Key exists data ? 'email' jsonb_build_object(k,v,...) Construct JSONB jsonb_build_object('name', 'Alice') jsonb_agg(expr) Aggregate into JSON array jsonb_agg(name) jsonb_object_agg(k, v) Aggregate into JSON object jsonb_object_agg(key, value) jsonb_array_elements(j) Expand JSON array to rows jsonb_array_elements('[1,2,3]') jsonb_each(j) Expand JSON object to key-value rows jsonb_each('{\"a\":1}') jsonb_set(j, path, val) Set value at path jsonb_set(data, '{name}', '\"Bob\"') jsonb_strip_nulls(j) Remove null keys jsonb_strip_nulls(data) Mathematical Functions Function Description ABS(x) Absolute value CEIL(x) / CEILING(x) Round up FLOOR(x) Round down ROUND(x, d) Round to d decimal places TRUNC(x, d) Truncate to d decimal places MOD(x, y) Modulo POWER(x, y) x raised to power y SQRT(x) Square root LN(x) Natural logarithm LOG(base, x) Logarithm with base EXP(x) Exponential (e^x) RANDOM() Random value between 0 and 1 GREATEST(a, b, ...) Maximum of values LEAST(a, b, ...) Minimum of values Conditional Expressions -- CASE expression SELECT name, CASE WHEN price \u003c 10 THEN 'budget' WHEN price \u003c 100 THEN 'mid-range' ELSE 'premium' END AS tier FROM products; -- COALESCE (first non-null) SELECT COALESCE(nickname, name, 'Anonymous') AS display_name FROM users; -- NULLIF (return null if equal) SELECT NULLIF(discount, 0) AS effective_discount FROM products; -- IIF (inline if) SELECT name, IIF(active, 'Active', 'Inactive') AS status FROM users; System Commands -- Show server version SELECT version(); -- Show current database SELECT current_database(); -- Show current user SELECT current_user; -- Show all tables SHOW TABLES; -- Show table schema DESCRIBE users; -- or \\d users -- Show running queries SELECT * FROM thunder_catalog.running_queries; -- Show cluster status SELECT * FROM thunder_catalog.cluster_nodes; -- Show replication status SELECT * FROM thunder_catalog.replication_status; -- Cancel a running query SELECT thunder_cancel_query('query_id_here'); -- Analyze table statistics (for query planner) ANALYZE users; -- Vacuum (reclaim storage) VACUUM users; VACUUM FULL users; -- Rewrites table, reclaims maximum space ","categories":"","description":"Complete SQL language reference for ThunderDB covering DDL, DML, transactions, vector operations, foreign data wrappers, and built-in functions.","excerpt":"Complete SQL language reference for ThunderDB covering DDL, DML, …","ref":"/docs/docs/developer/sql-reference/","tags":"","title":"SQL Reference"},{"body":"Developer Guide ThunderDB is a distributed HTAP (Hybrid Transactional/Analytical Processing) database written in Rust. It gives application developers a single system that handles OLTP workloads, OLAP analytics, vector similarity search, federated queries across external data sources, and real-time change data capture — all accessible through the protocols and languages you already know.\nThis guide covers everything you need to integrate ThunderDB into your applications.\nWhat You Can Do with ThunderDB Connect via Multiple Protocols ThunderDB exposes four wire-compatible protocol endpoints so you can use your existing drivers and client libraries without modification:\nProtocol Default Port Use Case PostgreSQL 5432 Full SQL access via any PostgreSQL-compatible driver MySQL 3306 Full SQL access via any MySQL-compatible driver Redis (RESP) 6379 Key-value caching, pub/sub, and data structure commands HTTP / WebSocket 8088 REST API, GraphQL, and WebSocket streaming gRPC 9090 High-performance programmatic access for services Write Standard SQL ThunderDB supports a rich SQL dialect compatible with PostgreSQL. You can create tables, run transactional INSERT/UPDATE/DELETE operations, and execute complex analytical queries with joins, aggregations, window functions, and CTEs — all in one system.\n-- Transactional write INSERT INTO orders (customer_id, product_id, quantity, total) VALUES (1001, 42, 3, 149.97); -- Analytical query on the same data, instantly SELECT date_trunc('month', created_at) AS month, SUM(total) AS revenue, COUNT(*) AS order_count FROM orders WHERE created_at \u003e= '2025-01-01' GROUP BY 1 ORDER BY 1; Call REST, gRPC, and GraphQL APIs Beyond SQL wire protocols, ThunderDB provides modern API layers:\nREST API — JSON-over-HTTP endpoints for queries, schema management, cluster operations, and CDC subscriptions. gRPC API — Protobuf-based RPC for high-throughput, low-latency service-to-service communication. GraphQL API — Schema-introspectable query and mutation interface with real-time subscriptions. Perform Vector Similarity Search Store high-dimensional embeddings alongside your relational data and run approximate nearest-neighbor (ANN) searches using HNSW or IVF-PQ indexes. This enables retrieval-augmented generation (RAG), recommendation engines, and semantic search without a separate vector database.\n-- Create a table with a vector column CREATE TABLE documents ( id BIGINT PRIMARY KEY, title VARCHAR(255), body TEXT, embed VECTOR(1536) ); -- Find the 10 most similar documents SELECT id, title, embed \u003c-\u003e $1 AS distance FROM documents ORDER BY embed \u003c-\u003e $1 LIMIT 10; Subscribe to Change Data Capture (CDC) ThunderDB publishes a structured change stream for every table. Applications can subscribe to inserts, updates, and deletes in real time over WebSockets, gRPC streams, or webhook callbacks — enabling event-driven architectures, materialized views, and cross-system synchronization.\n# Subscribe to changes on the \"orders\" table via WebSocket wscat -c ws://localhost:8088/ws/events?table=orders Query External Data with Foreign Data Wrappers (FDW) Define foreign tables that reference data living in PostgreSQL, MySQL, MongoDB, S3, or other sources. ThunderDB pushes predicates down to the remote system and joins the results with local data in a single query.\nCREATE FOREIGN TABLE remote_users SERVER pg_production OPTIONS (schema 'public', table 'users'); SELECT u.name, o.total FROM remote_users u JOIN orders o ON u.id = o.customer_id; Guide Structure This Developer Guide is organized into four sections:\nSection Description API Reference Complete REST, gRPC, GraphQL, and WebSocket API documentation with curl examples SQL Reference DDL, DML, transactions, vector operations, and FDW syntax SDKs \u0026 Drivers Native Rust client and usage with PostgreSQL, MySQL, and Redis drivers in Python, Node.js, Go, and Rust Examples \u0026 Use Cases End-to-end application patterns: e-commerce, analytics, RAG pipelines, federation, CDC, caching, and IoT Quick Start 1. Connect with psql psql -h localhost -p 5432 -U thunder -d thunderdb 2. Create a Table CREATE TABLE sensors ( sensor_id BIGINT PRIMARY KEY, location VARCHAR(100), reading FLOAT64, recorded_at TIMESTAMPTZ DEFAULT now() ); 3. Insert Data INSERT INTO sensors (sensor_id, location, reading) VALUES (1, 'warehouse-a', 22.5), (2, 'warehouse-b', 19.8), (3, 'warehouse-a', 23.1); 4. Query SELECT location, AVG(reading) AS avg_temp FROM sensors GROUP BY location; location | avg_temp --------------+---------- warehouse-a | 22.80 warehouse-b | 19.80 5. Use the REST API curl -s http://localhost:8088/api/v1/query \\ -H \"Content-Type: application/json\" \\ -d '{\"sql\": \"SELECT * FROM sensors WHERE location = '\\''warehouse-a'\\''\"}' Authentication All ThunderDB protocol endpoints support the same authentication mechanisms:\nMethod Description Username / Password Standard credentials passed via protocol handshake or HTTP Basic Auth API Key Bearer token in the Authorization header for REST/gRPC/GraphQL mTLS Mutual TLS client certificates for zero-trust environments OIDC / JWT External identity provider tokens validated by ThunderDB See the Security section of the Administrator Guide for configuration details.\nNext Steps Dive into the API Reference to explore every endpoint. Read the SQL Reference for the full query language. Pick an SDK for your programming language. Follow a complete Example that matches your use case. ","categories":"","description":"Everything you need to build applications on ThunderDB — connect via PostgreSQL, MySQL, or Redis protocols, write SQL, call REST/gRPC/GraphQL APIs, perform vector search, and subscribe to real-time change data capture streams.","excerpt":"Everything you need to build applications on ThunderDB — connect via …","ref":"/docs/docs/developer/","tags":"","title":"Developer Guide"},{"body":"Monitoring Effective monitoring is essential for maintaining ThunderDB in production. This guide covers the built-in metrics endpoint, health checks, structured logging, and how to set up a complete monitoring stack with Prometheus, Grafana, and alerting.\nPrometheus Metrics Endpoint ThunderDB exposes metrics in Prometheus format at the HTTP admin endpoint:\nGET http://\u003chost\u003e:8088/admin/metrics Example Request curl http://localhost:8088/admin/metrics Example Response # HELP thunderdb_query_total Total number of queries executed # TYPE thunderdb_query_total counter thunderdb_query_total{protocol=\"pg\",status=\"success\"} 1542893 thunderdb_query_total{protocol=\"pg\",status=\"error\"} 127 thunderdb_query_total{protocol=\"mysql\",status=\"success\"} 89421 thunderdb_query_total{protocol=\"resp\",status=\"success\"} 2345678 # HELP thunderdb_query_duration_seconds Query execution time in seconds # TYPE thunderdb_query_duration_seconds histogram thunderdb_query_duration_seconds_bucket{protocol=\"pg\",le=\"0.001\"} 892345 thunderdb_query_duration_seconds_bucket{protocol=\"pg\",le=\"0.01\"} 1234567 thunderdb_query_duration_seconds_bucket{protocol=\"pg\",le=\"0.1\"} 1500000 thunderdb_query_duration_seconds_bucket{protocol=\"pg\",le=\"1.0\"} 1540000 thunderdb_query_duration_seconds_bucket{protocol=\"pg\",le=\"10.0\"} 1542893 thunderdb_query_duration_seconds_bucket{protocol=\"pg\",le=\"+Inf\"} 1542893 thunderdb_query_duration_seconds_sum{protocol=\"pg\"} 4521.34 thunderdb_query_duration_seconds_count{protocol=\"pg\"} 1542893 # HELP thunderdb_buffer_pool_hit_ratio Buffer pool cache hit ratio # TYPE thunderdb_buffer_pool_hit_ratio gauge thunderdb_buffer_pool_hit_ratio 0.9847 # HELP thunderdb_buffer_pool_pages_total Total pages in buffer pool # TYPE thunderdb_buffer_pool_pages_total gauge thunderdb_buffer_pool_pages_total{state=\"clean\"} 7234 thunderdb_buffer_pool_pages_total{state=\"dirty\"} 512 thunderdb_buffer_pool_pages_total{state=\"free\"} 446 # HELP thunderdb_wal_size_bytes Current WAL size in bytes # TYPE thunderdb_wal_size_bytes gauge thunderdb_wal_size_bytes 134217728 # HELP thunderdb_connections_active Number of active client connections # TYPE thunderdb_connections_active gauge thunderdb_connections_active{protocol=\"pg\"} 42 thunderdb_connections_active{protocol=\"mysql\"} 15 thunderdb_connections_active{protocol=\"resp\"} 128 thunderdb_connections_active{protocol=\"http\"} 3 thunderdb_connections_active{protocol=\"grpc\"} 8 # HELP thunderdb_replication_lag_seconds Replication lag from leader in seconds # TYPE thunderdb_replication_lag_seconds gauge thunderdb_replication_lag_seconds{peer=\"node-2\"} 0.003 thunderdb_replication_lag_seconds{peer=\"node-3\"} 0.005 # HELP thunderdb_transactions_total Total transactions # TYPE thunderdb_transactions_total counter thunderdb_transactions_total{status=\"committed\"} 987654 thunderdb_transactions_total{status=\"aborted\"} 1234 # HELP thunderdb_checkpoint_duration_seconds Time taken for last checkpoint # TYPE thunderdb_checkpoint_duration_seconds gauge thunderdb_checkpoint_duration_seconds 2.34 # HELP thunderdb_regions_total Number of data regions # TYPE thunderdb_regions_total gauge thunderdb_regions_total{node=\"1\"} 128 thunderdb_regions_total{node=\"2\"} 125 thunderdb_regions_total{node=\"3\"} 127 # HELP thunderdb_raft_term Current Raft term # TYPE thunderdb_raft_term gauge thunderdb_raft_term 5 # HELP thunderdb_compaction_pending Number of pending compaction tasks # TYPE thunderdb_compaction_pending gauge thunderdb_compaction_pending 3 Key Metrics Reference Metric Type Description thunderdb_query_total counter Total queries executed, labeled by protocol and status. thunderdb_query_duration_seconds histogram Query execution latency distribution. thunderdb_buffer_pool_hit_ratio gauge Ratio of page reads served from buffer pool (target: \u003e0.95). thunderdb_buffer_pool_pages_total gauge Buffer pool page counts by state (clean, dirty, free). thunderdb_wal_size_bytes gauge Current size of the WAL on disk. thunderdb_connections_active gauge Active connections per protocol. thunderdb_replication_lag_seconds gauge Replication lag from leader to each follower. thunderdb_transactions_total counter Transactions by outcome (committed, aborted). thunderdb_checkpoint_duration_seconds gauge Duration of the most recent checkpoint. thunderdb_regions_total gauge Number of data regions per node. thunderdb_raft_term gauge Current Raft consensus term. thunderdb_compaction_pending gauge Pending background compaction tasks. thunderdb_disk_usage_bytes gauge Disk usage by category (data, wal, temp). thunderdb_memory_usage_bytes gauge Memory usage by component (buffer_pool, wal_buffer, query). thunderdb_slow_queries_total counter Count of queries exceeding the slow query threshold. Prometheus Scrape Configuration ThunderDB ships with a ready-to-use Prometheus configuration in deploy/prometheus/.\nprometheus.yml # deploy/prometheus/prometheus.yml global: scrape_interval: 15s evaluation_interval: 15s rule_files: - /etc/prometheus/rules/*.yml alerting: alertmanagers: - static_configs: - targets: - alertmanager:9093 scrape_configs: - job_name: \"thunderdb\" metrics_path: /admin/metrics scrape_interval: 10s scrape_timeout: 5s # For static deployments: static_configs: - targets: - \"thunderdb-1:8088\" - \"thunderdb-2:8088\" - \"thunderdb-3:8088\" labels: cluster: \"production\" # For Kubernetes deployments, replace static_configs with: # kubernetes_sd_configs: # - role: pod # namespaces: # names: # - thunderdb # relabel_configs: # - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape] # action: keep # regex: \"true\" # - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port] # action: replace # target_label: __address__ # regex: (.+) # replacement: $1 # - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path] # action: replace # target_label: __metrics_path__ # regex: (.+) Running Prometheus docker run -d \\ --name prometheus \\ -p 9091:9090 \\ -v $(pwd)/deploy/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro \\ -v $(pwd)/deploy/prometheus/rules:/etc/prometheus/rules:ro \\ prom/prometheus:latest Grafana Dashboards ThunderDB provides pre-built Grafana dashboards in deploy/grafana/. These dashboards give you immediate visibility into cluster health, query performance, storage utilization, and replication status.\nAvailable Dashboards Dashboard File Description Cluster Overview deploy/grafana/dashboards/cluster-overview.json High-level cluster health, node status, region distribution. Query Performance deploy/grafana/dashboards/query-performance.json Query latency percentiles, throughput, slow queries by protocol. Storage deploy/grafana/dashboards/storage.json Buffer pool hit rate, WAL size, disk usage, compaction status. Replication deploy/grafana/dashboards/replication.json Replication lag, Raft term changes, leader elections. Connections deploy/grafana/dashboards/connections.json Active connections by protocol, connection rate, errors. Setting Up Grafana docker run -d \\ --name grafana \\ -p 3000:3000 \\ -v $(pwd)/deploy/grafana/provisioning:/etc/grafana/provisioning:ro \\ -v $(pwd)/deploy/grafana/dashboards:/var/lib/grafana/dashboards:ro \\ -e GF_SECURITY_ADMIN_PASSWORD=admin \\ grafana/grafana:latest Grafana is accessible at http://localhost:3000 (default credentials: admin/admin).\nProvisioning Configuration The provisioning directory automatically configures the Prometheus data source and dashboard imports:\n# deploy/grafana/provisioning/datasources/prometheus.yml apiVersion: 1 datasources: - name: Prometheus type: prometheus access: proxy url: http://prometheus:9090 isDefault: true editable: false # deploy/grafana/provisioning/dashboards/thunderdb.yml apiVersion: 1 providers: - name: ThunderDB orgId: 1 folder: ThunderDB type: file disableDeletion: false editable: true options: path: /var/lib/grafana/dashboards foldersFromFilesStructure: false Key Dashboard Panels Cluster Overview dashboard includes:\nCluster status indicator (healthy/degraded/critical) Node status table with uptime, role, and region count Total queries per second across all protocols Average query latency (p50, p95, p99) Buffer pool hit ratio gauge Active connections count Query Performance dashboard includes:\nQuery throughput by protocol (QPS) Query latency histograms (p50, p95, p99, p99.9) Slow query count over time Query error rate Top slow queries table Query type distribution (SELECT, INSERT, UPDATE, DELETE) Health Check Endpoints ThunderDB exposes three health check endpoints for load balancers, orchestrators, and monitoring systems.\nGET /admin/health Returns the overall health status of the node, including subsystem checks.\ncurl http://localhost:8088/admin/health Response (healthy):\n{ \"status\": \"healthy\", \"version\": \"0.1.0\", \"uptime_seconds\": 86400, \"node_id\": 1, \"cluster_role\": \"leader\", \"checks\": { \"storage\": \"ok\", \"wal\": \"ok\", \"raft\": \"ok\", \"buffer_pool\": \"ok\" } } Response (degraded):\n{ \"status\": \"degraded\", \"version\": \"0.1.0\", \"uptime_seconds\": 86400, \"node_id\": 2, \"cluster_role\": \"follower\", \"checks\": { \"storage\": \"ok\", \"wal\": \"ok\", \"raft\": \"degraded: replication lag 5.2s\", \"buffer_pool\": \"ok\" } } HTTP status codes:\n200 OK – Node is healthy. 503 Service Unavailable – Node is unhealthy or degraded. GET /admin/live Liveness probe. Returns 200 OK if the process is running and responsive. Used by Kubernetes liveness probes to determine if the pod should be restarted.\ncurl http://localhost:8088/admin/live Response:\n{ \"status\": \"alive\" } GET /admin/ready Readiness probe. Returns 200 OK if the node is ready to serve traffic (storage initialized, WAL recovered, cluster joined). Used by Kubernetes readiness probes and load balancers.\ncurl http://localhost:8088/admin/ready Response (ready):\n{ \"status\": \"ready\", \"storage_initialized\": true, \"wal_recovered\": true, \"cluster_joined\": true, \"regions_loaded\": 128 } Response (not ready):\n{ \"status\": \"not_ready\", \"storage_initialized\": true, \"wal_recovered\": true, \"cluster_joined\": false, \"regions_loaded\": 0 } HTTP status codes:\n200 OK – Node is ready to serve traffic. 503 Service Unavailable – Node is not ready. Logging ThunderDB produces structured logs that can be consumed by log aggregation systems such as the ELK stack, Loki, or Splunk.\nLog Levels Level Description Use Case trace Very detailed internal tracing Deep debugging of specific subsystems debug Detailed operational information Development and troubleshooting info Normal operational events Production default warn Potentially problematic situations Slow queries, approaching limits error Error conditions Failed operations, connectivity issues Structured Log Format When format = \"json\" is configured, logs are emitted as JSON lines:\n{\"timestamp\":\"2026-01-15T10:30:45.123Z\",\"level\":\"info\",\"target\":\"thunderdb::server\",\"message\":\"Server started\",\"node_id\":1,\"pg_port\":5432,\"mysql_port\":3306,\"resp_port\":6379,\"http_port\":8088,\"grpc_port\":9090} {\"timestamp\":\"2026-01-15T10:30:45.456Z\",\"level\":\"info\",\"target\":\"thunderdb::cluster\",\"message\":\"Cluster joined\",\"node_id\":1,\"cluster_name\":\"production\",\"role\":\"follower\",\"term\":1} {\"timestamp\":\"2026-01-15T10:30:46.789Z\",\"level\":\"info\",\"target\":\"thunderdb::cluster\",\"message\":\"Leader elected\",\"node_id\":1,\"leader_id\":1,\"term\":2} {\"timestamp\":\"2026-01-15T10:31:15.012Z\",\"level\":\"warn\",\"target\":\"thunderdb::query\",\"message\":\"Slow query detected\",\"duration_ms\":2345,\"protocol\":\"pg\",\"query\":\"SELECT * FROM orders JOIN products ON ...\",\"client\":\"10.0.1.50:54321\"} When format = \"text\" is configured:\n2026-01-15T10:30:45.123Z INFO thunderdb::server: Server started node_id=1 pg_port=5432 mysql_port=3306 2026-01-15T10:30:45.456Z INFO thunderdb::cluster: Cluster joined node_id=1 cluster_name=production role=follower 2026-01-15T10:31:15.012Z WARN thunderdb::query: Slow query detected duration_ms=2345 protocol=pg Slow Query Log When slow_query_enabled = true, queries exceeding slow_query_threshold are logged at WARN level with full query text, execution time, client address, and protocol:\n{ \"timestamp\": \"2026-01-15T10:31:15.012Z\", \"level\": \"warn\", \"target\": \"thunderdb::query::slow\", \"message\": \"Slow query detected\", \"duration_ms\": 2345, \"protocol\": \"pg\", \"query\": \"SELECT o.id, p.name, SUM(o.quantity) FROM orders o JOIN products p ON o.product_id = p.id GROUP BY o.id, p.name HAVING SUM(o.quantity) \u003e 100\", \"client\": \"10.0.1.50:54321\", \"rows_examined\": 1500000, \"rows_returned\": 42, \"plan\": \"HashJoin -\u003e SeqScan(orders) + IndexScan(products)\" } Runtime Log Level Changes Change the log level at runtime without restarting:\n# Via HTTP API curl -X PUT http://localhost:8088/admin/config/log_level -d '{\"level\": \"debug\"}' # Via systemd reload sudo systemctl reload thunderdb # Via environment variable (requires restart) THUNDERDB_LOG_LEVEL=debug Log Rotation When running under systemd, logs go to the journal and are rotated automatically. For file-based logging, configure logrotate:\n# /etc/logrotate.d/thunderdb /var/log/thunderdb/*.log { daily rotate 14 compress delaycompress missingok notifempty create 0640 thunder thunder postrotate systemctl reload thunderdb endscript } Alerting Rules ThunderDB ships with recommended alerting rules based on SLOs in deploy/slo.yaml. These rules can be loaded into Prometheus Alertmanager.\nAlert Rules Configuration # deploy/prometheus/rules/thunderdb-alerts.yml groups: - name: thunderdb.availability rules: - alert: ThunderDBDown expr: up{job=\"thunderdb\"} == 0 for: 1m labels: severity: critical annotations: summary: \"ThunderDB node {{ $labels.instance }} is down\" description: \"The ThunderDB node has been unreachable for more than 1 minute.\" - alert: ThunderDBNotReady expr: thunderdb_ready == 0 for: 5m labels: severity: critical annotations: summary: \"ThunderDB node {{ $labels.instance }} is not ready\" description: \"The node has been in a not-ready state for more than 5 minutes.\" - name: thunderdb.performance rules: - alert: ThunderDBHighQueryLatency expr: histogram_quantile(0.99, rate(thunderdb_query_duration_seconds_bucket[5m])) \u003e 5 for: 10m labels: severity: warning annotations: summary: \"High p99 query latency on {{ $labels.instance }}\" description: \"The p99 query latency has exceeded 5 seconds for more than 10 minutes.\" - alert: ThunderDBLowBufferPoolHitRate expr: thunderdb_buffer_pool_hit_ratio \u003c 0.90 for: 15m labels: severity: warning annotations: summary: \"Low buffer pool hit rate on {{ $labels.instance }}\" description: \"Buffer pool hit rate is {{ $value }}, below the 0.90 threshold. Consider increasing buffer_pool_size.\" - alert: ThunderDBHighSlowQueryRate expr: rate(thunderdb_slow_queries_total[5m]) \u003e 10 for: 10m labels: severity: warning annotations: summary: \"High rate of slow queries on {{ $labels.instance }}\" description: \"More than 10 slow queries per second for the last 10 minutes.\" - name: thunderdb.storage rules: - alert: ThunderDBWALSizeHigh expr: thunderdb_wal_size_bytes \u003e 0.8 * thunderdb_wal_max_size_bytes for: 5m labels: severity: warning annotations: summary: \"WAL size approaching limit on {{ $labels.instance }}\" description: \"WAL is at {{ $value | humanize1024 }}, approaching the configured maximum.\" - alert: ThunderDBDiskSpaceLow expr: thunderdb_disk_usage_bytes / thunderdb_disk_total_bytes \u003e 0.85 for: 10m labels: severity: warning annotations: summary: \"Low disk space on {{ $labels.instance }}\" description: \"Disk usage is above 85%. Consider expanding storage or archiving old data.\" - alert: ThunderDBDiskSpaceCritical expr: thunderdb_disk_usage_bytes / thunderdb_disk_total_bytes \u003e 0.95 for: 5m labels: severity: critical annotations: summary: \"Critical disk space on {{ $labels.instance }}\" description: \"Disk usage is above 95%. Immediate action required.\" - alert: ThunderDBCompactionBacklog expr: thunderdb_compaction_pending \u003e 50 for: 30m labels: severity: warning annotations: summary: \"Compaction backlog on {{ $labels.instance }}\" description: \"More than 50 pending compaction tasks. Consider increasing compaction_threads.\" - name: thunderdb.cluster rules: - alert: ThunderDBReplicationLagHigh expr: thunderdb_replication_lag_seconds \u003e 10 for: 5m labels: severity: warning annotations: summary: \"High replication lag on {{ $labels.instance }}\" description: \"Replication lag to {{ $labels.peer }} is {{ $value }}s.\" - alert: ThunderDBReplicationLagCritical expr: thunderdb_replication_lag_seconds \u003e 60 for: 2m labels: severity: critical annotations: summary: \"Critical replication lag on {{ $labels.instance }}\" description: \"Replication lag to {{ $labels.peer }} has exceeded 60 seconds.\" - alert: ThunderDBLeaderChanged expr: changes(thunderdb_raft_term[5m]) \u003e 2 labels: severity: warning annotations: summary: \"Frequent Raft leader elections on {{ $labels.instance }}\" description: \"More than 2 leader elections in the last 5 minutes. Check network stability.\" - alert: ThunderDBClusterDegraded expr: count(up{job=\"thunderdb\"} == 1) \u003c 3 for: 1m labels: severity: critical annotations: summary: \"ThunderDB cluster is degraded\" description: \"Fewer than 3 nodes are healthy. Cluster may lose quorum.\" - name: thunderdb.connections rules: - alert: ThunderDBHighConnectionCount expr: sum(thunderdb_connections_active) by (instance) \u003e 1000 for: 5m labels: severity: warning annotations: summary: \"High connection count on {{ $labels.instance }}\" description: \"Active connections have exceeded 1000. Consider connection pooling.\" - alert: ThunderDBHighErrorRate expr: rate(thunderdb_query_total{status=\"error\"}[5m]) / rate(thunderdb_query_total[5m]) \u003e 0.05 for: 10m labels: severity: warning annotations: summary: \"High query error rate on {{ $labels.instance }}\" description: \"More than 5% of queries are failing.\" SLO Definitions # deploy/slo.yaml slos: - name: thunderdb-availability description: \"ThunderDB cluster availability\" target: 99.95% window: 30d indicator: type: availability query: \"up{job='thunderdb'}\" - name: thunderdb-latency description: \"Query latency SLO\" target: 99% window: 30d indicator: type: latency threshold: 500ms query: \"histogram_quantile(0.99, rate(thunderdb_query_duration_seconds_bucket[5m]))\" - name: thunderdb-error-rate description: \"Query error rate SLO\" target: 99.9% window: 30d indicator: type: error_rate query: \"rate(thunderdb_query_total{status='error'}[5m]) / rate(thunderdb_query_total[5m])\" Recommended Monitoring Stack Setup For a complete production monitoring setup, deploy the following stack alongside ThunderDB:\nArchitecture ThunderDB Nodes ──\u003e Prometheus ──\u003e Grafana | | | v | Alertmanager ──\u003e PagerDuty/Slack/Email | v Log Aggregation (Loki/ELK) Quick Start with Docker Compose Use the provided docker-compose.monitoring.yml or add the monitoring services to your existing compose file (see Deployment Guide).\nStep-by-Step Setup Deploy Prometheus with ThunderDB scrape configuration. Deploy Grafana with provisioned data source and dashboards. Deploy Alertmanager with notification channels (Slack, PagerDuty, email). Import alert rules from deploy/prometheus/rules/. Verify metrics flow by checking Prometheus targets page. Set up log aggregation (Loki for Grafana, or Elasticsearch + Kibana) for centralized log analysis. Test alerting by simulating a failure (e.g., stopping a node). Operational Runbook Integration Combine monitoring with operational runbooks (see deploy/runbook.md) to ensure alerts are actionable. Each alert should link to a runbook entry with:\nWhat the alert means How to diagnose the root cause Step-by-step remediation procedures Escalation paths ","categories":"","description":"Monitor ThunderDB health and performance with Prometheus metrics, Grafana dashboards, structured logging, and alerting.","excerpt":"Monitor ThunderDB health and performance with Prometheus metrics, …","ref":"/docs/docs/administrator/monitoring/","tags":"","title":"Monitoring"},{"body":"SDKs \u0026 Drivers ThunderDB implements the PostgreSQL, MySQL, and Redis (RESP) wire protocols natively. This means you can use any standard driver for these databases to connect to ThunderDB with zero modifications. ThunderDB also ships a native Rust client crate with additional features like connection pooling, cluster-aware routing, and vector type support.\nDriver Compatibility Matrix Language PostgreSQL Driver MySQL Driver Redis Client Native Client Rust tokio-postgres mysql_async redis crate thunder-client Python psycopg2 / asyncpg mysql-connector-python redis-py – Node.js node-postgres (pg) mysql2 ioredis – Go pgx / lib/pq go-sql-driver/mysql go-redis – Java JDBC (PostgreSQL) JDBC (MySQL) Jedis / Lettuce – C#/.NET Npgsql MySqlConnector StackExchange.Redis – Native Rust Client (thunder-client) The thunder-client crate provides the most feature-complete integration with ThunderDB, including cluster-aware connection routing, automatic failover, native vector type support, and CDC stream subscriptions.\nInstallation Add to your Cargo.toml:\n[dependencies] thunder-client = \"0.9\" tokio = { version = \"1\", features = [\"full\"] } Connecting use thunder_client::{ClientBuilder, Client}; #[tokio::main] async fn main() -\u003e Result\u003c(), thunder_client::Error\u003e { // Simple connection let client = ClientBuilder::new() .host(\"localhost\") .port(5432) .user(\"thunder\") .password(\"secret\") .database(\"myapp\") .build() .await?; println!(\"Connected to ThunderDB {}\", client.server_version()); Ok(()) } Connection Pooling use thunder_client::{ClientBuilder, PoolConfig}; #[tokio::main] async fn main() -\u003e Result\u003c(), thunder_client::Error\u003e { let client = ClientBuilder::new() .host(\"localhost\") .port(5432) .user(\"thunder\") .password(\"secret\") .database(\"myapp\") .pool(PoolConfig { min_connections: 5, max_connections: 50, idle_timeout: std::time::Duration::from_secs(300), max_lifetime: std::time::Duration::from_secs(3600), acquire_timeout: std::time::Duration::from_secs(5), }) .build() .await?; // Connections are automatically managed by the pool let rows = client.query(\"SELECT COUNT(*) FROM users\", \u0026[]).await?; println!(\"User count: {}\", rows[0].get::\u003ci64\u003e(0)); Ok(()) } Cluster-Aware Connection use thunder_client::{ClientBuilder, ClusterConfig}; #[tokio::main] async fn main() -\u003e Result\u003c(), thunder_client::Error\u003e { let client = ClientBuilder::new() .cluster(ClusterConfig { seeds: vec![ \"10.0.1.10:5432\".to_string(), \"10.0.1.11:5432\".to_string(), \"10.0.2.10:5432\".to_string(), ], // Route reads to followers, writes to leader read_preference: thunder_client::ReadPreference::Follower, // Automatically retry on failover auto_retry: true, max_retries: 3, }) .user(\"thunder\") .password(\"secret\") .database(\"myapp\") .build() .await?; // This query is automatically routed to a follower let rows = client.query(\"SELECT * FROM users LIMIT 10\", \u0026[]).await?; // This statement is automatically routed to the leader client.execute( \"INSERT INTO users (name, email) VALUES ($1, $2)\", \u0026[\u0026\"Alice\", \u0026\"alice@example.com\"], ).await?; Ok(()) } Queries and Parameterized Statements use thunder_client::Client; async fn query_examples(client: \u0026Client) -\u003e Result\u003c(), thunder_client::Error\u003e { // Simple query let rows = client.query( \"SELECT id, name, email FROM users WHERE active = $1\", \u0026[\u0026true], ).await?; for row in \u0026rows { let id: i64 = row.get(\"id\"); let name: String = row.get(\"name\"); let email: String = row.get(\"email\"); println!(\"{}: {} \u003c{}\u003e\", id, name, email); } // Query returning a single row let row = client.query_one( \"SELECT COUNT(*) AS total FROM orders WHERE customer_id = $1\", \u0026[\u002642_i64], ).await?; let total: i64 = row.get(\"total\"); println!(\"Order count: {}\", total); // Execute (INSERT/UPDATE/DELETE) returning affected rows let affected = client.execute( \"UPDATE users SET active = false WHERE last_login \u003c now() - INTERVAL '90 days'\", \u0026[], ).await?; println!(\"Deactivated {} users\", affected); Ok(()) } Prepared Statements use thunder_client::Client; async fn prepared_example(client: \u0026Client) -\u003e Result\u003c(), thunder_client::Error\u003e { // Prepare a statement once let stmt = client.prepare( \"SELECT id, name, price FROM products WHERE category = $1 AND price \u003c $2\" ).await?; // Execute multiple times with different parameters let electronics = client.query_prepared(\u0026stmt, \u0026[\u0026\"electronics\", \u0026500.0_f64]).await?; let books = client.query_prepared(\u0026stmt, \u0026[\u0026\"books\", \u002630.0_f64]).await?; println!(\"Found {} electronics, {} books\", electronics.len(), books.len()); Ok(()) } Transactions use thunder_client::{Client, IsolationLevel}; async fn transaction_example(client: \u0026Client) -\u003e Result\u003c(), thunder_client::Error\u003e { // Begin a transaction let txn = client.begin() .isolation_level(IsolationLevel::Serializable) .start() .await?; // Execute statements within the transaction txn.execute( \"UPDATE accounts SET balance = balance - $1 WHERE id = $2\", \u0026[\u0026100.0_f64, \u00261_i64], ).await?; txn.execute( \"UPDATE accounts SET balance = balance + $1 WHERE id = $2\", \u0026[\u0026100.0_f64, \u00262_i64], ).await?; txn.execute( \"INSERT INTO transfers (from_id, to_id, amount) VALUES ($1, $2, $3)\", \u0026[\u00261_i64, \u00262_i64, \u0026100.0_f64], ).await?; // Commit the transaction txn.commit().await?; println!(\"Transfer committed successfully\"); // Using savepoints let txn = client.begin().start().await?; txn.execute(\"INSERT INTO orders (customer_id, total) VALUES ($1, $2)\", \u0026[\u002642_i64, \u0026299.99_f64]).await?; let sp = txn.savepoint(\"before_items\").await?; // Try something risky let result = txn.execute( \"INSERT INTO order_items (order_id, product_id, quantity) VALUES ($1, $2, $3)\", \u0026[\u00261_i64, \u0026999_i64, \u00261_i32], ).await; if result.is_err() { // Roll back to the savepoint sp.rollback().await?; // Try with a different product txn.execute( \"INSERT INTO order_items (order_id, product_id, quantity) VALUES ($1, $2, $3)\", \u0026[\u00261_i64, \u002642_i64, \u00261_i32], ).await?; } txn.commit().await?; Ok(()) } Vector Operations use thunder_client::{Client, Vector}; async fn vector_examples(client: \u0026Client) -\u003e Result\u003c(), thunder_client::Error\u003e { // Insert a vector let embedding = Vector::from(vec![0.1_f32, -0.23, 0.98, 0.45, 0.67]); client.execute( \"INSERT INTO documents (id, title, embedding) VALUES ($1, $2, $3)\", \u0026[\u00261_i64, \u0026\"Quantum Computing\", \u0026embedding], ).await?; // Similarity search let query_vec = Vector::from(vec![0.15_f32, -0.20, 0.95, 0.50, 0.60]); let results = client.query( \"SELECT id, title, embedding \u003c-\u003e $1 AS distance FROM documents ORDER BY embedding \u003c-\u003e $1 LIMIT 10\", \u0026[\u0026query_vec], ).await?; for row in \u0026results { let id: i64 = row.get(\"id\"); let title: String = row.get(\"title\"); let distance: f64 = row.get(\"distance\"); println!(\"[{:.4}] {} - {}\", distance, id, title); } Ok(()) } CDC Stream Subscription use thunder_client::{Client, CdcEvent}; use futures::StreamExt; async fn cdc_example(client: \u0026Client) -\u003e Result\u003c(), thunder_client::Error\u003e { // Subscribe to changes on the orders table let mut stream = client.subscribe_cdc(\"orders\") .events(vec![\"insert\", \"update\"]) .filter(\"total \u003e 100\") .start() .await?; // Process events as they arrive while let Some(event) = stream.next().await { let event = event?; match event { CdcEvent::Insert { table, row, lsn, .. } =\u003e { println!(\"New order in {}: {:?} (LSN: {})\", table, row, lsn); } CdcEvent::Update { table, old_row, new_row, changed_columns, .. } =\u003e { println!(\"Updated order in {}: {:?} -\u003e {:?} (changed: {:?})\", table, old_row, new_row, changed_columns); } _ =\u003e {} } } Ok(()) } PostgreSQL Drivers Because ThunderDB speaks the PostgreSQL wire protocol, any PostgreSQL driver connects without modifications. Below are examples for popular languages.\nPython (psycopg2) pip install psycopg2-binary import psycopg2 # Connect to ThunderDB via PostgreSQL protocol conn = psycopg2.connect( host=\"localhost\", port=5432, user=\"thunder\", password=\"secret\", dbname=\"myapp\" ) # Create a table with conn.cursor() as cur: cur.execute(\"\"\" CREATE TABLE IF NOT EXISTS users ( id BIGINT PRIMARY KEY, name VARCHAR(255) NOT NULL, email VARCHAR(255) UNIQUE NOT NULL, active BOOLEAN DEFAULT true, created_at TIMESTAMPTZ DEFAULT now() ) \"\"\") conn.commit() # Insert data with conn.cursor() as cur: cur.execute( \"INSERT INTO users (id, name, email) VALUES (%s, %s, %s)\", (1, \"Alice Johnson\", \"alice@example.com\") ) conn.commit() # Batch insert with conn.cursor() as cur: users = [ (2, \"Bob Smith\", \"bob@example.com\"), (3, \"Carol White\", \"carol@example.com\"), (4, \"Dave Brown\", \"dave@example.com\"), ] cur.executemany( \"INSERT INTO users (id, name, email) VALUES (%s, %s, %s)\", users ) conn.commit() # Query data with conn.cursor() as cur: cur.execute(\"SELECT id, name, email FROM users WHERE active = %s\", (True,)) rows = cur.fetchall() for row in rows: print(f\"User {row[0]}: {row[1]} \u003c{row[2]}\u003e\") # Transactions try: with conn.cursor() as cur: cur.execute(\"UPDATE accounts SET balance = balance - 100 WHERE id = 1\") cur.execute(\"UPDATE accounts SET balance = balance + 100 WHERE id = 2\") conn.commit() except Exception as e: conn.rollback() print(f\"Transaction failed: {e}\") conn.close() Python (asyncpg – async) pip install asyncpg import asyncio import asyncpg async def main(): # Create a connection pool pool = await asyncpg.create_pool( host=\"localhost\", port=5432, user=\"thunder\", password=\"secret\", database=\"myapp\", min_size=5, max_size=20, ) # Query with pool async with pool.acquire() as conn: rows = await conn.fetch( \"SELECT id, name, email FROM users WHERE active = $1\", True ) for row in rows: print(f\"User {row['id']}: {row['name']} \u003c{row['email']}\u003e\") # Transaction async with pool.acquire() as conn: async with conn.transaction(): await conn.execute( \"UPDATE accounts SET balance = balance - $1 WHERE id = $2\", 100, 1 ) await conn.execute( \"UPDATE accounts SET balance = balance + $1 WHERE id = $2\", 100, 2 ) await pool.close() asyncio.run(main()) Node.js (node-postgres / pg) npm install pg const { Pool } = require('pg'); // Create connection pool const pool = new Pool({ host: 'localhost', port: 5432, user: 'thunder', password: 'secret', database: 'myapp', max: 20, idleTimeoutMillis: 30000, }); async function main() { // Create a table await pool.query(` CREATE TABLE IF NOT EXISTS users ( id BIGINT PRIMARY KEY, name VARCHAR(255) NOT NULL, email VARCHAR(255) UNIQUE NOT NULL, active BOOLEAN DEFAULT true, created_at TIMESTAMPTZ DEFAULT now() ) `); // Insert data with parameterized query await pool.query( 'INSERT INTO users (id, name, email) VALUES ($1, $2, $3)', [1, 'Alice Johnson', 'alice@example.com'] ); // Query data const result = await pool.query( 'SELECT id, name, email FROM users WHERE active = $1', [true] ); for (const row of result.rows) { console.log(`User ${row.id}: ${row.name} \u003c${row.email}\u003e`); } // Transaction const client = await pool.connect(); try { await client.query('BEGIN'); await client.query( 'UPDATE accounts SET balance = balance - $1 WHERE id = $2', [100, 1] ); await client.query( 'UPDATE accounts SET balance = balance + $1 WHERE id = $2', [100, 2] ); await client.query('COMMIT'); console.log('Transfer committed'); } catch (e) { await client.query('ROLLBACK'); console.error('Transaction failed:', e.message); } finally { client.release(); } await pool.end(); } main().catch(console.error); Go (pgx) go get github.com/jackc/pgx/v5 package main import ( \"context\" \"fmt\" \"log\" \"github.com/jackc/pgx/v5\" \"github.com/jackc/pgx/v5/pgxpool\" ) func main() { ctx := context.Background() // Create connection pool poolConfig, err := pgxpool.ParseConfig( \"postgresql://thunder:secret@localhost:5432/myapp?pool_max_conns=20\", ) if err != nil { log.Fatal(err) } pool, err := pgxpool.NewWithConfig(ctx, poolConfig) if err != nil { log.Fatal(err) } defer pool.Close() // Create a table _, err = pool.Exec(ctx, ` CREATE TABLE IF NOT EXISTS users ( id BIGINT PRIMARY KEY, name VARCHAR(255) NOT NULL, email VARCHAR(255) UNIQUE NOT NULL, active BOOLEAN DEFAULT true, created_at TIMESTAMPTZ DEFAULT now() ) `) if err != nil { log.Fatal(err) } // Insert data _, err = pool.Exec(ctx, \"INSERT INTO users (id, name, email) VALUES ($1, $2, $3)\", 1, \"Alice Johnson\", \"alice@example.com\", ) if err != nil { log.Fatal(err) } // Query data rows, err := pool.Query(ctx, \"SELECT id, name, email FROM users WHERE active = $1\", true, ) if err != nil { log.Fatal(err) } defer rows.Close() for rows.Next() { var id int64 var name, email string if err := rows.Scan(\u0026id, \u0026name, \u0026email); err != nil { log.Fatal(err) } fmt.Printf(\"User %d: %s \u003c%s\u003e\\n\", id, name, email) } // Transaction tx, err := pool.Begin(ctx) if err != nil { log.Fatal(err) } defer tx.Rollback(ctx) // No-op if committed _, err = tx.Exec(ctx, \"UPDATE accounts SET balance = balance - $1 WHERE id = $2\", 100, 1) if err != nil { log.Fatal(err) } _, err = tx.Exec(ctx, \"UPDATE accounts SET balance = balance + $1 WHERE id = $2\", 100, 2) if err != nil { log.Fatal(err) } if err := tx.Commit(ctx); err != nil { log.Fatal(err) } fmt.Println(\"Transfer committed\") } Rust (tokio-postgres) [dependencies] tokio-postgres = \"0.7\" tokio = { version = \"1\", features = [\"full\"] } use tokio_postgres::{NoTls, Error}; #[tokio::main] async fn main() -\u003e Result\u003c(), Error\u003e { // Connect to ThunderDB via PostgreSQL protocol let (client, connection) = tokio_postgres::connect( \"host=localhost port=5432 user=thunder password=secret dbname=myapp\", NoTls, ).await?; // Spawn the connection handler tokio::spawn(async move { if let Err(e) = connection.await { eprintln!(\"Connection error: {}\", e); } }); // Create a table client.execute( \"CREATE TABLE IF NOT EXISTS users ( id BIGINT PRIMARY KEY, name VARCHAR(255) NOT NULL, email VARCHAR(255) UNIQUE NOT NULL, active BOOLEAN DEFAULT true, created_at TIMESTAMPTZ DEFAULT now() )\", \u0026[], ).await?; // Insert data client.execute( \"INSERT INTO users (id, name, email) VALUES ($1, $2, $3)\", \u0026[\u00261_i64, \u0026\"Alice Johnson\", \u0026\"alice@example.com\"], ).await?; // Query data let rows = client.query( \"SELECT id, name, email FROM users WHERE active = $1\", \u0026[\u0026true], ).await?; for row in \u0026rows { let id: i64 = row.get(0); let name: \u0026str = row.get(1); let email: \u0026str = row.get(2); println!(\"User {}: {} \u003c{}\u003e\", id, name, email); } // Transaction let txn = client.transaction().await?; txn.execute( \"UPDATE accounts SET balance = balance - $1 WHERE id = $2\", \u0026[\u0026100.0_f64, \u00261_i64], ).await?; txn.execute( \"UPDATE accounts SET balance = balance + $1 WHERE id = $2\", \u0026[\u0026100.0_f64, \u00262_i64], ).await?; txn.commit().await?; println!(\"Transfer committed\"); Ok(()) } MySQL Drivers ThunderDB implements the MySQL wire protocol, allowing any MySQL driver to connect.\nPython (mysql-connector-python) pip install mysql-connector-python import mysql.connector # Connect to ThunderDB via MySQL protocol conn = mysql.connector.connect( host=\"localhost\", port=3306, user=\"thunder\", password=\"secret\", database=\"myapp\" ) cursor = conn.cursor() # Create a table cursor.execute(\"\"\" CREATE TABLE IF NOT EXISTS products ( id BIGINT PRIMARY KEY, name VARCHAR(255) NOT NULL, price DECIMAL(10,2) NOT NULL, category VARCHAR(100), created_at TIMESTAMPTZ DEFAULT now() ) \"\"\") conn.commit() # Insert data cursor.execute( \"INSERT INTO products (id, name, price, category) VALUES (%s, %s, %s, %s)\", (1, \"Wireless Mouse\", 29.99, \"electronics\") ) conn.commit() # Batch insert products = [ (2, \"USB-C Cable\", 12.99, \"electronics\"), (3, \"Python Cookbook\", 45.00, \"books\"), (4, \"Standing Desk\", 599.99, \"furniture\"), ] cursor.executemany( \"INSERT INTO products (id, name, price, category) VALUES (%s, %s, %s, %s)\", products ) conn.commit() # Query data cursor.execute( \"SELECT id, name, price FROM products WHERE category = %s ORDER BY price\", (\"electronics\",) ) for row in cursor.fetchall(): print(f\"Product {row[0]}: {row[1]} - ${row[2]}\") cursor.close() conn.close() Node.js (mysql2) npm install mysql2 const mysql = require('mysql2/promise'); async function main() { // Create connection pool const pool = mysql.createPool({ host: 'localhost', port: 3306, user: 'thunder', password: 'secret', database: 'myapp', connectionLimit: 20, waitForConnections: true, }); // Create a table await pool.query(` CREATE TABLE IF NOT EXISTS products ( id BIGINT PRIMARY KEY, name VARCHAR(255) NOT NULL, price DECIMAL(10,2) NOT NULL, category VARCHAR(100), created_at TIMESTAMPTZ DEFAULT now() ) `); // Insert data with parameterized query await pool.query( 'INSERT INTO products (id, name, price, category) VALUES (?, ?, ?, ?)', [1, 'Wireless Mouse', 29.99, 'electronics'] ); // Query data const [rows] = await pool.query( 'SELECT id, name, price FROM products WHERE category = ? ORDER BY price', ['electronics'] ); for (const row of rows) { console.log(`Product ${row.id}: ${row.name} - $${row.price}`); } // Transaction const conn = await pool.getConnection(); try { await conn.beginTransaction(); await conn.query( 'UPDATE accounts SET balance = balance - ? WHERE id = ?', [100, 1] ); await conn.query( 'UPDATE accounts SET balance = balance + ? WHERE id = ?', [100, 2] ); await conn.commit(); console.log('Transfer committed'); } catch (e) { await conn.rollback(); console.error('Transaction failed:', e.message); } finally { conn.release(); } await pool.end(); } main().catch(console.error); Go (go-sql-driver/mysql) go get github.com/go-sql-driver/mysql package main import ( \"database/sql\" \"fmt\" \"log\" _ \"github.com/go-sql-driver/mysql\" ) func main() { // Connect to ThunderDB via MySQL protocol db, err := sql.Open(\"mysql\", \"thunder:secret@tcp(localhost:3306)/myapp\") if err != nil { log.Fatal(err) } defer db.Close() db.SetMaxOpenConns(20) db.SetMaxIdleConns(5) // Create a table _, err = db.Exec(` CREATE TABLE IF NOT EXISTS products ( id BIGINT PRIMARY KEY, name VARCHAR(255) NOT NULL, price DECIMAL(10,2) NOT NULL, category VARCHAR(100), created_at TIMESTAMPTZ DEFAULT now() ) `) if err != nil { log.Fatal(err) } // Insert data _, err = db.Exec( \"INSERT INTO products (id, name, price, category) VALUES (?, ?, ?, ?)\", 1, \"Wireless Mouse\", 29.99, \"electronics\", ) if err != nil { log.Fatal(err) } // Query data rows, err := db.Query( \"SELECT id, name, price FROM products WHERE category = ? ORDER BY price\", \"electronics\", ) if err != nil { log.Fatal(err) } defer rows.Close() for rows.Next() { var id int64 var name string var price float64 if err := rows.Scan(\u0026id, \u0026name, \u0026price); err != nil { log.Fatal(err) } fmt.Printf(\"Product %d: %s - $%.2f\\n\", id, name, price) } // Transaction tx, err := db.Begin() if err != nil { log.Fatal(err) } _, err = tx.Exec(\"UPDATE accounts SET balance = balance - ? WHERE id = ?\", 100, 1) if err != nil { tx.Rollback() log.Fatal(err) } _, err = tx.Exec(\"UPDATE accounts SET balance = balance + ? WHERE id = ?\", 100, 2) if err != nil { tx.Rollback() log.Fatal(err) } if err := tx.Commit(); err != nil { log.Fatal(err) } fmt.Println(\"Transfer committed\") } Redis Clients ThunderDB implements the RESP (Redis Serialization Protocol), supporting common Redis commands for key-value operations, data structures, and pub/sub. You can use ThunderDB as a Redis-compatible cache with the bonus of SQL queryability over the cached data.\nPython (redis-py) pip install redis import redis # Connect to ThunderDB via Redis protocol r = redis.Redis( host=\"localhost\", port=6379, password=\"secret\", decode_responses=True ) # String operations r.set(\"user:1:name\", \"Alice Johnson\") r.set(\"user:1:email\", \"alice@example.com\") r.setex(\"session:abc123\", 3600, \"user:1\") # Expires in 1 hour name = r.get(\"user:1:name\") print(f\"Name: {name}\") # Hash operations r.hset(\"product:42\", mapping={ \"name\": \"Wireless Mouse\", \"price\": \"29.99\", \"category\": \"electronics\", \"stock\": \"150\" }) product = r.hgetall(\"product:42\") print(f\"Product: {product}\") # List operations (message queue pattern) r.lpush(\"task_queue\", \"process_order:1001\") r.lpush(\"task_queue\", \"send_email:user:1\") task = r.rpop(\"task_queue\") print(f\"Next task: {task}\") # Set operations r.sadd(\"user:1:tags\", \"premium\", \"early-adopter\", \"beta-tester\") r.sadd(\"user:2:tags\", \"premium\", \"enterprise\") common_tags = r.sinter(\"user:1:tags\", \"user:2:tags\") print(f\"Common tags: {common_tags}\") # Sorted set (leaderboard) r.zadd(\"leaderboard\", {\"alice\": 2500, \"bob\": 1800, \"carol\": 3200}) top_players = r.zrevrange(\"leaderboard\", 0, 2, withscores=True) print(f\"Top players: {top_players}\") # Pub/Sub pubsub = r.pubsub() pubsub.subscribe(\"order_events\") # In another thread/process: # r.publish(\"order_events\", '{\"order_id\": 1001, \"status\": \"shipped\"}') # Pipeline (batch commands) pipe = r.pipeline() pipe.set(\"counter:visits\", 0) pipe.incr(\"counter:visits\") pipe.incr(\"counter:visits\") pipe.incr(\"counter:visits\") pipe.get(\"counter:visits\") results = pipe.execute() print(f\"Visit count: {results[-1]}\") Node.js (ioredis) npm install ioredis const Redis = require('ioredis'); async function main() { // Connect to ThunderDB via Redis protocol const redis = new Redis({ host: 'localhost', port: 6379, password: 'secret', }); // String operations await redis.set('user:1:name', 'Alice Johnson'); await redis.setex('session:abc123', 3600, 'user:1'); const name = await redis.get('user:1:name'); console.log(`Name: ${name}`); // Hash operations await redis.hset('product:42', { name: 'Wireless Mouse', price: '29.99', category: 'electronics', stock: '150', }); const product = await redis.hgetall('product:42'); console.log('Product:', product); // Sorted set (leaderboard) await redis.zadd('leaderboard', 2500, 'alice', 1800, 'bob', 3200, 'carol'); const topPlayers = await redis.zrevrange('leaderboard', 0, 2, 'WITHSCORES'); console.log('Top players:', topPlayers); // Pipeline const pipeline = redis.pipeline(); pipeline.set('counter:api_calls', 0); pipeline.incr('counter:api_calls'); pipeline.incr('counter:api_calls'); pipeline.incr('counter:api_calls'); pipeline.get('counter:api_calls'); const results = await pipeline.exec(); console.log('API call count:', results[results.length - 1][1]); // Pub/Sub const subscriber = new Redis({ host: 'localhost', port: 6379, password: 'secret' }); subscriber.subscribe('order_events', (err) =\u003e { if (err) console.error('Subscribe error:', err); }); subscriber.on('message', (channel, message) =\u003e { console.log(`[${channel}] ${message}`); }); // Publish from main connection await redis.publish('order_events', JSON.stringify({ order_id: 1001, status: 'shipped', })); // Clean up subscriber.disconnect(); redis.disconnect(); } main().catch(console.error); Go (go-redis) go get github.com/redis/go-redis/v9 package main import ( \"context\" \"fmt\" \"log\" \"github.com/redis/go-redis/v9\" ) func main() { ctx := context.Background() // Connect to ThunderDB via Redis protocol rdb := redis.NewClient(\u0026redis.Options{ Addr: \"localhost:6379\", Password: \"secret\", PoolSize: 20, }) defer rdb.Close() // String operations err := rdb.Set(ctx, \"user:1:name\", \"Alice Johnson\", 0).Err() if err != nil { log.Fatal(err) } name, err := rdb.Get(ctx, \"user:1:name\").Result() if err != nil { log.Fatal(err) } fmt.Printf(\"Name: %s\\n\", name) // Hash operations err = rdb.HSet(ctx, \"product:42\", map[string]interface{}{ \"name\": \"Wireless Mouse\", \"price\": \"29.99\", \"category\": \"electronics\", \"stock\": \"150\", }).Err() if err != nil { log.Fatal(err) } product, err := rdb.HGetAll(ctx, \"product:42\").Result() if err != nil { log.Fatal(err) } fmt.Printf(\"Product: %v\\n\", product) // Sorted set (leaderboard) rdb.ZAdd(ctx, \"leaderboard\", redis.Z{Score: 2500, Member: \"alice\"}, redis.Z{Score: 1800, Member: \"bob\"}, redis.Z{Score: 3200, Member: \"carol\"}, ) topPlayers, err := rdb.ZRevRangeWithScores(ctx, \"leaderboard\", 0, 2).Result() if err != nil { log.Fatal(err) } for _, player := range topPlayers { fmt.Printf(\"%s: %.0f\\n\", player.Member, player.Score) } // Pipeline pipe := rdb.Pipeline() pipe.Set(ctx, \"counter:requests\", 0, 0) pipe.Incr(ctx, \"counter:requests\") pipe.Incr(ctx, \"counter:requests\") pipe.Incr(ctx, \"counter:requests\") getCmd := pipe.Get(ctx, \"counter:requests\") _, err = pipe.Exec(ctx) if err != nil { log.Fatal(err) } fmt.Printf(\"Request count: %s\\n\", getCmd.Val()) // Pub/Sub pubsub := rdb.Subscribe(ctx, \"order_events\") defer pubsub.Close() go func() { ch := pubsub.Channel() for msg := range ch { fmt.Printf(\"[%s] %s\\n\", msg.Channel, msg.Payload) } }() // Publish rdb.Publish(ctx, \"order_events\", `{\"order_id\": 1001, \"status\": \"shipped\"}`) } Connection String Reference ThunderDB accepts connection strings in the standard formats for each protocol:\nPostgreSQL Format postgresql://thunder:secret@localhost:5432/myapp?sslmode=require\u0026connect_timeout=10 Parameter Description Default sslmode disable, require, verify-ca, verify-full disable connect_timeout Connection timeout in seconds 10 application_name Application identifier for monitoring – options Additional server options – target_session_attrs read-write, read-only, any any MySQL Format thunder:secret@tcp(localhost:3306)/myapp?tls=true\u0026timeout=10s Redis Format redis://:secret@localhost:6379/0 Best Practices Use connection pools – Always pool connections in production. Most drivers support this natively. Use parameterized queries – Never concatenate user input into SQL strings. Use bind parameters ($1, %s, ?) to prevent SQL injection. Choose the right protocol – Use PostgreSQL for full SQL features, MySQL for compatibility with existing apps, Redis for caching workloads. Set timeouts – Configure connection and query timeouts appropriate for your workload. Handle transaction retries – When using SERIALIZABLE isolation, be prepared to retry transactions on serialization failures. Close connections – Always close connections and release pool resources when done. Use prepared statements – For repeated queries, prepared statements avoid repeated parsing and planning overhead. Monitor connections – Watch thunderdb_active_connections metrics to ensure pools are properly sized. ","categories":"","description":"Connect to ThunderDB using the native Rust client, standard PostgreSQL/MySQL drivers, or Redis clients in Python, Node.js, Go, and Rust.","excerpt":"Connect to ThunderDB using the native Rust client, standard …","ref":"/docs/docs/developer/sdk/","tags":"","title":"SDKs \u0026 Drivers"},{"body":"Testing ThunderDB maintains a rigorous testing strategy to ensure correctness, reliability, and performance across all 14 crates. This guide covers every aspect of testing: how tests are organized, how to run them, how to write new tests, and how the CI/CD pipeline enforces quality standards.\nTesting Philosophy ThunderDB follows these testing principles:\nCorrectness is non-negotiable. A database must never lose data, return wrong results, or violate ACID properties. Tests verify these guarantees exhaustively. Test at multiple levels. Unit tests verify individual functions, integration tests verify component interactions, and end-to-end tests verify the full system. Automate everything. Every test runs in CI. Manual testing procedures are documented but not relied upon as the sole quality gate. Test failure modes. A database must handle crashes, network partitions, disk failures, and malformed input gracefully. Chaos tests verify resilience. Benchmark continuously. Performance regressions are caught early through automated benchmarks. Test Organization Tests are organized following Rust conventions:\nthunder-storage/ +-- src/ | +-- wal.rs # Contains #[cfg(test)] mod tests { ... } | +-- btree.rs # Contains #[cfg(test)] mod tests { ... } | +-- ... +-- tests/ | +-- acid_compliance.rs # Integration tests | +-- recovery_tests.rs # Integration tests +-- benches/ +-- btree_bench.rs # Criterion benchmarks +-- wal_bench.rs # Criterion benchmarks Unit tests live inside each source file within a #[cfg(test)] mod tests block. Integration tests live in the tests/ directory of each crate. Benchmarks live in the benches/ directory of each crate. Unit Tests Unit tests verify the correctness of individual functions, methods, and modules in isolation.\nRunning Unit Tests # Run all unit tests across the workspace cargo test --lib # Run unit tests for a specific crate cargo test -p thunder-storage --lib # Run unit tests matching a name pattern cargo test -p thunder-storage --lib btree::tests:: # Run with output (println! and tracing output visible) cargo test -p thunder-storage --lib -- --nocapture # Run a single test by exact name cargo test -p thunder-storage --lib btree::tests::test_insert_and_lookup -- --exact Unit Test Example // thunder-storage/src/btree.rs #[cfg(test)] mod tests { use super::*; use crate::buffer::BufferPool; use tempfile::TempDir; /// Helper to create a B+Tree backed by a temporary directory fn setup_btree() -\u003e (BTree, TempDir) { let dir = TempDir::new().unwrap(); let buffer_pool = BufferPool::new(1024, dir.path()); let btree = BTree::new(buffer_pool, KeyType::Int64); (btree, dir) } #[test] fn test_insert_and_lookup() { let (mut btree, _dir) = setup_btree(); // Insert 1000 key-value pairs for i in 0..1000i64 { let key = Key::Int64(i); let value = Value::Int64(i * 10); btree.insert(\u0026key, \u0026value).unwrap(); } // Verify all values are retrievable for i in 0..1000i64 { let key = Key::Int64(i); let result = btree.get(\u0026key).unwrap(); assert_eq!(result, Some(Value::Int64(i * 10))); } // Verify non-existent key returns None assert_eq!(btree.get(\u0026Key::Int64(9999)).unwrap(), None); } #[test] fn test_range_scan() { let (mut btree, _dir) = setup_btree(); for i in 0..100i64 { btree.insert(\u0026Key::Int64(i), \u0026Value::Int64(i)).unwrap(); } // Scan range [10, 20) let results: Vec\u003c_\u003e = btree .range_scan(\u0026Key::Int64(10), \u0026Key::Int64(20)) .unwrap() .collect(); assert_eq!(results.len(), 10); assert_eq!(results[0].0, Key::Int64(10)); assert_eq!(results[9].0, Key::Int64(19)); } #[test] fn test_delete() { let (mut btree, _dir) = setup_btree(); btree.insert(\u0026Key::Int64(42), \u0026Value::Int64(100)).unwrap(); assert_eq!(btree.get(\u0026Key::Int64(42)).unwrap(), Some(Value::Int64(100))); btree.delete(\u0026Key::Int64(42)).unwrap(); assert_eq!(btree.get(\u0026Key::Int64(42)).unwrap(), None); } } Unit Test Conventions Test function names should describe the scenario being tested: test_insert_and_lookup, test_concurrent_writes_do_not_lose_data, test_recovery_after_crash. One assertion per logical check. Multiple assertions are fine if they verify different aspects of the same operation. Use helper functions to reduce boilerplate. Common setup patterns should be extracted into setup_* functions. Test edge cases: empty inputs, maximum sizes, boundary values, concurrent access. Temporary resources: Use tempfile::TempDir for temporary directories and tempfile::NamedTempFile for temporary files. These are automatically cleaned up when dropped. Integration Tests Integration tests verify that multiple components work correctly together. They live in the tests/ directory of each crate and have access to the crate’s public API (but not internal modules).\nKey Integration Test Files ACID Compliance Tests File: thunder-storage/tests/acid_compliance.rs\nThese tests verify that ThunderDB correctly implements ACID properties:\n// thunder-storage/tests/acid_compliance.rs /// Verify atomicity: a transaction either fully commits or fully aborts. /// No partial results should ever be visible. #[test] fn test_atomicity_all_or_nothing() { let db = TestDatabase::new(); // Begin a transaction that performs multiple writes let txn = db.begin().unwrap(); txn.execute(\"INSERT INTO accounts VALUES (1, 'Alice', 1000)\").unwrap(); txn.execute(\"INSERT INTO accounts VALUES (2, 'Bob', 2000)\").unwrap(); // Abort the transaction txn.abort().unwrap(); // Verify neither row is visible let result = db.query(\"SELECT COUNT(*) FROM accounts\").unwrap(); assert_eq!(result.rows[0].get_i64(0), 0); } /// Verify consistency: constraints are enforced even under concurrent access. #[test] fn test_consistency_constraints_enforced() { let db = TestDatabase::new(); db.execute(\"CREATE TABLE accounts (id INT PRIMARY KEY, balance INT CHECK (balance \u003e= 0))\").unwrap(); db.execute(\"INSERT INTO accounts VALUES (1, 1000)\").unwrap(); // Attempt to violate the CHECK constraint let result = db.execute(\"UPDATE accounts SET balance = -1 WHERE id = 1\"); assert!(result.is_err()); // Verify balance is unchanged let row = db.query(\"SELECT balance FROM accounts WHERE id = 1\").unwrap(); assert_eq!(row.rows[0].get_i64(0), 1000); } /// Verify isolation: concurrent transactions do not see each other's uncommitted changes. #[test] fn test_isolation_snapshot() { let db = TestDatabase::new(); db.execute(\"CREATE TABLE counter (id INT PRIMARY KEY, value INT)\").unwrap(); db.execute(\"INSERT INTO counter VALUES (1, 0)\").unwrap(); let txn1 = db.begin().unwrap(); let txn2 = db.begin().unwrap(); // txn1 updates the value txn1.execute(\"UPDATE counter SET value = 42 WHERE id = 1\").unwrap(); // txn2 should still see the old value (snapshot isolation) let result = txn2.query(\"SELECT value FROM counter WHERE id = 1\").unwrap(); assert_eq!(result.rows[0].get_i64(0), 0); txn1.commit().unwrap(); txn2.commit().unwrap(); } /// Verify durability: committed data survives server restart. #[test] fn test_durability_survives_restart() { let dir = TempDir::new().unwrap(); // Write data and commit { let db = TestDatabase::with_dir(dir.path()); db.execute(\"CREATE TABLE persist (id INT PRIMARY KEY, data TEXT)\").unwrap(); db.execute(\"INSERT INTO persist VALUES (1, 'important data')\").unwrap(); db.shutdown().unwrap(); // graceful shutdown with WAL flush } // Restart and verify data is present { let db = TestDatabase::with_dir(dir.path()); let result = db.query(\"SELECT data FROM persist WHERE id = 1\").unwrap(); assert_eq!(result.rows[0].get_str(0), \"important data\"); } } API Integration Tests File: thunder-api/tests/integration_test.rs\nTests the full API stack from HTTP request to response:\n// thunder-api/tests/integration_test.rs use reqwest::Client; use thunder_server::TestServer; #[tokio::test] async fn test_rest_api_crud() { let server = TestServer::start().await; let client = Client::new(); let base_url = server.rest_url(); // Create a table let resp = client.post(format!(\"{}/api/v1/execute\", base_url)) .json(\u0026json!({ \"sql\": \"CREATE TABLE users (id INT PRIMARY KEY, name TEXT, email TEXT)\" })) .send().await.unwrap(); assert_eq!(resp.status(), 200); // Insert a row let resp = client.post(format!(\"{}/api/v1/execute\", base_url)) .json(\u0026json!({ \"sql\": \"INSERT INTO users VALUES (1, 'Alice', 'alice@example.com')\" })) .send().await.unwrap(); assert_eq!(resp.status(), 200); // Query the row let resp = client.post(format!(\"{}/api/v1/query\", base_url)) .json(\u0026json!({ \"sql\": \"SELECT * FROM users WHERE id = 1\" })) .send().await.unwrap(); assert_eq!(resp.status(), 200); let body: serde_json::Value = resp.json().await.unwrap(); assert_eq!(body[\"rows\"][0][\"name\"], \"Alice\"); } #[tokio::test] async fn test_grpc_api_query() { let server = TestServer::start().await; let mut client = ThunderGrpcClient::connect(server.grpc_url()).await.unwrap(); let response = client.execute_query(QueryRequest { sql: \"SELECT 1 + 1 AS result\".to_string(), ..Default::default() }).await.unwrap(); assert_eq!(response.rows[0].values[0], Value::Int64(2)); } #[tokio::test] async fn test_postgres_wire_protocol() { let server = TestServer::start().await; // Connect using the tokio-postgres client let (client, connection) = tokio_postgres::connect( \u0026format!(\"host=localhost port={} user=admin dbname=thunderdb\", server.pg_port()), tokio_postgres::NoTls, ).await.unwrap(); tokio::spawn(connection); let rows = client.query(\"SELECT 42 AS answer\", \u0026[]).await.unwrap(); assert_eq!(rows[0].get::\u003c_, i32\u003e(0), 42); } Chaos Tests File: thunder-server/tests/chaos_tests.rs\nTests that verify ThunderDB handles failure conditions correctly:\n// thunder-server/tests/chaos_tests.rs /// Test that the database recovers correctly after a simulated crash /// (process killed without graceful shutdown). #[test] fn test_crash_recovery() { let dir = TempDir::new().unwrap(); // Phase 1: Write data, then simulate a crash { let db = TestDatabase::with_dir(dir.path()); db.execute(\"CREATE TABLE crash_test (id INT PRIMARY KEY, value INT)\").unwrap(); for i in 0..1000 { db.execute(\u0026format!(\"INSERT INTO crash_test VALUES ({}, {})\", i, i * 10)).unwrap(); } // Simulate crash: drop without graceful shutdown // The WAL has been written but the data files may be inconsistent db.simulate_crash(); } // Phase 2: Restart and verify ARIES recovery { let db = TestDatabase::with_dir(dir.path()); let result = db.query(\"SELECT COUNT(*) FROM crash_test\").unwrap(); assert_eq!(result.rows[0].get_i64(0), 1000); // Verify all values are correct for i in 0..1000 { let result = db.query(\u0026format!( \"SELECT value FROM crash_test WHERE id = {}\", i )).unwrap(); assert_eq!(result.rows[0].get_i64(0), i * 10); } } } /// Test that the cluster handles node failure and re-joining correctly. #[test] fn test_node_failure_and_rejoin() { let cluster = TestCluster::new(3); // 3-node cluster // Write data cluster.node(0).execute(\"CREATE TABLE replicated (id INT PRIMARY KEY, value TEXT)\").unwrap(); cluster.node(0).execute(\"INSERT INTO replicated VALUES (1, 'hello')\").unwrap(); // Wait for replication cluster.wait_for_replication().unwrap(); // Kill node 2 cluster.kill_node(2); // Verify reads still work on remaining nodes let result = cluster.node(0).query(\"SELECT value FROM replicated WHERE id = 1\").unwrap(); assert_eq!(result.rows[0].get_str(0), \"hello\"); // Write more data with node 2 down cluster.node(0).execute(\"INSERT INTO replicated VALUES (2, 'world')\").unwrap(); // Restart node 2 cluster.restart_node(2); cluster.wait_for_replication().unwrap(); // Verify node 2 has caught up with all data let result = cluster.node(2).query(\"SELECT COUNT(*) FROM replicated\").unwrap(); assert_eq!(result.rows[0].get_i64(0), 2); } /// Test behavior under network partition. #[test] fn test_network_partition() { let cluster = TestCluster::new(5); // 5-node cluster cluster.node(0).execute(\"CREATE TABLE partition_test (id INT PRIMARY KEY)\").unwrap(); // Partition: nodes [0,1] cannot communicate with nodes [2,3,4] cluster.create_partition(\u0026[0, 1], \u0026[2, 3, 4]); // The minority partition (nodes 0,1) should not be able to commit writes let result = cluster.node(0).execute(\"INSERT INTO partition_test VALUES (1)\"); assert!(result.is_err()); // Should fail or timeout // The majority partition (nodes 2,3,4) should elect a new leader and accept writes cluster.node(2).execute(\"INSERT INTO partition_test VALUES (2)\").unwrap(); // Heal the partition cluster.heal_partition(); cluster.wait_for_replication().unwrap(); // All nodes should converge on the same state for i in 0..5 { let result = cluster.node(i).query(\"SELECT COUNT(*) FROM partition_test\").unwrap(); assert_eq!(result.rows[0].get_i64(0), 1); // Only the majority write succeeded } } /// Test behavior under disk full conditions. #[test] fn test_disk_full() { let dir = TempDir::new().unwrap(); let db = TestDatabase::with_dir(dir.path()); db.execute(\"CREATE TABLE disk_test (id INT PRIMARY KEY, data TEXT)\").unwrap(); // Simulate disk full by setting a size limit on the test directory db.set_disk_limit(1024 * 1024); // 1MB limit // Insert data until disk is full let mut succeeded = 0; for i in 0..100_000 { match db.execute(\u0026format!( \"INSERT INTO disk_test VALUES ({}, '{}')\", i, \"x\".repeat(1000) )) { Ok(_) =\u003e succeeded += 1, Err(e) =\u003e { // Should get a clear \"disk full\" error, not corruption assert!(e.to_string().contains(\"disk full\") || e.to_string().contains(\"no space\")); break; } } } // Verify that successfully committed data is still readable let result = db.query(\"SELECT COUNT(*) FROM disk_test\").unwrap(); assert_eq!(result.rows[0].get_i64(0), succeeded); } Running Integration Tests # Run all integration tests cargo test --test '*' # Run integration tests for a specific crate cargo test -p thunder-storage --test acid_compliance # Run a specific integration test function cargo test -p thunder-server --test chaos_tests test_crash_recovery # Run with verbose output cargo test -p thunder-api --test integration_test -- --nocapture Property-Based Tests ThunderDB uses the proptest crate for property-based testing. Instead of testing specific examples, property-based tests verify that invariants hold across randomly generated inputs.\nExample: B+Tree Property Tests // thunder-storage/src/btree.rs (within #[cfg(test)] block) use proptest::prelude::*; proptest! { /// Property: Every key that is inserted can be retrieved. #[test] fn prop_insert_then_get( keys in prop::collection::vec(any::\u003ci64\u003e(), 1..1000) ) { let (mut btree, _dir) = setup_btree(); let unique_keys: Vec\u003c_\u003e = keys.into_iter().collect::\u003cstd::collections::HashSet\u003c_\u003e\u003e() .into_iter().collect(); for \u0026key in \u0026unique_keys { btree.insert(\u0026Key::Int64(key), \u0026Value::Int64(key * 2)).unwrap(); } for \u0026key in \u0026unique_keys { let result = btree.get(\u0026Key::Int64(key)).unwrap(); prop_assert_eq!(result, Some(Value::Int64(key * 2))); } } /// Property: The tree is always sorted (range scan returns keys in order). #[test] fn prop_sorted_order( keys in prop::collection::vec(any::\u003ci64\u003e(), 1..500) ) { let (mut btree, _dir) = setup_btree(); for \u0026key in \u0026keys { let _ = btree.insert(\u0026Key::Int64(key), \u0026Value::Int64(key)); } let results: Vec\u003c_\u003e = btree.full_scan().unwrap().collect(); for window in results.windows(2) { prop_assert!(window[0].0 \u003c= window[1].0, \"Keys must be sorted\"); } } /// Property: Deleting a key makes it unretrievable. #[test] fn prop_delete_removes_key( keys in prop::collection::vec(any::\u003ci64\u003e(), 1..200), delete_idx in any::\u003cprop::sample::Index\u003e(), ) { let (mut btree, _dir) = setup_btree(); let unique_keys: Vec\u003c_\u003e = keys.into_iter().collect::\u003cstd::collections::HashSet\u003c_\u003e\u003e() .into_iter().collect(); if unique_keys.is_empty() { return Ok(()); } for \u0026key in \u0026unique_keys { btree.insert(\u0026Key::Int64(key), \u0026Value::Int64(key)).unwrap(); } let delete_key = unique_keys[delete_idx.index(unique_keys.len())]; btree.delete(\u0026Key::Int64(delete_key)).unwrap(); prop_assert_eq!(btree.get(\u0026Key::Int64(delete_key)).unwrap(), None); } } Running Property-Based Tests Property-based tests are part of the regular test suite and run with cargo test. They use a default of 256 test cases per property. For more thorough testing:\n# Run with more test cases PROPTEST_CASES=10000 cargo test -p thunder-storage -- prop_ # Run with a specific seed (for reproducing failures) PROPTEST_SEED=12345 cargo test -p thunder-storage -- prop_insert_then_get When a property test fails, proptest automatically shrinks the failing input to the smallest reproduction case and prints the seed for deterministic replay.\nLoad Tests File: thunder-api/tests/load_test.rs\nLoad tests measure throughput and latency under sustained workloads:\n// thunder-api/tests/load_test.rs /// Test sustained query throughput under concurrent load. #[tokio::test] #[ignore] // Run only when explicitly requested: cargo test -- --ignored async fn test_concurrent_query_throughput() { let server = TestServer::start().await; // Setup: create table and populate with data setup_test_data(\u0026server, 100_000).await; let num_clients = 50; let queries_per_client = 1000; let start = Instant::now(); let handles: Vec\u003c_\u003e = (0..num_clients).map(|_| { let url = server.rest_url(); tokio::spawn(async move { let client = Client::new(); for _ in 0..queries_per_client { let id = rand::random::\u003cu64\u003e() % 100_000; let resp = client.post(format!(\"{}/api/v1/query\", url)) .json(\u0026json!({ \"sql\": format!(\"SELECT * FROM load_test WHERE id = {}\", id) })) .send().await.unwrap(); assert_eq!(resp.status(), 200); } }) }).collect(); for handle in handles { handle.await.unwrap(); } let elapsed = start.elapsed(); let total_queries = num_clients * queries_per_client; let qps = total_queries as f64 / elapsed.as_secs_f64(); println!(\"Load test results:\"); println!(\" Total queries: {}\", total_queries); println!(\" Duration: {:?}\", elapsed); println!(\" Throughput: {:.0} queries/sec\", qps); println!(\" Avg latency: {:.2}ms\", elapsed.as_millis() as f64 / total_queries as f64); // Assert minimum performance thresholds assert!(qps \u003e 1000.0, \"Expected at least 1000 QPS, got {:.0}\", qps); } /// Test write throughput under concurrent load. #[tokio::test] #[ignore] async fn test_concurrent_write_throughput() { let server = TestServer::start().await; server.execute(\"CREATE TABLE write_test (id INT PRIMARY KEY, value TEXT)\").await.unwrap(); let num_writers = 20; let writes_per_writer = 5000; let start = Instant::now(); let handles: Vec\u003c_\u003e = (0..num_writers).map(|writer_id| { let url = server.rest_url(); tokio::spawn(async move { let client = Client::new(); for i in 0..writes_per_writer { let id = writer_id * writes_per_writer + i; let resp = client.post(format!(\"{}/api/v1/execute\", url)) .json(\u0026json!({ \"sql\": format!(\"INSERT INTO write_test VALUES ({}, 'data_{}')\", id, id) })) .send().await.unwrap(); assert_eq!(resp.status(), 200); } }) }).collect(); for handle in handles { handle.await.unwrap(); } let elapsed = start.elapsed(); let total_writes = num_writers * writes_per_writer; let wps = total_writes as f64 / elapsed.as_secs_f64(); println!(\"Write throughput: {:.0} writes/sec\", wps); assert!(wps \u003e 500.0, \"Expected at least 500 writes/sec, got {:.0}\", wps); } Running Load Tests Load tests are marked with #[ignore] so they do not run during normal cargo test. Run them explicitly:\n# Run all load tests cargo test -p thunder-api --test load_test -- --ignored --nocapture # Run a specific load test cargo test -p thunder-api --test load_test test_concurrent_query_throughput -- --ignored --nocapture Benchmarks ThunderDB uses the criterion crate for statistically rigorous micro-benchmarks. Benchmarks live in the benches/ directory of each crate.\nExample Benchmark // thunder-storage/benches/btree_bench.rs use criterion::{criterion_group, criterion_main, Criterion, BenchmarkId, BatchSize}; use thunder_storage::btree::{BTree, Key, Value}; fn bench_btree_insert(c: \u0026mut Criterion) { let mut group = c.benchmark_group(\"btree_insert\"); for size in [100, 1_000, 10_000, 100_000] { group.bench_with_input( BenchmarkId::from_parameter(size), \u0026size, |b, \u0026size| { b.iter_batched( || setup_btree(), // setup |(mut btree, _dir)| { for i in 0..size { btree.insert(\u0026Key::Int64(i), \u0026Value::Int64(i)).unwrap(); } }, BatchSize::SmallInput, ); }, ); } group.finish(); } fn bench_btree_point_lookup(c: \u0026mut Criterion) { let mut group = c.benchmark_group(\"btree_point_lookup\"); for size in [1_000, 10_000, 100_000] { group.bench_with_input( BenchmarkId::from_parameter(size), \u0026size, |b, \u0026size| { let (mut btree, _dir) = setup_btree(); for i in 0..size { btree.insert(\u0026Key::Int64(i), \u0026Value::Int64(i)).unwrap(); } let mut rng = rand::thread_rng(); b.iter(|| { let key = Key::Int64(rng.gen_range(0..size)); btree.get(\u0026key).unwrap() }); }, ); } group.finish(); } fn bench_btree_range_scan(c: \u0026mut Criterion) { let mut group = c.benchmark_group(\"btree_range_scan\"); let (mut btree, _dir) = setup_btree(); for i in 0..100_000i64 { btree.insert(\u0026Key::Int64(i), \u0026Value::Int64(i)).unwrap(); } for range_size in [10, 100, 1_000, 10_000] { group.bench_with_input( BenchmarkId::from_parameter(range_size), \u0026range_size, |b, \u0026range_size| { b.iter(|| { let start = Key::Int64(50_000); let end = Key::Int64(50_000 + range_size); let _results: Vec\u003c_\u003e = btree.range_scan(\u0026start, \u0026end).unwrap().collect(); }); }, ); } group.finish(); } criterion_group!(benches, bench_btree_insert, bench_btree_point_lookup, bench_btree_range_scan); criterion_main!(benches); Running Benchmarks # Run all benchmarks cargo bench # Run benchmarks for a specific crate cargo bench -p thunder-storage # Run a specific benchmark cargo bench -p thunder-storage -- btree_point_lookup # Generate HTML reports (criterion automatically creates these in target/criterion/) cargo bench -p thunder-storage open target/criterion/report/index.html Benchmark Files Crate Benchmark File What It Measures thunder-storage benches/btree_bench.rs B+Tree insert, lookup, range scan throughput thunder-storage benches/wal_bench.rs WAL write throughput, group commit latency thunder-storage benches/compression_bench.rs Compression/decompression speed and ratios thunder-query benches/executor_bench.rs Query execution throughput for various query types thunder-query benches/vectorized_bench.rs Vectorized vs. row-at-a-time execution thunder-protocol benches/protocol_bench.rs Protocol encoding/decoding throughput thunder-sql benches/parser_bench.rs SQL parsing throughput thunder-sql benches/optimizer_bench.rs Query optimization time for various plan shapes Test Coverage Measuring Coverage Use cargo-tarpaulin to measure test coverage:\n# Install tarpaulin cargo install cargo-tarpaulin # Run coverage for the entire workspace cargo tarpaulin --workspace --out Html # Run coverage for a specific crate cargo tarpaulin -p thunder-storage --out Html # Generate Lcov output for CI integration cargo tarpaulin --workspace --out Lcov --output-dir coverage/ # View the HTML report open tarpaulin-report.html Coverage Targets ThunderDB aims for the following coverage targets:\nCategory Target Rationale thunder-common 90%+ Foundational types must be thoroughly tested thunder-storage 85%+ Storage correctness is critical for data integrity thunder-txn 85%+ Transaction correctness ensures ACID properties thunder-sql 80%+ SQL parsing and optimization have many edge cases thunder-query 80%+ Query execution correctness ensures correct results thunder-protocol 75%+ Protocol compatibility requires testing many message types thunder-api 70%+ API tests cover handler logic and serialization Overall workspace 80%+ Comprehensive coverage across all crates Coverage numbers are tracked in CI and reported on each pull request.\nWriting New Tests Test File Placement Unit test: Add a #[test] function inside the #[cfg(test)] mod tests block in the relevant source file. Integration test: Create or add to a file in the tests/ directory of the relevant crate. Benchmark: Create or add to a file in the benches/ directory of the relevant crate. Test Fixtures and Utilities ThunderDB provides shared test utilities in several locations:\n// thunder-common/src/test_utils.rs (compiled only in test mode) #[cfg(test)] pub mod test_utils { /// Create a temporary database for testing pub fn create_test_db() -\u003e TestDatabase { /* ... */ } /// Generate random rows for testing pub fn random_rows(count: usize, schema: \u0026Schema) -\u003e Vec\u003cRow\u003e { /* ... */ } /// Assert that two result sets are equivalent (order-independent) pub fn assert_result_sets_equal(a: \u0026[Row], b: \u0026[Row]) { /* ... */ } } Assertions Use these assertion patterns:\n// Standard assertions assert_eq!(actual, expected); assert_ne!(actual, unexpected); assert!(condition, \"descriptive message: {}\", context); // Result assertions assert!(result.is_ok(), \"Expected Ok, got {:?}\", result); assert!(result.is_err(), \"Expected Err, got {:?}\", result); // For proptest prop_assert_eq!(actual, expected); prop_assert!(condition); // Custom assertion for approximate floating-point comparison assert!((actual - expected).abs() \u003c 1e-6, \"Values differ: {} vs {}\", actual, expected); Async Test Pattern For async tests, use the #[tokio::test] attribute:\n#[tokio::test] async fn test_async_operation() { let server = TestServer::start().await; let result = server.query(\"SELECT 1\").await.unwrap(); assert_eq!(result.rows[0].get_i64(0), 1); } // For tests that need a multi-threaded runtime #[tokio::test(flavor = \"multi_thread\", worker_threads = 4)] async fn test_concurrent_operations() { // ... } Test Naming Conventions Follow these naming patterns:\ntest_{operation} # Basic operation test test_{operation}_{condition} # Operation under specific condition test_{operation}_{expected_outcome} # Operation with expected outcome test_{component}_{scenario} # Component-specific scenario # Examples: test_insert_single_row test_insert_duplicate_key_returns_error test_btree_split_at_capacity test_wal_recovery_after_crash test_mvcc_snapshot_isolation test_postgres_protocol_ssl_handshake CI/CD Pipeline ThunderDB uses a comprehensive CI/CD pipeline that runs on every push and pull request.\nPipeline Stages +-- Stage 1: Format \u0026 Lint (parallel) --------+ | cargo fmt -- --check | | cargo clippy --all-targets -- -D warnings | +----------------------------------------------+ | +-- Stage 2: Build (sequential) ---------------+ | cargo build --all-targets | +----------------------------------------------+ | +-- Stage 3: Test (parallel) ------------------+ | cargo test --lib (unit tests) | | cargo test --test '*' (integration) | | cargo test --doc (doc tests) | +----------------------------------------------+ | +-- Stage 4: Coverage (sequential) ------------+ | cargo tarpaulin --workspace | | Upload coverage report | +----------------------------------------------+ | +-- Stage 5: Benchmark (on main only) ---------+ | cargo bench | | Compare with baseline | | Alert on regressions | +----------------------------------------------+ CI Configuration The pipeline is defined in .github/workflows/ci.yml:\nTrigger: Runs on every push to main and on every pull request. Matrix: Tests on Linux (Ubuntu latest), macOS (latest), with the minimum supported Rust version (MSRV) and the latest stable Rust. Caching: Cargo registry and target directories are cached for faster builds. Timeout: Individual jobs have a 30-minute timeout. Required Checks The following checks must pass before a pull request can be merged:\ncargo fmt -- --check – Code is properly formatted cargo clippy --all-targets --all-features -- -D warnings – No clippy warnings cargo test – All tests pass cargo test --doc – All doc tests pass Coverage does not decrease below thresholds No performance regressions detected in benchmarks (main branch only) Running the Full CI Locally Before pushing, you can run the same checks that CI will execute:\n# Run all CI checks locally cargo fmt -- --check \u0026\u0026 \\ cargo clippy --all-targets --all-features -- -D warnings \u0026\u0026 \\ cargo test \u0026\u0026 \\ cargo test --doc # Or use the test script which does all of the above ./scripts/run_tests.sh Debugging Test Failures Viewing Test Output By default, Rust captures stdout/stderr from passing tests. To see all output:\ncargo test -- --nocapture Enabling Trace Logging in Tests # Enable debug logging for a specific module RUST_LOG=thunder_storage::wal=debug cargo test -p thunder-storage # Enable trace logging for everything RUST_LOG=trace cargo test -p thunder-storage -- --nocapture Reproducing Flaky Tests If a test fails intermittently:\n# Run the test repeatedly to reproduce for i in $(seq 1 100); do cargo test -p thunder-storage test_concurrent_writes || break done Using a Debugger # Build tests without running them cargo test -p thunder-storage --no-run # Find the test binary ls target/debug/deps/thunder_storage-* # Run under a debugger lldb target/debug/deps/thunder_storage-abc123 -- test_name ","categories":"","description":"Comprehensive guide to ThunderDB's testing strategy -- unit tests, integration tests, ACID compliance tests, chaos tests, property-based tests, benchmarks, and CI/CD pipeline.","excerpt":"Comprehensive guide to ThunderDB's testing strategy -- unit tests, …","ref":"/docs/docs/contributor/testing/","tags":"","title":"Testing"},{"body":"Administrator Guide This guide provides comprehensive documentation for deploying, configuring, monitoring, and maintaining ThunderDB in production environments. Whether you are running a single-node development instance or a multi-node distributed cluster, this guide covers the operational knowledge required to keep ThunderDB running reliably and efficiently.\nOverview ThunderDB is a distributed HTAP (Hybrid Transactional/Analytical Processing) database built in Rust. It supports multiple wire protocols (PostgreSQL, MySQL, RESP/Redis, HTTP, and gRPC) and is designed for high-throughput, low-latency workloads across both OLTP and OLAP use cases. As an administrator, your responsibilities span the following areas.\nDeployment Deploy ThunderDB from source, via Docker or Kubernetes, or through system packages. Set up single-node instances or multi-node clusters with Raft-based consensus and automatic region balancing.\nDeployment Guide Configuration Tune ThunderDB for your workload using the thunderdb.toml configuration file. Configure network ports, storage engine parameters, cluster settings, security policies, and logging levels.\nConfiguration Reference Monitoring Observe ThunderDB’s health and performance through Prometheus metrics, Grafana dashboards, structured logs, and health check endpoints. Set up alerting based on SLOs to catch issues before they affect users.\nMonitoring Guide Backup and Recovery Protect your data with full backups, incremental WAL-based backups, and point-in-time recovery. Plan for disaster recovery with cross-region backup strategies.\nBackup \u0026 Recovery Guide Security Harden ThunderDB with authentication, TLS encryption, role-based access control, audit logging, and encryption at rest. Follow security best practices for production deployments.\nSecurity Guide Troubleshooting Diagnose and resolve common issues including connection problems, performance degradation, WAL corruption, cluster split-brain scenarios, and memory pressure. Use structured logs and debug tracing to identify root causes.\nTroubleshooting Guide Quick Reference Task Command / Path Start ThunderDB ./thunderdb --config config/thunderdb.toml Configuration file /etc/thunderdb/thunderdb.toml Data directory /var/lib/thunderdb/data/ WAL directory /var/lib/thunderdb/wal/ Log files /var/log/thunderdb/ systemd service systemctl start thunderdb Health check GET http://localhost:8088/admin/health Metrics endpoint GET http://localhost:8088/admin/metrics PostgreSQL port 5432 MySQL port 3306 RESP (Redis) port 6379 HTTP API port 8088 gRPC port 9090 Prerequisites Before deploying ThunderDB in production, ensure the following:\nOperating System: Linux (Ubuntu 20.04+, Debian 11+, RHEL 8+, or Amazon Linux 2) or macOS 12+. Linux is recommended for production. Hardware: Minimum 4 CPU cores, 8 GB RAM, and SSD-backed storage. See the Configuration Guide for detailed sizing recommendations. Network: Ensure all required ports are accessible between cluster nodes and from client applications. Permissions: A dedicated system user (thunder) with appropriate file system permissions for data and log directories. Architecture Overview for Administrators Understanding ThunderDB’s internal architecture helps with operational decision-making.\nClient Connections | | | | | +----+----+----+----+----+----+ | PG | MySQL| RESP | HTTP | gRPC| | 5432| 3306 | 6379 | 8088 | 9090| +-----+------+------+------+-----+ | +-------+-------+ | Query Engine | | (Volcano/Vec) | +-------+-------+ | +----------+----------+ | Transaction Manager | | (MVCC + 2PC) | +----------+----------+ | +----------+----------+ | Storage Engine | | (Buffer Pool + WAL) | +----------+----------+ | +----------+----------+ | Distributed Layer | | (Raft + Region Split)| +----------+----------+ Key components from an operational perspective:\nBuffer Pool: In-memory cache for data pages. Size this appropriately for your workload to maximize cache hit rates. WAL (Write-Ahead Log): Ensures durability and supports point-in-time recovery. Monitor WAL size and configure archival policies. Raft Consensus: Provides strong consistency across cluster nodes. Monitor election timeouts and replication lag. Region Management: Data is split into regions that can be automatically balanced across nodes. Configure region sizes based on your data distribution. Next Steps Start with the Deployment Guide to get ThunderDB running, then proceed to Configuration for tuning, and Monitoring for observability.\n","categories":"","description":"Deploy, configure, monitor, and maintain ThunderDB in production environments.","excerpt":"Deploy, configure, monitor, and maintain ThunderDB in production …","ref":"/docs/docs/administrator/","tags":"","title":"Administrator Guide"},{"body":"Backup \u0026 Recovery Data protection is a critical aspect of operating ThunderDB in production. This guide covers full backup procedures, incremental backups through WAL archiving, point-in-time recovery (PITR), and disaster recovery planning.\nBackup Overview ThunderDB supports multiple backup strategies that can be combined for comprehensive data protection:\nStrategy RPO RTO Storage Cost Complexity Full backup Point-in-time of backup Minutes to hours High Low Incremental (WAL archiving) Near-zero (last WAL flush) Minutes Low (deltas only) Medium Full + Incremental (PITR) Near-zero Minutes Medium Medium Cross-region replication Near-zero Seconds (failover) High High RPO = Recovery Point Objective (how much data you can afford to lose). RTO = Recovery Time Objective (how quickly you need to recover).\nFull Backup A full backup captures the complete state of a ThunderDB node at a point in time. It includes the data directory and current WAL files.\nOnline Backup (Recommended) ThunderDB supports online (hot) backups that do not require stopping the server:\n# Trigger a consistent backup via the admin API curl -X POST http://localhost:8088/admin/backup \\ -H \"Content-Type: application/json\" \\ -d '{ \"destination\": \"/backups/thunderdb/full-2026-01-15\", \"include_wal\": true, \"compress\": true }' Response:\n{ \"status\": \"started\", \"backup_id\": \"bk-20260115-103045\", \"destination\": \"/backups/thunderdb/full-2026-01-15\", \"estimated_size_bytes\": 5368709120 } Monitor backup progress:\ncurl http://localhost:8088/admin/backup/status/bk-20260115-103045 Manual Full Backup If you prefer a manual approach, follow these steps:\n# 1. Force a checkpoint to flush dirty pages to disk curl -X POST http://localhost:8088/admin/checkpoint # 2. Copy the data directory sudo -u thunder rsync -av --progress \\ /var/lib/thunderdb/data/ \\ /backups/thunderdb/full-$(date +%Y%m%d)/data/ # 3. Copy the WAL directory sudo -u thunder rsync -av --progress \\ /var/lib/thunderdb/wal/ \\ /backups/thunderdb/full-$(date +%Y%m%d)/wal/ # 4. Copy the configuration sudo cp /etc/thunderdb/thunderdb.toml \\ /backups/thunderdb/full-$(date +%Y%m%d)/thunderdb.toml Backup Contents A full backup includes:\nDirectory / File Description data/ All data pages, indexes, and metadata files. wal/ Write-ahead log files active at backup time. thunderdb.toml Configuration file (for reference during restore). backup_manifest.json Metadata about the backup (timestamp, LSN, checksum). Verifying a Backup Always verify backups after creation:\n# Verify backup integrity thunderdb --verify-backup /backups/thunderdb/full-2026-01-15 # Expected output: # Backup verification: PASSED # Backup time: 2026-01-15T10:30:45Z # LSN: 0/1A3B4C5D # Data pages: 8192 (verified) # WAL segments: 12 (verified) # Checksum: OK Incremental Backup (WAL Archiving) Incremental backups capture only the changes since the last full or incremental backup by archiving WAL (Write-Ahead Log) segments. This dramatically reduces backup storage and time.\nEnabling WAL Archiving Add the following to your configuration:\n[storage] # Enable WAL archiving wal_archive_enabled = true # Directory or command for archiving WAL segments wal_archive_dir = \"/backups/thunderdb/wal-archive\" # Alternative: archive via command (e.g., to S3) # wal_archive_command = \"aws s3 cp %f s3://my-bucket/thunderdb/wal/%n\" # Retain archived WAL segments for this duration wal_archive_retention = \"7d\" How WAL Archiving Works ThunderDB writes transactions to WAL segments (files of max_wal_size or less). When a WAL segment is full or a checkpoint occurs, the segment is archived (copied to the archive directory or processed by the archive command). Archived segments are retained according to wal_archive_retention. For recovery, archived WAL segments are replayed on top of a full backup. Monitoring WAL Archiving # Check archiving status curl http://localhost:8088/admin/wal/archive/status # Response: # { # \"archiving_enabled\": true, # \"last_archived_segment\": \"000000010000000000000042\", # \"last_archive_time\": \"2026-01-15T10:30:45Z\", # \"segments_pending\": 0, # \"archive_rate_bytes_per_sec\": 1048576, # \"total_archived_bytes\": 536870912 # } WAL Archive to Object Storage For cloud deployments, archive WAL segments to object storage:\nAmazon S3:\n[storage] wal_archive_command = \"aws s3 cp %f s3://my-thunderdb-backups/wal/%n --storage-class STANDARD_IA\" wal_restore_command = \"aws s3 cp s3://my-thunderdb-backups/wal/%n %f\" Google Cloud Storage:\n[storage] wal_archive_command = \"gsutil cp %f gs://my-thunderdb-backups/wal/%n\" wal_restore_command = \"gsutil cp gs://my-thunderdb-backups/wal/%n %f\" Azure Blob Storage:\n[storage] wal_archive_command = \"az storage blob upload --file %f --container-name thunderdb-wal --name %n\" wal_restore_command = \"az storage blob download --container-name thunderdb-wal --name %n --file %f\" In these commands:\n%f is replaced with the full path to the WAL segment file. %n is replaced with the WAL segment filename only. Point-in-Time Recovery (PITR) PITR allows you to restore a ThunderDB instance to any specific point in time, provided you have a full backup and the WAL archive covering that time period.\nPrerequisites A full backup taken before the target recovery time. All WAL archive segments from the backup time to the target recovery time. Recovery Procedure # Restore to a specific timestamp thunderdb --restore-pitr \"2026-01-15T14:30:00Z\" \\ --restore-backup /backups/thunderdb/full-2026-01-15 # Restore to the latest available point thunderdb --restore-pitr \"latest\" \\ --restore-backup /backups/thunderdb/full-2026-01-15 # Restore to a specific WAL LSN (Log Sequence Number) thunderdb --restore-pitr \"lsn:0/1A3B4C5D\" \\ --restore-backup /backups/thunderdb/full-2026-01-15 Step-by-Step PITR Process Stop ThunderDB on the target node:\nsudo systemctl stop thunderdb Clear the existing data and WAL directories (or use a fresh node):\nsudo rm -rf /var/lib/thunderdb/data/* sudo rm -rf /var/lib/thunderdb/wal/* Restore from the full backup:\nsudo -u thunder cp -a /backups/thunderdb/full-2026-01-15/data/* /var/lib/thunderdb/data/ sudo -u thunder cp -a /backups/thunderdb/full-2026-01-15/wal/* /var/lib/thunderdb/wal/ Run PITR recovery:\nthunderdb --restore-pitr \"2026-01-15T14:30:00Z\" \\ --restore-backup /backups/thunderdb/full-2026-01-15 \\ --wal-archive-dir /backups/thunderdb/wal-archive \\ --config /etc/thunderdb/thunderdb.toml Start ThunderDB normally after recovery completes:\nsudo systemctl start thunderdb Verify data integrity after recovery:\ncurl http://localhost:8088/admin/health # Connect via psql and verify data psql -h localhost -U admin -c \"SELECT COUNT(*) FROM your_table;\" Recovery Output During PITR, ThunderDB logs the recovery progress:\n[INFO] Starting Point-in-Time Recovery [INFO] Target time: 2026-01-15T14:30:00Z [INFO] Base backup LSN: 0/1A000000 [INFO] Phase 1: Restoring base backup... done (8192 pages) [INFO] Phase 2: Replaying WAL segments... [INFO] Replaying segment 000000010000000000000038... done [INFO] Replaying segment 000000010000000000000039... done [INFO] Replaying segment 00000001000000000000003A... done (target reached) [INFO] Phase 3: Recovery complete [INFO] Recovered to: 2026-01-15T14:30:00.000Z (LSN: 0/1A3B4C5D) [INFO] Transactions recovered: 45,231 [INFO] Transactions rolled back: 12 (in-progress at recovery point) WAL-Based Recovery (ARIES) ThunderDB uses the ARIES (Algorithm for Recovery and Isolation Exploiting Semantics) recovery algorithm, which provides crash recovery through a three-phase process. This happens automatically on startup after an unclean shutdown.\nPhase 1: Analysis The analysis phase scans the WAL from the last checkpoint to determine:\nWhich pages were dirty (modified but not flushed) at the time of the crash. Which transactions were active (not yet committed or aborted). The starting point for the redo phase. Phase 2: Redo The redo phase replays all WAL records from the analysis starting point forward, reapplying all changes to bring the database to the exact state it was in at the time of the crash. This includes changes made by transactions that will later be undone.\nPhase 3: Undo The undo phase rolls back all transactions that were active (not committed) at the time of the crash. It processes undo records in reverse order, ensuring the database only contains the effects of committed transactions.\nMonitoring Recovery Recovery progress is logged during startup:\n[INFO] Crash recovery initiated [INFO] Last checkpoint LSN: 0/1A000000 [INFO] Phase 1 (Analysis): Scanning WAL... 42 dirty pages, 3 active transactions [INFO] Phase 2 (Redo): Replaying from LSN 0/1A000000... 1,234 records replayed [INFO] Phase 3 (Undo): Rolling back 3 active transactions... done [INFO] Recovery complete in 2.34s Recovery Tuning For large databases where recovery time is critical:\n[storage] # More frequent checkpoints reduce the amount of WAL to replay checkpoint_interval = \"30s\" # Smaller max WAL size limits recovery scope max_wal_size = \"512MB\" Backup Scheduling Best Practices Recommended Backup Schedule Backup Type Frequency Retention Purpose Full backup Daily (off-peak hours) 7 days Base for PITR, standalone restore WAL archiving Continuous 7 days Incremental changes for PITR Full backup (weekly) Weekly (Sunday night) 30 days Longer-term recovery Full backup (monthly) Monthly 12 months Compliance and archival Automated Backup Script #!/bin/bash # /etc/cron.d/thunderdb-backup.sh # Run daily at 2:00 AM: 0 2 * * * /etc/cron.d/thunderdb-backup.sh set -euo pipefail BACKUP_DIR=\"/backups/thunderdb\" DATE=$(date +%Y%m%d) RETENTION_DAYS=7 echo \"[$(date)] Starting ThunderDB backup...\" # Trigger online backup RESPONSE=$(curl -s -X POST http://localhost:8088/admin/backup \\ -H \"Content-Type: application/json\" \\ -d \"{\\\"destination\\\": \\\"${BACKUP_DIR}/full-${DATE}\\\", \\\"include_wal\\\": true, \\\"compress\\\": true}\") BACKUP_ID=$(echo $RESPONSE | jq -r '.backup_id') echo \"[$(date)] Backup started: $BACKUP_ID\" # Wait for backup to complete while true; do STATUS=$(curl -s http://localhost:8088/admin/backup/status/$BACKUP_ID | jq -r '.status') if [ \"$STATUS\" = \"completed\" ]; then echo \"[$(date)] Backup completed successfully\" break elif [ \"$STATUS\" = \"failed\" ]; then echo \"[$(date)] ERROR: Backup failed!\" exit 1 fi sleep 10 done # Verify backup thunderdb --verify-backup \"${BACKUP_DIR}/full-${DATE}\" # Remove old backups find \"${BACKUP_DIR}\" -maxdepth 1 -name \"full-*\" -mtime +${RETENTION_DAYS} -exec rm -rf {} \\; echo \"[$(date)] Cleaned up backups older than ${RETENTION_DAYS} days\" echo \"[$(date)] Backup process complete\" Backup Monitoring Add alerts for backup failures:\n# deploy/prometheus/rules/thunderdb-backup-alerts.yml groups: - name: thunderdb.backup rules: - alert: ThunderDBBackupFailed expr: thunderdb_last_backup_status == 0 for: 1m labels: severity: critical annotations: summary: \"ThunderDB backup failed on {{ $labels.instance }}\" - alert: ThunderDBBackupStale expr: time() - thunderdb_last_backup_timestamp \u003e 86400 * 2 for: 1h labels: severity: warning annotations: summary: \"No successful backup in 48 hours on {{ $labels.instance }}\" - alert: ThunderDBWALArchiveLag expr: thunderdb_wal_archive_pending_segments \u003e 100 for: 10m labels: severity: warning annotations: summary: \"WAL archiving is falling behind on {{ $labels.instance }}\" Disaster Recovery Planning Recovery Scenarios Scenario Strategy Expected RTO Single node failure (cluster) Automatic Raft failover Seconds Data corruption on one node Restore from backup or re-replicate from peers Minutes Full cluster failure (same region) Restore all nodes from backup + WAL archive 30-60 minutes Regional disaster Failover to cross-region replica Minutes Accidental data deletion PITR to before deletion timestamp 15-30 minutes Cross-Region Backup Strategy For maximum disaster resilience, maintain backups in a different geographic region:\nPrimary Region (us-east-1) Backup Region (us-west-2) +-------------------+ +-------------------+ | ThunderDB Cluster | -- WAL --\u003e | S3 Bucket | | (3 nodes) | archiving | (WAL archive) | | | | | | Daily full backup | -- sync --\u003e | S3 Bucket | | (local disk) | | (full backups) | +-------------------+ +-------------------+ Implementation:\n# Sync local backups to a remote region aws s3 sync /backups/thunderdb/ s3://thunderdb-backups-us-west-2/ \\ --storage-class STANDARD_IA \\ --region us-west-2 # Configure WAL archiving to the remote region # In thunderdb.toml: # wal_archive_command = \"aws s3 cp %f s3://thunderdb-backups-us-west-2/wal/%n --region us-west-2\" Disaster Recovery Runbook Assess the failure scope: Determine whether it is a single node, full cluster, or regional failure. For single node failure: If the cluster has quorum, the node will recover automatically. Otherwise, restore from backup. For full cluster failure: a. Provision new infrastructure (or use standby). b. Restore the most recent full backup on each node. c. Apply WAL archive to bring all nodes to the same point. d. Start the cluster and verify data integrity. e. Update DNS/load balancer to point to the recovered cluster. For accidental deletion: Use PITR to recover to a timestamp just before the deletion. Post-recovery: Verify data integrity, check replication status, resume backups. Testing Recovery Regularly test your recovery procedures (at least quarterly):\n# 1. Provision a test environment # 2. Restore from the latest production backup thunderdb --restore-pitr \"latest\" \\ --restore-backup /backups/thunderdb/full-latest \\ --config /etc/thunderdb/thunderdb-test.toml # 3. Start the test instance thunderdb --config /etc/thunderdb/thunderdb-test.toml # 4. Run validation queries to verify data integrity psql -h localhost -p 15432 -U admin -f /scripts/recovery-validation.sql # 5. Document the recovery time and any issues Record the results of each recovery test, including actual RTO, data completeness verification, and any problems encountered.\n","categories":"","description":"Protect your data with full backups, incremental WAL-based backups, point-in-time recovery, and disaster recovery planning.","excerpt":"Protect your data with full backups, incremental WAL-based backups, …","ref":"/docs/docs/administrator/backup-recovery/","tags":"","title":"Backup \u0026 Recovery"},{"body":"Examples \u0026 Use Cases This section provides complete, runnable examples for seven common application patterns. Each example includes the schema design, sample data, queries, and expected output so you can follow along against a local ThunderDB instance.\n1. E-Commerce Application (OLTP) An online store with users, products, orders, and real-time inventory management. This example demonstrates ThunderDB’s transactional capabilities with row-oriented storage.\nDescription A typical e-commerce backend needs fast point lookups for product pages, ACID transactions for order placement (decrement inventory atomically), and efficient queries for user order history. ThunderDB’s row-oriented engine handles all of these in a single system.\nSchema -- Users table CREATE TABLE users ( id BIGINT PRIMARY KEY, name VARCHAR(255) NOT NULL, email VARCHAR(255) UNIQUE NOT NULL, membership VARCHAR(20) DEFAULT 'standard', created_at TIMESTAMPTZ DEFAULT now() ); -- Product catalog CREATE TABLE products ( id BIGINT PRIMARY KEY, name VARCHAR(255) NOT NULL, description TEXT, price DECIMAL(10,2) NOT NULL, category VARCHAR(100) NOT NULL, created_at TIMESTAMPTZ DEFAULT now() ); -- Inventory (separate for concurrency) CREATE TABLE inventory ( product_id BIGINT PRIMARY KEY REFERENCES products(id), quantity INT32 NOT NULL CHECK (quantity \u003e= 0), reserved INT32 NOT NULL DEFAULT 0, warehouse VARCHAR(50) NOT NULL ); -- Orders CREATE TABLE orders ( id BIGINT PRIMARY KEY, customer_id BIGINT NOT NULL REFERENCES users(id), status VARCHAR(20) NOT NULL DEFAULT 'pending', total DECIMAL(10,2) NOT NULL, created_at TIMESTAMPTZ DEFAULT now(), updated_at TIMESTAMPTZ DEFAULT now() ); -- Order line items CREATE TABLE order_items ( id BIGINT PRIMARY KEY, order_id BIGINT NOT NULL REFERENCES orders(id) ON DELETE CASCADE, product_id BIGINT NOT NULL REFERENCES products(id), quantity INT32 NOT NULL CHECK (quantity \u003e 0), unit_price DECIMAL(10,2) NOT NULL ); -- Indexes CREATE INDEX idx_orders_customer ON orders (customer_id); CREATE INDEX idx_orders_status ON orders (status); CREATE INDEX idx_order_items_order ON order_items (order_id); CREATE INDEX idx_products_category ON products (category); Sample Data -- Users INSERT INTO users (id, name, email, membership) VALUES (1, 'Alice Johnson', 'alice@example.com', 'gold'), (2, 'Bob Smith', 'bob@example.com', 'standard'), (3, 'Carol White', 'carol@example.com', 'gold'), (4, 'Dave Brown', 'dave@example.com', 'platinum'); -- Products INSERT INTO products (id, name, description, price, category) VALUES (101, 'Wireless Mouse', 'Ergonomic wireless mouse with USB-C', 29.99, 'electronics'), (102, 'Mechanical Keyboard', 'Cherry MX Blue switches, RGB', 149.99, 'electronics'), (103, 'Python Cookbook', 'Advanced Python recipes, 3rd edition', 45.00, 'books'), (104, 'Standing Desk', 'Electric height-adjustable, 60 inch', 599.99, 'furniture'), (105, 'USB-C Hub', '7-port USB-C dock with HDMI', 79.99, 'electronics'); -- Inventory INSERT INTO inventory (product_id, quantity, reserved, warehouse) VALUES (101, 500, 12, 'warehouse-east'), (102, 200, 5, 'warehouse-east'), (103, 1000, 0, 'warehouse-west'), (104, 50, 3, 'warehouse-west'), (105, 350, 8, 'warehouse-east'); Queries Place an order (transactional):\nBEGIN TRANSACTION ISOLATION LEVEL SERIALIZABLE; -- Check inventory SELECT quantity - reserved AS available FROM inventory WHERE product_id = 102; -- Returns: available = 195 -- Reserve inventory UPDATE inventory SET reserved = reserved + 1 WHERE product_id = 102 AND (quantity - reserved) \u003e= 1; -- Create the order INSERT INTO orders (id, customer_id, status, total) VALUES (1001, 1, 'confirmed', 149.99); INSERT INTO order_items (id, order_id, product_id, quantity, unit_price) VALUES (5001, 1001, 102, 1, 149.99); COMMIT; User order history:\nSELECT o.id AS order_id, o.status, o.total, o.created_at, jsonb_agg(jsonb_build_object( 'product', p.name, 'quantity', oi.quantity, 'price', oi.unit_price )) AS items FROM orders o JOIN order_items oi ON o.id = oi.order_id JOIN products p ON oi.product_id = p.id WHERE o.customer_id = 1 GROUP BY o.id, o.status, o.total, o.created_at ORDER BY o.created_at DESC; Expected output:\norder_id | status | total | created_at | items ----------+-----------+--------+--------------------------+----------------------------------------------- 1001 | confirmed | 149.99 | 2025-12-15 10:30:00+00 | [{\"price\": 149.99, \"product\": \"Mechanical Keyboard\", \"quantity\": 1}] Low-stock alert:\nSELECT p.id, p.name, p.category, i.quantity, i.reserved, i.quantity - i.reserved AS available, i.warehouse FROM products p JOIN inventory i ON p.id = i.product_id WHERE (i.quantity - i.reserved) \u003c 100 ORDER BY available ASC; Expected output:\nid | name | category | quantity | reserved | available | warehouse -----+---------------+-----------+----------+----------+-----------+---------------- 104 | Standing Desk | furniture | 50 | 3 | 47 | warehouse-west 2. Analytics Dashboard (OLAP) An analytics platform that ingests high volumes of events and serves aggregate dashboards. This example demonstrates ThunderDB’s columnar storage engine for analytical workloads.\nDescription Analytics dashboards need to scan millions of rows, compute aggregations by various dimensions (time, geography, device), and return results in sub-second latency. ThunderDB’s columnar engine stores data in compressed columns with BRIN indexes, making it ideal for time-series analytics.\nSchema -- Columnar table for events (optimized for scans) CREATE TABLE analytics_events ( event_id BIGINT PRIMARY KEY, user_id BIGINT, session_id UUID, event_type VARCHAR(50) NOT NULL, page_url VARCHAR(500), referrer VARCHAR(500), device_type VARCHAR(20), country VARCHAR(2), city VARCHAR(100), properties JSONB, occurred_at TIMESTAMPTZ NOT NULL ) ENGINE = COLUMNAR; -- BRIN index on timestamp for efficient time range scans CREATE INDEX idx_events_time ON analytics_events USING BRIN (occurred_at) WITH (pages_per_range = 32); -- B-tree index for event type filtering CREATE INDEX idx_events_type ON analytics_events (event_type); -- Daily revenue materialization CREATE TABLE daily_revenue ( date DATE PRIMARY KEY, revenue DECIMAL(12,2) NOT NULL, orders INT32 NOT NULL, avg_order DECIMAL(10,2) NOT NULL ) ENGINE = COLUMNAR; Sample Data INSERT INTO analytics_events (event_id, user_id, session_id, event_type, page_url, device_type, country, city, properties, occurred_at) VALUES (1, 1001, 'a1b2c3d4-e5f6-7890-abcd-ef1234567890', 'page_view', '/products/102', 'desktop', 'US', 'New York', '{\"duration_ms\": 4500}', '2025-12-15 10:00:00+00'), (2, 1001, 'a1b2c3d4-e5f6-7890-abcd-ef1234567890', 'add_to_cart', '/products/102', 'desktop', 'US', 'New York', '{\"product_id\": 102, \"price\": 149.99}', '2025-12-15 10:02:00+00'), (3, 1002, 'b2c3d4e5-f6a7-8901-bcde-f12345678901', 'page_view', '/products/101', 'mobile', 'GB', 'London', '{\"duration_ms\": 2100}', '2025-12-15 10:05:00+00'), (4, 1003, 'c3d4e5f6-a7b8-9012-cdef-123456789012', 'purchase', '/checkout', 'desktop', 'US', 'San Francisco', '{\"order_id\": 1001, \"total\": 149.99}', '2025-12-15 10:10:00+00'), (5, 1002, 'b2c3d4e5-f6a7-8901-bcde-f12345678901', 'page_view', '/', 'mobile', 'GB', 'London', '{\"duration_ms\": 800}', '2025-12-15 10:12:00+00'), (6, 1004, 'd4e5f6a7-b8c9-0123-defa-234567890123', 'signup', '/register', 'tablet', 'DE', 'Berlin', '{\"source\": \"google_ads\"}', '2025-12-15 10:15:00+00'), (7, 1004, 'd4e5f6a7-b8c9-0123-defa-234567890123', 'page_view', '/products', 'tablet', 'DE', 'Berlin', '{\"duration_ms\": 3200}', '2025-12-15 10:16:00+00'), (8, 1001, 'a1b2c3d4-e5f6-7890-abcd-ef1234567890', 'purchase', '/checkout', 'desktop', 'US', 'New York', '{\"order_id\": 1002, \"total\": 79.99}', '2025-12-15 10:20:00+00'); INSERT INTO daily_revenue (date, revenue, orders, avg_order) VALUES ('2025-12-01', 12450.00, 85, 146.47), ('2025-12-02', 14200.50, 102, 139.22), ('2025-12-03', 11890.25, 78, 152.44), ('2025-12-04', 15600.00, 112, 139.29), ('2025-12-05', 13100.75, 91, 143.96), ('2025-12-06', 9800.00, 65, 150.77), ('2025-12-07', 8200.50, 58, 141.39), ('2025-12-08', 13900.25, 95, 146.32), ('2025-12-09', 16200.00, 118, 137.29), ('2025-12-10', 14800.50, 105, 140.96); Queries Hourly event counts by type (time-series):\nSELECT date_trunc('hour', occurred_at) AS hour, event_type, COUNT(*) AS event_count FROM analytics_events WHERE occurred_at \u003e= '2025-12-15' AND occurred_at \u003c '2025-12-16' GROUP BY 1, 2 ORDER BY 1, 2; Expected output:\nhour | event_type | event_count --------------------------+--------------+------------ 2025-12-15 10:00:00+00 | add_to_cart | 1 2025-12-15 10:00:00+00 | page_view | 4 2025-12-15 10:00:00+00 | purchase | 2 2025-12-15 10:00:00+00 | signup | 1 Conversion funnel analysis:\nWITH funnel AS ( SELECT COUNT(DISTINCT CASE WHEN event_type = 'page_view' THEN user_id END) AS viewers, COUNT(DISTINCT CASE WHEN event_type = 'add_to_cart' THEN user_id END) AS added_to_cart, COUNT(DISTINCT CASE WHEN event_type = 'purchase' THEN user_id END) AS purchasers FROM analytics_events WHERE occurred_at \u003e= '2025-12-15' AND occurred_at \u003c '2025-12-16' ) SELECT viewers, added_to_cart, purchasers, ROUND(100.0 * added_to_cart / NULLIF(viewers, 0), 1) AS view_to_cart_pct, ROUND(100.0 * purchasers / NULLIF(added_to_cart, 0), 1) AS cart_to_purchase_pct FROM funnel; Expected output:\nviewers | added_to_cart | purchasers | view_to_cart_pct | cart_to_purchase_pct ---------+---------------+------------+------------------+--------------------- 3 | 1 | 2 | 33.3 | 200.0 Revenue trend with 7-day moving average:\nSELECT date, revenue, orders, ROUND(AVG(revenue) OVER ( ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW ), 2) AS revenue_7d_avg, ROUND(AVG(orders) OVER ( ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW ), 0) AS orders_7d_avg FROM daily_revenue ORDER BY date; Expected output:\ndate | revenue | orders | revenue_7d_avg | orders_7d_avg ------------+-----------+--------+----------------+-------------- 2025-12-01 | 12450.00 | 85 | 12450.00 | 85 2025-12-02 | 14200.50 | 102 | 13325.25 | 94 2025-12-03 | 11890.25 | 78 | 12846.92 | 88 2025-12-04 | 15600.00 | 112 | 13535.19 | 94 2025-12-05 | 13100.75 | 91 | 13448.30 | 94 2025-12-06 | 9800.00 | 65 | 12840.25 | 89 2025-12-07 | 8200.50 | 58 | 12177.43 | 84 2025-12-08 | 13900.25 | 95 | 12384.61 | 86 2025-12-09 | 16200.00 | 118 | 12670.25 | 88 2025-12-10 | 14800.50 | 105 | 13086.00 | 92 Device and country breakdown:\nSELECT device_type, country, COUNT(*) AS events, COUNT(DISTINCT user_id) AS unique_users, COUNT(DISTINCT session_id) AS sessions FROM analytics_events WHERE occurred_at \u003e= '2025-12-15' AND occurred_at \u003c '2025-12-16' GROUP BY device_type, country ORDER BY events DESC; Expected output:\ndevice_type | country | events | unique_users | sessions -------------+---------+--------+--------------+--------- desktop | US | 4 | 2 | 2 mobile | GB | 2 | 1 | 1 tablet | DE | 2 | 1 | 1 3. AI/ML RAG Pipeline (Vector Search) A retrieval-augmented generation (RAG) system that stores document embeddings alongside metadata and performs semantic search to provide context for LLM responses.\nDescription RAG applications need to store text chunks with their vector embeddings, perform fast approximate nearest-neighbor (ANN) searches, and return the most relevant passages along with metadata. ThunderDB’s native vector support eliminates the need for a separate vector database.\nSchema -- Knowledge base documents CREATE TABLE kb_documents ( id BIGINT PRIMARY KEY, title VARCHAR(500) NOT NULL, source_url VARCHAR(1000), doc_type VARCHAR(50), created_at TIMESTAMPTZ DEFAULT now() ); -- Document chunks with embeddings CREATE TABLE kb_chunks ( id BIGINT PRIMARY KEY, doc_id BIGINT NOT NULL REFERENCES kb_documents(id), chunk_index INT32 NOT NULL, content TEXT NOT NULL, token_count INT32, embedding VECTOR(1536), metadata JSONB ); -- HNSW index for fast ANN search CREATE INDEX idx_chunks_embedding ON kb_chunks USING HNSW (embedding) WITH (m = 16, ef_construction = 200, distance_metric = 'cosine'); CREATE INDEX idx_chunks_doc ON kb_chunks (doc_id); -- Chat history for context CREATE TABLE chat_sessions ( id UUID PRIMARY KEY DEFAULT gen_random_uuid(), user_id BIGINT, created_at TIMESTAMPTZ DEFAULT now() ); CREATE TABLE chat_messages ( id BIGINT PRIMARY KEY, session_id UUID NOT NULL REFERENCES chat_sessions(id), role VARCHAR(20) NOT NULL, content TEXT NOT NULL, sources JSONB, created_at TIMESTAMPTZ DEFAULT now() ); Sample Data -- Documents INSERT INTO kb_documents (id, title, source_url, doc_type) VALUES (1, 'ThunderDB Architecture Overview', 'https://docs.thunderdb.io/architecture', 'documentation'), (2, 'Raft Consensus Protocol Explained', 'https://docs.thunderdb.io/architecture/raft', 'documentation'), (3, 'ThunderDB Query Optimization Guide', 'https://docs.thunderdb.io/developer/optimization', 'guide'); -- Chunks (embeddings truncated for readability -- actual embeddings are 1536-dim) INSERT INTO kb_chunks (id, doc_id, chunk_index, content, token_count, embedding, metadata) VALUES (1, 1, 0, 'ThunderDB uses a hybrid storage architecture with both row-oriented and columnar engines. The row engine is optimized for OLTP point lookups while the columnar engine excels at analytical scans.', 38, '[0.021, -0.034, 0.089, ...]'::VECTOR(1536), '{\"section\": \"storage\", \"heading\": \"Hybrid Storage\"}'), (2, 1, 1, 'Data is automatically sharded across cluster nodes using consistent hashing. Each shard is replicated to three nodes for fault tolerance.', 28, '[0.015, -0.067, 0.043, ...]'::VECTOR(1536), '{\"section\": \"sharding\", \"heading\": \"Data Distribution\"}'), (3, 2, 0, 'ThunderDB uses the Raft consensus protocol for leader election and log replication. Each Raft group manages a set of shards and ensures strong consistency.', 32, '[-0.012, 0.045, 0.078, ...]'::VECTOR(1536), '{\"section\": \"consensus\", \"heading\": \"Raft Overview\"}'), (4, 2, 1, 'When a leader fails, Raft triggers an election. Followers with the most up-to-date log are preferred. Election completes within 150-300ms in typical deployments.', 34, '[-0.008, 0.052, 0.061, ...]'::VECTOR(1536), '{\"section\": \"consensus\", \"heading\": \"Leader Election\"}'), (5, 3, 0, 'Use EXPLAIN ANALYZE to profile query execution. The output shows physical operators, estimated vs actual row counts, and time spent in each stage.', 28, '[0.033, -0.019, 0.071, ...]'::VECTOR(1536), '{\"section\": \"optimization\", \"heading\": \"Query Profiling\"}'); Queries Semantic search – find relevant chunks for a user question:\n-- User question: \"How does ThunderDB handle node failures?\" -- First, generate the embedding for the question using your embedding model, -- then search: SET hnsw.ef_search = 128; SELECT c.id AS chunk_id, d.title AS document, c.content, c.metadata-\u003e\u003e'heading' AS section, 1 - (c.embedding \u003c=\u003e $1) AS similarity FROM kb_chunks c JOIN kb_documents d ON c.doc_id = d.id ORDER BY c.embedding \u003c=\u003e $1 LIMIT 5; Expected output (similarity scores depend on actual embeddings):\nchunk_id | document | content | section | similarity ----------+-----------------------------------+------------------------------------------------------------+------------------+----------- 4 | Raft Consensus Protocol Explained | When a leader fails, Raft triggers an election... | Leader Election | 0.9234 3 | Raft Consensus Protocol Explained | ThunderDB uses the Raft consensus protocol... | Raft Overview | 0.8876 2 | ThunderDB Architecture Overview | Data is automatically sharded across cluster nodes... | Data Distribution| 0.8543 1 | ThunderDB Architecture Overview | ThunderDB uses a hybrid storage architecture... | Hybrid Storage | 0.7891 5 | ThunderDB Query Optimization Guide| Use EXPLAIN ANALYZE to profile query execution... | Query Profiling | 0.5123 Filtered semantic search (search only documentation):\nSELECT c.id AS chunk_id, c.content, 1 - (c.embedding \u003c=\u003e $1) AS similarity FROM kb_chunks c JOIN kb_documents d ON c.doc_id = d.id WHERE d.doc_type = 'documentation' ORDER BY c.embedding \u003c=\u003e $1 LIMIT 3; Store chat history with sources:\n-- Create a session INSERT INTO chat_sessions (id, user_id) VALUES ('550e8400-e29b-41d4-a716-446655440000', 1001); -- Store user message INSERT INTO chat_messages (id, session_id, role, content) VALUES (1, '550e8400-e29b-41d4-a716-446655440000', 'user', 'How does ThunderDB handle node failures?'); -- Store assistant response with source references INSERT INTO chat_messages (id, session_id, role, content, sources) VALUES (2, '550e8400-e29b-41d4-a716-446655440000', 'assistant', 'ThunderDB handles node failures through the Raft consensus protocol. When a leader node fails, Raft automatically triggers a leader election among the remaining nodes. Followers with the most up-to-date log are preferred as candidates. In typical deployments, a new leader is elected within 150-300ms, minimizing downtime.', '[{\"chunk_id\": 4, \"document\": \"Raft Consensus Protocol Explained\", \"similarity\": 0.9234}, {\"chunk_id\": 3, \"document\": \"Raft Consensus Protocol Explained\", \"similarity\": 0.8876}]'); -- Retrieve conversation history SELECT role, content, sources FROM chat_messages WHERE session_id = '550e8400-e29b-41d4-a716-446655440000' ORDER BY created_at; Expected output:\nrole | content | sources -----------+----------------------------------------------------------------------+---------------------------------------------------- user | How does ThunderDB handle node failures? | null assistant | ThunderDB handles node failures through the Raft consensus protocol. | [{\"chunk_id\": 4, \"document\": \"Raft Consensus ...}] | When a leader node fails, Raft automatically triggers... | 4. Multi-Database Federation (FDW) Joining data from PostgreSQL, MySQL, and MongoDB in a single ThunderDB query without ETL pipelines.\nDescription Many organizations have data spread across multiple database systems. ThunderDB’s foreign data wrappers let you query and join data from PostgreSQL, MySQL, MongoDB, and S3 as if it were local. ThunderDB pushes predicates down to remote systems to minimize data transfer.\nSchema -- Connect to external PostgreSQL (user accounts) CREATE SERVER pg_accounts TYPE 'postgresql' OPTIONS ( host '10.0.1.50', port '5432', dbname 'accounts', user 'readonly', password 'secret' ); CREATE FOREIGN TABLE remote_users ( id BIGINT, name VARCHAR(255), email VARCHAR(255), plan VARCHAR(20), created_at TIMESTAMPTZ ) SERVER pg_accounts OPTIONS (schema 'public', table 'users'); -- Connect to external MySQL (legacy orders) CREATE SERVER mysql_orders TYPE 'mysql' OPTIONS ( host '10.0.2.50', port '3306', dbname 'legacy_shop', user 'reader', password 'secret' ); CREATE FOREIGN TABLE legacy_orders ( order_id INT32, customer_email VARCHAR(255), total DECIMAL(10,2), status VARCHAR(20), order_date DATE ) SERVER mysql_orders OPTIONS (table 'orders'); -- Connect to external MongoDB (activity logs) CREATE SERVER mongo_activity TYPE 'mongodb' OPTIONS ( connection_string 'mongodb://10.0.3.50:27017/activity', user 'reader', password 'secret' ); CREATE FOREIGN TABLE activity_logs ( _id VARCHAR(24), user_email VARCHAR(255), action VARCHAR(50), details JSONB, timestamp TIMESTAMPTZ ) SERVER mongo_activity OPTIONS (collection 'user_actions'); -- Local ThunderDB table (enrichment data) CREATE TABLE user_segments ( user_email VARCHAR(255) PRIMARY KEY, segment VARCHAR(50) NOT NULL, score FLOAT64 NOT NULL, updated_at TIMESTAMPTZ DEFAULT now() ); Sample Data The foreign tables reference data in their respective external systems. The local table has:\nINSERT INTO user_segments (user_email, segment, score) VALUES ('alice@example.com', 'high_value', 95.2), ('bob@example.com', 'at_risk', 32.1), ('carol@example.com', 'growing', 67.8), ('dave@example.com', 'new', 15.5); Queries Cross-database customer 360 view:\nSELECT u.name, u.email, u.plan, s.segment, s.score AS engagement_score, COUNT(DISTINCT o.order_id) AS total_orders, COALESCE(SUM(o.total), 0) AS lifetime_value, COUNT(DISTINCT a._id) AS activity_count, MAX(a.timestamp) AS last_activity FROM remote_users u LEFT JOIN legacy_orders o ON u.email = o.customer_email LEFT JOIN activity_logs a ON u.email = a.user_email LEFT JOIN user_segments s ON u.email = s.user_email GROUP BY u.name, u.email, u.plan, s.segment, s.score ORDER BY lifetime_value DESC; Expected output:\nname | email | plan | segment | engagement_score | total_orders | lifetime_value | activity_count | last_activity ---------------+--------------------+----------+------------+------------------+--------------+----------------+----------------+---------------------- Alice Johnson | alice@example.com | premium | high_value | 95.2 | 12 | 2845.50 | 89 | 2025-12-15 09:45:00 Carol White | carol@example.com | standard | growing | 67.8 | 5 | 723.25 | 34 | 2025-12-14 18:22:00 Bob Smith | bob@example.com | standard | at_risk | 32.1 | 2 | 129.98 | 5 | 2025-11-20 11:10:00 Dave Brown | dave@example.com | free | new | 15.5 | 0 | 0.00 | 2 | 2025-12-15 08:00:00 Find at-risk users with declining activity:\nWITH user_monthly_activity AS ( SELECT user_email, date_trunc('month', timestamp) AS month, COUNT(*) AS actions FROM activity_logs WHERE timestamp \u003e= now() - INTERVAL '3 months' GROUP BY user_email, date_trunc('month', timestamp) ) SELECT u.name, u.email, s.segment, s.score, curr.actions AS current_month_actions, prev.actions AS prev_month_actions, ROUND(100.0 * (curr.actions - prev.actions) / NULLIF(prev.actions, 0), 1) AS activity_change_pct FROM remote_users u JOIN user_segments s ON u.email = s.user_email LEFT JOIN user_monthly_activity curr ON u.email = curr.user_email AND curr.month = date_trunc('month', now()) LEFT JOIN user_monthly_activity prev ON u.email = prev.user_email AND prev.month = date_trunc('month', now() - INTERVAL '1 month') WHERE s.segment = 'at_risk' OR (curr.actions \u003c prev.actions * 0.5) ORDER BY s.score ASC; 5. Real-Time Sync (CDC) Streaming changes from a production PostgreSQL database into ThunderDB for real-time analytics, search, and enrichment.\nDescription Change Data Capture (CDC) lets you subscribe to row-level changes on ThunderDB tables and consume them as a structured event stream. This example shows how to set up a pipeline that mirrors production data changes into an analytics-optimized representation and triggers downstream actions.\nSchema -- Source table (receives real-time changes) CREATE TABLE orders ( id BIGINT PRIMARY KEY, customer_id BIGINT NOT NULL, product_id BIGINT NOT NULL, quantity INT32 NOT NULL, total DECIMAL(10,2) NOT NULL, status VARCHAR(20) NOT NULL DEFAULT 'pending', created_at TIMESTAMPTZ DEFAULT now(), updated_at TIMESTAMPTZ DEFAULT now() ); -- Analytics target (columnar for fast aggregation) CREATE TABLE orders_analytics ( order_id BIGINT PRIMARY KEY, customer_id BIGINT NOT NULL, product_id BIGINT NOT NULL, quantity INT32 NOT NULL, total DECIMAL(10,2) NOT NULL, status VARCHAR(20) NOT NULL, day DATE NOT NULL, hour INT32 NOT NULL, is_high_value BOOLEAN NOT NULL ) ENGINE = COLUMNAR; Setting Up CDC Subscriptions Via REST API – subscribe to order changes:\n# Create a webhook subscription for order inserts and updates curl -s http://localhost:8088/api/v1/subscriptions \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"orders_to_analytics\", \"table\": \"orders\", \"events\": [\"insert\", \"update\"], \"delivery\": \"webhook\", \"endpoint\": \"https://analytics-worker.internal/hooks/order-events\", \"include_old_values\": true, \"batch_size\": 50, \"batch_timeout_ms\": 2000, \"retry_policy\": { \"max_retries\": 10, \"backoff_ms\": 500, \"backoff_multiplier\": 2.0 } }' | jq . Via WebSocket – consume events in real time:\nwscat -c ws://localhost:8088/ws/events { \"type\": \"subscribe\", \"id\": \"orders_stream\", \"table\": \"orders\", \"events\": [\"insert\", \"update\", \"delete\"], \"filter\": \"total \u003e 0\" } Simulating Changes -- New orders arrive INSERT INTO orders (id, customer_id, product_id, quantity, total, status) VALUES (2001, 101, 42, 2, 299.98, 'pending'), (2002, 102, 15, 1, 45.00, 'pending'), (2003, 103, 42, 5, 749.95, 'pending'); -- Order status updates UPDATE orders SET status = 'confirmed', updated_at = now() WHERE id = 2001; UPDATE orders SET status = 'shipped', updated_at = now() WHERE id = 2001; UPDATE orders SET status = 'cancelled', updated_at = now() WHERE id = 2002; CDC Event Payloads Insert event received via WebSocket:\n{ \"type\": \"event\", \"id\": \"orders_stream\", \"table\": \"orders\", \"operation\": \"insert\", \"row\": { \"id\": 2001, \"customer_id\": 101, \"product_id\": 42, \"quantity\": 2, \"total\": 299.98, \"status\": \"pending\", \"created_at\": \"2025-12-15T10:30:00Z\", \"updated_at\": \"2025-12-15T10:30:00Z\" }, \"lsn\": \"0/2A000010\", \"timestamp\": \"2025-12-15T10:30:00.001Z\" } Update event with old values:\n{ \"type\": \"event\", \"id\": \"orders_stream\", \"table\": \"orders\", \"operation\": \"update\", \"old_row\": { \"id\": 2001, \"status\": \"pending\", \"updated_at\": \"2025-12-15T10:30:00Z\" }, \"new_row\": { \"id\": 2001, \"status\": \"confirmed\", \"updated_at\": \"2025-12-15T10:31:00Z\" }, \"changed_columns\": [\"status\", \"updated_at\"], \"lsn\": \"0/2A000020\", \"timestamp\": \"2025-12-15T10:31:00.001Z\" } Analytics Query on Synced Data -- Transform and insert into analytics table INSERT INTO orders_analytics (order_id, customer_id, product_id, quantity, total, status, day, hour, is_high_value) SELECT id, customer_id, product_id, quantity, total, status, created_at::DATE AS day, EXTRACT(HOUR FROM created_at)::INT32 AS hour, total \u003e 200.00 AS is_high_value FROM orders; -- Real-time dashboard query SELECT day, COUNT(*) AS total_orders, COUNT(*) FILTER (WHERE status = 'confirmed') AS confirmed, COUNT(*) FILTER (WHERE status = 'shipped') AS shipped, COUNT(*) FILTER (WHERE status = 'cancelled') AS cancelled, SUM(total) AS total_revenue, SUM(total) FILTER (WHERE is_high_value) AS high_value_revenue FROM orders_analytics WHERE day = CURRENT_DATE GROUP BY day; Expected output:\nday | total_orders | confirmed | shipped | cancelled | total_revenue | high_value_revenue ------------+--------------+-----------+---------+-----------+---------------+------------------- 2025-12-15 | 3 | 1 | 1 | 1 | 1094.93 | 1049.93 6. Caching Layer (RESP Protocol) Using ThunderDB as a Redis-compatible cache that also supports SQL queries over cached data.\nDescription ThunderDB’s Redis protocol support lets you use it as a drop-in replacement for Redis in caching scenarios. The unique advantage is that data written via Redis commands can also be queried via SQL, enabling analytics over cached data and eliminating cache-database synchronization issues.\nSchema ThunderDB automatically maps Redis data structures to internal tables. You can also create explicit tables and access them through both SQL and Redis protocols.\n-- Explicit table for session data (accessible via both SQL and RESP) CREATE TABLE sessions ( key VARCHAR(255) PRIMARY KEY, user_id BIGINT NOT NULL, user_name VARCHAR(255), user_email VARCHAR(255), role VARCHAR(50), created_at TIMESTAMPTZ DEFAULT now(), expires_at TIMESTAMPTZ NOT NULL ); -- Cache table for frequently accessed products CREATE TABLE product_cache ( key VARCHAR(255) PRIMARY KEY, name VARCHAR(255), price DECIMAL(10,2), stock INT32, category VARCHAR(100), cached_at TIMESTAMPTZ DEFAULT now(), ttl INT32 ); Redis Operations Session management via Redis:\nimport redis import json r = redis.Redis(host='localhost', port=6379, password='secret', decode_responses=True) # Store a session (expires in 1 hour) session_data = { \"user_id\": 1001, \"user_name\": \"Alice Johnson\", \"user_email\": \"alice@example.com\", \"role\": \"admin\" } r.setex(\"session:abc123\", 3600, json.dumps(session_data)) r.setex(\"session:def456\", 3600, json.dumps({ \"user_id\": 1002, \"user_name\": \"Bob Smith\", \"user_email\": \"bob@example.com\", \"role\": \"viewer\" })) r.setex(\"session:ghi789\", 3600, json.dumps({ \"user_id\": 1003, \"user_name\": \"Carol White\", \"user_email\": \"carol@example.com\", \"role\": \"editor\" })) # Read a session session = json.loads(r.get(\"session:abc123\")) print(f\"User: {session['user_name']} ({session['role']})\") # Product caching products = { \"product:101\": {\"name\": \"Wireless Mouse\", \"price\": 29.99, \"stock\": 500, \"category\": \"electronics\"}, \"product:102\": {\"name\": \"Mechanical Keyboard\", \"price\": 149.99, \"stock\": 200, \"category\": \"electronics\"}, \"product:103\": {\"name\": \"Python Cookbook\", \"price\": 45.00, \"stock\": 1000, \"category\": \"books\"}, } pipe = r.pipeline() for key, data in products.items(): pipe.hset(key, mapping=data) pipe.expire(key, 900) # 15-minute cache TTL pipe.execute() # Rate limiting user_key = \"ratelimit:user:1001:api\" current = r.incr(user_key) if current == 1: r.expire(user_key, 60) # Reset counter every 60 seconds if current \u003e 100: print(\"Rate limited!\") else: print(f\"Request {current}/100\") # Leaderboard r.zadd(\"leaderboard:monthly\", {\"alice\": 2500, \"bob\": 1800, \"carol\": 3200, \"dave\": 950}) top_3 = r.zrevrange(\"leaderboard:monthly\", 0, 2, withscores=True) for rank, (player, score) in enumerate(top_3, 1): print(f\"#{rank} {player}: {score}\") SQL Queries Over Cached Data The unique power of ThunderDB: query data written via Redis using SQL.\n-- Find all active sessions SELECT key, user_name, role, created_at FROM thunder_cache.string_keys WHERE key LIKE 'session:%' AND expires_at \u003e now() ORDER BY created_at DESC; Expected output:\nkey | user_name | role | created_at -----------------+---------------+--------+------------------------- session:ghi789 | Carol White | editor | 2025-12-15 10:30:02+00 session:def456 | Bob Smith | viewer | 2025-12-15 10:30:01+00 session:abc123 | Alice Johnson | admin | 2025-12-15 10:30:00+00 -- Analytics: sessions by role SELECT json_extract(value, '$.role') AS role, COUNT(*) AS session_count FROM thunder_cache.string_keys WHERE key LIKE 'session:%' AND expires_at \u003e now() GROUP BY json_extract(value, '$.role'); Expected output:\nrole | session_count --------+-------------- admin | 1 editor | 1 viewer | 1 -- Product cache analytics: total value by category SELECT category, COUNT(*) AS product_count, SUM(price::DECIMAL) AS total_value, SUM(stock::INT32) AS total_stock FROM thunder_cache.hash_keys WHERE key LIKE 'product:%' GROUP BY category; Expected output:\ncategory | product_count | total_value | total_stock -------------+---------------+-------------+------------ electronics | 2 | 179.98 | 700 books | 1 | 45.00 | 1000 -- Leaderboard query via SQL (sorted set data) SELECT member, score FROM thunder_cache.sorted_set_members WHERE key = 'leaderboard:monthly' ORDER BY score DESC LIMIT 5; Expected output:\nmember | score --------+------ carol | 3200 alice | 2500 bob | 1800 dave | 950 7. IoT Data Platform A time-series ingestion and analysis platform for sensor data from industrial IoT devices with real-time alerting.\nDescription IoT platforms need to ingest high volumes of time-series data, run continuous aggregate queries for dashboards, and trigger alerts when sensor readings exceed thresholds. ThunderDB’s columnar engine with BRIN indexes handles time-series data efficiently, and CDC subscriptions power the alerting system.\nSchema -- Device registry CREATE TABLE devices ( device_id VARCHAR(50) PRIMARY KEY, device_type VARCHAR(50) NOT NULL, location VARCHAR(100) NOT NULL, zone VARCHAR(50) NOT NULL, installed_at TIMESTAMPTZ NOT NULL, status VARCHAR(20) DEFAULT 'active' ); -- Sensor readings (columnar, time-series optimized) CREATE TABLE sensor_readings ( reading_id BIGINT PRIMARY KEY, device_id VARCHAR(50) NOT NULL, metric VARCHAR(50) NOT NULL, value FLOAT64 NOT NULL, unit VARCHAR(20) NOT NULL, quality VARCHAR(10) DEFAULT 'good', recorded_at TIMESTAMPTZ NOT NULL ) ENGINE = COLUMNAR; -- BRIN index for time-range queries (very compact) CREATE INDEX idx_readings_time ON sensor_readings USING BRIN (recorded_at) WITH (pages_per_range = 16); CREATE INDEX idx_readings_device ON sensor_readings (device_id); CREATE INDEX idx_readings_metric ON sensor_readings (metric); -- Alert rules CREATE TABLE alert_rules ( id BIGINT PRIMARY KEY, name VARCHAR(255) NOT NULL, device_id VARCHAR(50), metric VARCHAR(50) NOT NULL, condition VARCHAR(20) NOT NULL, threshold FLOAT64 NOT NULL, severity VARCHAR(20) NOT NULL, enabled BOOLEAN DEFAULT true ); -- Alert history CREATE TABLE alert_history ( id BIGINT PRIMARY KEY, rule_id BIGINT NOT NULL REFERENCES alert_rules(id), device_id VARCHAR(50) NOT NULL, metric VARCHAR(50) NOT NULL, value FLOAT64 NOT NULL, threshold FLOAT64 NOT NULL, severity VARCHAR(20) NOT NULL, message TEXT, triggered_at TIMESTAMPTZ DEFAULT now(), resolved_at TIMESTAMPTZ ); Sample Data -- Devices INSERT INTO devices (device_id, device_type, location, zone, installed_at) VALUES ('sensor-001', 'temperature', 'Building A, Floor 1', 'zone-north', '2025-01-15'), ('sensor-002', 'temperature', 'Building A, Floor 2', 'zone-north', '2025-01-15'), ('sensor-003', 'humidity', 'Building A, Floor 1', 'zone-north', '2025-01-15'), ('sensor-004', 'temperature', 'Building B, Floor 1', 'zone-south', '2025-03-01'), ('sensor-005', 'pressure', 'Building B, Floor 1', 'zone-south', '2025-03-01'), ('sensor-006', 'vibration', 'Building B, Machine Room', 'zone-south', '2025-06-01'); -- Sensor readings (simulated time-series data) INSERT INTO sensor_readings (reading_id, device_id, metric, value, unit, quality, recorded_at) VALUES (1, 'sensor-001', 'temperature', 22.5, 'celsius', 'good', '2025-12-15 10:00:00+00'), (2, 'sensor-001', 'temperature', 22.7, 'celsius', 'good', '2025-12-15 10:01:00+00'), (3, 'sensor-001', 'temperature', 23.1, 'celsius', 'good', '2025-12-15 10:02:00+00'), (4, 'sensor-001', 'temperature', 28.5, 'celsius', 'good', '2025-12-15 10:03:00+00'), (5, 'sensor-001', 'temperature', 31.2, 'celsius', 'good', '2025-12-15 10:04:00+00'), (6, 'sensor-002', 'temperature', 21.0, 'celsius', 'good', '2025-12-15 10:00:00+00'), (7, 'sensor-002', 'temperature', 21.2, 'celsius', 'good', '2025-12-15 10:01:00+00'), (8, 'sensor-002', 'temperature', 21.1, 'celsius', 'good', '2025-12-15 10:02:00+00'), (9, 'sensor-003', 'humidity', 45.0, 'percent', 'good', '2025-12-15 10:00:00+00'), (10, 'sensor-003', 'humidity', 46.5, 'percent', 'good', '2025-12-15 10:01:00+00'), (11, 'sensor-003', 'humidity', 48.2, 'percent', 'good', '2025-12-15 10:02:00+00'), (12, 'sensor-004', 'temperature', 19.8, 'celsius', 'good', '2025-12-15 10:00:00+00'), (13, 'sensor-005', 'pressure', 1013.25, 'hpa', 'good', '2025-12-15 10:00:00+00'), (14, 'sensor-005', 'pressure', 1013.10, 'hpa', 'good', '2025-12-15 10:01:00+00'), (15, 'sensor-006', 'vibration', 0.5, 'mm/s', 'good', '2025-12-15 10:00:00+00'), (16, 'sensor-006', 'vibration', 2.8, 'mm/s', 'degraded', '2025-12-15 10:01:00+00'), (17, 'sensor-006', 'vibration', 5.2, 'mm/s', 'degraded', '2025-12-15 10:02:00+00'); -- Alert rules INSERT INTO alert_rules (id, name, device_id, metric, condition, threshold, severity) VALUES (1, 'High temperature', NULL, 'temperature', 'greater_than', 30.0, 'warning'), (2, 'Critical temperature', NULL, 'temperature', 'greater_than', 40.0, 'critical'), (3, 'High vibration', 'sensor-006', 'vibration', 'greater_than', 3.0, 'warning'), (4, 'Low humidity', NULL, 'humidity', 'less_than', 30.0, 'info'); Queries Real-time dashboard: latest reading per device:\nSELECT DISTINCT ON (device_id, metric) d.device_id, d.device_type, d.location, r.metric, r.value, r.unit, r.quality, r.recorded_at FROM sensor_readings r JOIN devices d ON r.device_id = d.device_id WHERE d.status = 'active' ORDER BY device_id, metric, recorded_at DESC; Expected output:\ndevice_id | device_type | location | metric | value | unit | quality | recorded_at -------------+-------------+---------------------------+-------------+---------+---------+----------+------------------------- sensor-001 | temperature | Building A, Floor 1 | temperature | 31.2 | celsius | good | 2025-12-15 10:04:00+00 sensor-002 | temperature | Building A, Floor 2 | temperature | 21.1 | celsius | good | 2025-12-15 10:02:00+00 sensor-003 | humidity | Building A, Floor 1 | humidity | 48.2 | percent | good | 2025-12-15 10:02:00+00 sensor-004 | temperature | Building B, Floor 1 | temperature | 19.8 | celsius | good | 2025-12-15 10:00:00+00 sensor-005 | pressure | Building B, Floor 1 | pressure | 1013.10 | hpa | good | 2025-12-15 10:01:00+00 sensor-006 | vibration | Building B, Machine Room | vibration | 5.2 | mm/s | degraded | 2025-12-15 10:02:00+00 Time-series aggregation: 5-minute averages:\nSELECT device_id, metric, date_trunc('minute', recorded_at) - (EXTRACT(MINUTE FROM recorded_at)::INT32 % 5) * INTERVAL '1 minute' AS bucket, ROUND(AVG(value)::DECIMAL, 2) AS avg_value, ROUND(MIN(value)::DECIMAL, 2) AS min_value, ROUND(MAX(value)::DECIMAL, 2) AS max_value, COUNT(*) AS sample_count FROM sensor_readings WHERE device_id = 'sensor-001' AND recorded_at \u003e= '2025-12-15 10:00:00' AND recorded_at \u003c '2025-12-15 10:10:00' GROUP BY device_id, metric, bucket ORDER BY bucket; Expected output:\ndevice_id | metric | bucket | avg_value | min_value | max_value | sample_count ------------+-------------+--------------------------+-----------+-----------+-----------+------------- sensor-001 | temperature | 2025-12-15 10:00:00+00 | 25.60 | 22.50 | 31.20 | 5 Anomaly detection: readings that deviate significantly from recent average:\nWITH recent_stats AS ( SELECT device_id, metric, AVG(value) AS avg_value, STDDEV(value) AS stddev_value FROM sensor_readings WHERE recorded_at \u003e= now() - INTERVAL '1 hour' GROUP BY device_id, metric ) SELECT r.device_id, d.location, r.metric, r.value, r.unit, ROUND((r.value - s.avg_value) / NULLIF(s.stddev_value, 0), 2) AS z_score, r.recorded_at FROM sensor_readings r JOIN recent_stats s ON r.device_id = s.device_id AND r.metric = s.metric JOIN devices d ON r.device_id = d.device_id WHERE ABS(r.value - s.avg_value) \u003e 2 * s.stddev_value AND r.recorded_at \u003e= now() - INTERVAL '10 minutes' ORDER BY ABS((r.value - s.avg_value) / NULLIF(s.stddev_value, 0)) DESC; Expected output:\ndevice_id | location | metric | value | unit | z_score | recorded_at ------------+--------------------------+-------------+-------+-------+---------+------------------------- sensor-001 | Building A, Floor 1 | temperature | 31.20 | celsius | 2.35 | 2025-12-15 10:04:00+00 sensor-006 | Building B, Machine Room | vibration | 5.20 | mm/s | 2.12 | 2025-12-15 10:02:00+00 Trigger alerts for threshold violations:\n-- Find readings that violate alert rules INSERT INTO alert_history (id, rule_id, device_id, metric, value, threshold, severity, message) SELECT nextval('alert_history_id_seq'), ar.id, r.device_id, r.metric, r.value, ar.threshold, ar.severity, CONCAT( ar.name, ': ', r.device_id, ' reading ', r.value, ' ', r.unit, ' exceeds threshold ', ar.threshold ) FROM sensor_readings r JOIN alert_rules ar ON r.metric = ar.metric AND (ar.device_id IS NULL OR ar.device_id = r.device_id) AND ar.enabled = true WHERE r.recorded_at \u003e= now() - INTERVAL '5 minutes' AND ( (ar.condition = 'greater_than' AND r.value \u003e ar.threshold) OR (ar.condition = 'less_than' AND r.value \u003c ar.threshold) ); -- View recent alerts SELECT ah.severity, ah.device_id, d.location, ah.metric, ah.value, ah.threshold, ah.message, ah.triggered_at FROM alert_history ah JOIN devices d ON ah.device_id = d.device_id WHERE ah.triggered_at \u003e= now() - INTERVAL '1 hour' AND ah.resolved_at IS NULL ORDER BY CASE ah.severity WHEN 'critical' THEN 1 WHEN 'warning' THEN 2 WHEN 'info' THEN 3 END, ah.triggered_at DESC; Expected output:\nseverity | device_id | location | metric | value | threshold | message | triggered_at ----------+------------+--------------------------+-------------+-------+-----------+------------------------------------------------------------------+------------------------- warning | sensor-001 | Building A, Floor 1 | temperature | 31.20 | 30.0 | High temperature: sensor-001 reading 31.2 celsius exceeds 30.0 | 2025-12-15 10:04:00+00 warning | sensor-006 | Building B, Machine Room | vibration | 5.20 | 3.0 | High vibration: sensor-006 reading 5.2 mm/s exceeds threshold 3.0| 2025-12-15 10:02:00+00 Set up CDC for real-time alerting:\n# Subscribe to sensor_readings for real-time alert evaluation curl -s http://localhost:8088/api/v1/subscriptions \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"sensor_alert_pipeline\", \"table\": \"sensor_readings\", \"events\": [\"insert\"], \"delivery\": \"webhook\", \"endpoint\": \"https://alerting.internal/hooks/evaluate\", \"filter\": \"quality != '\\''bad'\\''\", \"batch_size\": 10, \"batch_timeout_ms\": 1000 }' | jq . Zone-level summary for facility management:\nSELECT d.zone, d.device_type, COUNT(DISTINCT d.device_id) AS device_count, ROUND(AVG(r.value)::DECIMAL, 2) AS avg_reading, ROUND(MIN(r.value)::DECIMAL, 2) AS min_reading, ROUND(MAX(r.value)::DECIMAL, 2) AS max_reading, COUNT(*) AS total_readings, COUNT(*) FILTER (WHERE r.quality = 'degraded') AS degraded_readings FROM devices d JOIN sensor_readings r ON d.device_id = r.device_id WHERE r.recorded_at \u003e= now() - INTERVAL '1 hour' GROUP BY d.zone, d.device_type ORDER BY d.zone, d.device_type; Expected output:\nzone | device_type | device_count | avg_reading | min_reading | max_reading | total_readings | degraded_readings ------------+-------------+--------------+-------------+-------------+-------------+----------------+------------------ zone-north | humidity | 1 | 46.57 | 45.00 | 48.20 | 3 | 0 zone-north | temperature | 2 | 23.64 | 21.00 | 31.20 | 8 | 0 zone-south | pressure | 1 | 1013.18 | 1013.10 | 1013.25 | 2 | 0 zone-south | temperature | 1 | 19.80 | 19.80 | 19.80 | 1 | 0 zone-south | vibration | 1 | 2.83 | 0.50 | 5.20 | 3 | 2 ","categories":"","description":"End-to-end application examples demonstrating ThunderDB for e-commerce, analytics, RAG pipelines, data federation, CDC, caching, and IoT.","excerpt":"End-to-end application examples demonstrating ThunderDB for …","ref":"/docs/docs/developer/examples/","tags":"","title":"Examples \u0026 Use Cases"},{"body":"Release Process This guide documents the end-to-end release process for ThunderDB. It covers version numbering conventions, the release checklist, building release artifacts, changelog management, and post-release verification.\nVersion Numbering ThunderDB follows Semantic Versioning 2.0.0 (SemVer):\nMAJOR.MINOR.PATCH[-PRERELEASE][+BUILD] Component When to Increment Example MAJOR Breaking changes to the public API, wire protocol incompatibilities, data format changes requiring migration 1.0.0 -\u003e 2.0.0 MINOR New features, new SQL functions, new API endpoints, new configuration options (backward compatible) 1.2.0 -\u003e 1.3.0 PATCH Bug fixes, performance improvements, documentation updates (backward compatible, no new features) 1.2.3 -\u003e 1.2.4 Pre-Release Versions Pre-release versions are used for testing before a stable release:\nTag Purpose Example -alpha.N Early development, API may change significantly 1.3.0-alpha.1 -beta.N Feature-complete, testing and stabilization 1.3.0-beta.1 -rc.N Release candidate, final validation 1.3.0-rc.1 Compatibility Guarantees Wire protocol compatibility: PostgreSQL, MySQL, and Redis wire protocol compatibility is maintained across MINOR versions. Breaking protocol changes require a MAJOR version bump. Data format compatibility: On-disk data format changes that require migration are only allowed in MAJOR versions. Minor versions must be able to read data written by previous minor versions of the same major version. Configuration compatibility: New configuration options may be added in MINOR versions with sensible defaults. Removing or renaming configuration options requires a MAJOR version bump with a migration guide. Client library compatibility: The thunder-client crate follows the same versioning as the server. Client version X.Y.* is compatible with server version X.Y.*. Release Checklist The following checklist must be completed for every release. Each step is detailed in the sections below.\nPre-Release All CI checks pass on the main branch All planned features for this release are merged All known release-blocking bugs are fixed Version numbers are updated in all Cargo.toml files CHANGELOG.md is updated with all changes since the last release Release notes are drafted Documentation is updated for new features and changes Upgrade/migration guide is written (for MAJOR versions) Performance benchmarks show no unexpected regressions Build and Test Release binary builds successfully: cargo build --release Full test suite passes against the release binary ACID compliance tests pass Chaos tests pass Load tests meet minimum performance thresholds Docker image builds successfully Docker image smoke test passes Debian package builds successfully (if applicable) Cross-platform builds succeed (Linux x86_64, Linux aarch64, macOS x86_64, macOS aarch64) Release Git tag is created and pushed Release artifacts are uploaded to GitHub Releases Docker image is pushed to container registry Debian package is published to package repository (if applicable) Crates are published to crates.io (if applicable) Release announcement is published Post-Release Download and verify release artifacts Smoke test release artifacts on a clean machine Verify Docker image works with docker run Monitor issue tracker for release-related bug reports Update version numbers on main to next development version Updating Version Numbers Version numbers must be updated in all Cargo.toml files in the workspace. Use a script or do it manually:\n# The version update script updates all Cargo.toml files consistently ./scripts/bump-version.sh 1.3.0 # Or manually update each Cargo.toml: # 1. Root Cargo.toml (workspace.package.version) # 2. Each crate's Cargo.toml (package.version) # 3. Inter-crate dependency versions Files to Update File Field Cargo.toml (root) workspace.package.version thunder-common/Cargo.toml package.version thunder-storage/Cargo.toml package.version, dependency versions thunder-txn/Cargo.toml package.version, dependency versions thunder-sql/Cargo.toml package.version, dependency versions thunder-query/Cargo.toml package.version, dependency versions thunder-cluster/Cargo.toml package.version, dependency versions thunder-protocol/Cargo.toml package.version, dependency versions thunder-vector/Cargo.toml package.version, dependency versions thunder-api/Cargo.toml package.version, dependency versions thunder-cdc/Cargo.toml package.version, dependency versions thunder-fdw/Cargo.toml package.version, dependency versions thunder-server/Cargo.toml package.version, dependency versions thunder-client/Cargo.toml package.version, dependency versions After updating, verify that the workspace builds:\ncargo build --release cargo test Building Release Binaries Standard Release Build cargo build --release This produces the thunder-server binary at target/release/thunder-server with the release profile settings:\nSetting Value Effect opt-level 3 Maximum optimization for best runtime performance lto \"thin\" Thin link-time optimization enables cross-crate inlining codegen-units 1 Single codegen unit allows maximum LLVM optimization panic \"abort\" Abort on panic produces smaller binaries with no unwinding overhead Cross-Platform Builds ThunderDB supports the following target platforms:\nPlatform Target Triple Build Command Linux x86_64 x86_64-unknown-linux-gnu cargo build --release --target x86_64-unknown-linux-gnu Linux aarch64 aarch64-unknown-linux-gnu cross build --release --target aarch64-unknown-linux-gnu macOS x86_64 x86_64-apple-darwin cargo build --release --target x86_64-apple-darwin macOS aarch64 aarch64-apple-darwin cargo build --release --target aarch64-apple-darwin For cross-compilation, use the cross tool:\n# Install cross cargo install cross # Build for Linux aarch64 from a Linux x86_64 or macOS host cross build --release --target aarch64-unknown-linux-gnu Static Linking (Linux) For maximum portability on Linux, build a statically linked binary using musl:\n# Add the musl target rustup target add x86_64-unknown-linux-musl # Build statically linked binary cargo build --release --target x86_64-unknown-linux-musl The resulting binary has no dynamic library dependencies and runs on any Linux distribution.\nRelease Binary Verification After building, verify the release binary:\n# Check the binary exists and is the expected type file target/release/thunder-server # Check the binary size (should be 30-80MB depending on features) ls -lh target/release/thunder-server # Verify the version string is correct ./target/release/thunder-server --version # Run a quick smoke test ./target/release/thunder-server --config config/test.toml \u0026 sleep 2 curl http://localhost:8080/api/v1/health kill %1 # Strip debug symbols for smaller production binary (optional) strip target/release/thunder-server Building Docker Images Production Docker Image # Build the production image docker build -t thunderdb:1.3.0 . # Also tag as latest docker tag thunderdb:1.3.0 thunderdb:latest The Dockerfile uses a multi-stage build for minimal image size:\n# Stage 1: Build FROM rust:1.75 AS builder WORKDIR /app COPY . . RUN cargo build --release # Stage 2: Runtime FROM debian:bookworm-slim RUN apt-get update \u0026\u0026 apt-get install -y \\ ca-certificates \\ libssl3 \\ \u0026\u0026 rm -rf /var/lib/apt/lists/* COPY --from=builder /app/target/release/thunder-server /usr/local/bin/ COPY config/prod.toml /etc/thunderdb/config.toml EXPOSE 5432 3306 6379 8080 50051 8081 8082 9090 ENTRYPOINT [\"thunder-server\"] CMD [\"--config\", \"/etc/thunderdb/config.toml\"] Docker Image Verification # Verify the image was built correctly docker images thunderdb:1.3.0 # Run a smoke test docker run -d --name thunder-test -p 5432:5432 -p 8080:8080 thunderdb:1.3.0 sleep 3 # Health check curl http://localhost:8080/api/v1/health # Connect with psql psql -h localhost -p 5432 -U admin -d thunderdb -c \"SELECT version();\" # Clean up docker stop thunder-test \u0026\u0026 docker rm thunder-test Pushing to Container Registry # Tag for registry docker tag thunderdb:1.3.0 ghcr.io/thunderdb/thunderdb:1.3.0 docker tag thunderdb:1.3.0 ghcr.io/thunderdb/thunderdb:latest # Push docker push ghcr.io/thunderdb/thunderdb:1.3.0 docker push ghcr.io/thunderdb/thunderdb:latest Multi-Architecture Docker Images For ARM64 support (Apple Silicon, AWS Graviton, etc.):\n# Create a multi-architecture builder docker buildx create --name thunder-builder --use # Build and push multi-arch image docker buildx build \\ --platform linux/amd64,linux/arm64 \\ -t ghcr.io/thunderdb/thunderdb:1.3.0 \\ -t ghcr.io/thunderdb/thunderdb:latest \\ --push . Building Debian Packages Using the Build Script ./scripts/build-deb.sh This script:\nBuilds the release binary Creates the Debian package directory structure Writes the control file with package metadata Includes the binary, default configuration, systemd service file, and man pages Runs dpkg-deb to produce the .deb file Package Contents The Debian package installs the following files:\nPath Content /usr/bin/thunder-server Server binary /etc/thunderdb/config.toml Default configuration file /lib/systemd/system/thunderdb.service systemd service unit /var/lib/thunderdb/ Data directory (created on install) /var/log/thunderdb/ Log directory (created on install) /usr/share/man/man1/thunder-server.1.gz Man page Package Metadata Package: thunderdb Version: 1.3.0 Architecture: amd64 Maintainer: ThunderDB Team \u003cteam@thunderdb.io\u003e Description: ThunderDB - Distributed HTAP Database A high-performance distributed database that unifies transactional and analytical workloads with multi-protocol support. Depends: libc6 (\u003e= 2.31), libssl3 Installing the Package # Install sudo dpkg -i thunderdb_1.3.0_amd64.deb # Start the service sudo systemctl start thunderdb sudo systemctl enable thunderdb # Check status sudo systemctl status thunderdb # View logs sudo journalctl -u thunderdb -f Verifying the Package # List package contents dpkg -c thunderdb_1.3.0_amd64.deb # Verify package metadata dpkg -I thunderdb_1.3.0_amd64.deb # Install and verify sudo dpkg -i thunderdb_1.3.0_amd64.deb thunder-server --version Changelog Management ThunderDB maintains a CHANGELOG.md file in the repository root following the Keep a Changelog format.\nChangelog Format # Changelog All notable changes to ThunderDB are documented in this file. The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.1.0/), and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html). ## [Unreleased] ### Added - Vector search support with HNSW and IVF indexes (#234) - GraphQL API endpoint (#256) ### Changed - Improved B+Tree prefix compression reduces index size by 15% (#245) ### Fixed - Fixed deadlock in concurrent DDL operations (#267) ## [1.2.0] - 2025-12-15 ### Added - MySQL wire protocol support (#189) - Change Data Capture (CDC) with Kafka output (#195) - WebSocket API for live query subscriptions (#201) ### Changed - Upgraded Tokio runtime to 1.35 (#210) - WAL group commit batch size is now configurable (#215) ### Fixed - Fixed memory leak in buffer pool eviction under high concurrency (#220) - Fixed incorrect NULL handling in outer joins (#225) ### Security - Fixed timing side-channel in password authentication (#230) ## [1.1.0] - 2025-09-01 ... Changelog Categories Category Description Added New features Changed Changes to existing functionality Deprecated Features that will be removed in a future version Removed Features removed in this version Fixed Bug fixes Security Security-related fixes Updating the Changelog When preparing a release:\nReview all merged pull requests since the last release:\ngit log v1.2.0..HEAD --oneline --merges Categorize each change into the appropriate changelog section.\nMove items from [Unreleased] to the new version section with the release date.\nInclude issue/PR numbers for each entry for traceability.\nGit Tagging Creating a Release Tag # Ensure you are on the main branch and it is up to date git checkout main git pull origin main # Verify all tests pass cargo test # Create an annotated tag git tag -a v1.3.0 -m \"ThunderDB v1.3.0 Highlights: - Vector search support with HNSW indexes - GraphQL API endpoint - 15% reduction in index size through improved prefix compression See CHANGELOG.md for the complete list of changes.\" # Push the tag git push origin v1.3.0 Tag Naming Convention Tags follow the format v{MAJOR}.{MINOR}.{PATCH}[-PRERELEASE]:\nv1.3.0 – Stable release v1.3.0-alpha.1 – Alpha pre-release v1.3.0-beta.1 – Beta pre-release v1.3.0-rc.1 – Release candidate Listing Tags # List all tags git tag -l # List tags matching a pattern git tag -l 'v1.3.*' # Show tag details git show v1.3.0 Release Notes Release notes are published on GitHub Releases and provide a user-friendly summary of the release.\nRelease Notes Structure # ThunderDB v1.3.0 **Release date:** 2026-01-15 ## Highlights - **Vector Search:** ThunderDB now supports vector similarity search with HNSW and IVF indexes, enabling AI/ML workloads directly in the database. - **GraphQL API:** A new GraphQL endpoint auto-generates a schema from your database tables, supporting queries, mutations, and subscriptions. - **Smaller Indexes:** Improved B+Tree prefix compression reduces index storage by approximately 15%. ## What's New ### Vector Search (#234) Store and search high-dimensional vectors directly in ThunderDB: ```sql CREATE TABLE embeddings ( id INT PRIMARY KEY, content TEXT, embedding VECTOR(1536) ); CREATE INDEX ON embeddings USING hnsw (embedding vector_cosine_ops); SELECT * FROM embeddings ORDER BY embedding \u003c=\u003e '[0.1, 0.2, ...]'::vector LIMIT 10; GraphQL API (#256) Access your data through a fully-featured GraphQL endpoint at /graphql:\nquery { users(where: { age: { gt: 21 } }, limit: 10) { id name email } } Breaking Changes None in this release.\nUpgrade Guide This is a backward-compatible release. Simply replace the binary and restart:\nsudo systemctl stop thunderdb sudo dpkg -i thunderdb_1.3.0_amd64.deb sudo systemctl start thunderdb Download Platform Architecture Download Linux x86_64 thunderdb-1.3.0-linux-amd64.tar.gz Linux aarch64 thunderdb-1.3.0-linux-arm64.tar.gz macOS x86_64 thunderdb-1.3.0-darwin-amd64.tar.gz macOS aarch64 thunderdb-1.3.0-darwin-arm64.tar.gz Docker multi-arch docker pull ghcr.io/thunderdb/thunderdb:1.3.0 Debian amd64 thunderdb_1.3.0_amd64.deb Checksums sha256 abc123... thunderdb-1.3.0-linux-amd64.tar.gz sha256 def456... thunderdb-1.3.0-linux-arm64.tar.gz sha256 ghi789... thunderdb-1.3.0-darwin-amd64.tar.gz sha256 jkl012... thunderdb-1.3.0-darwin-arm64.tar.gz sha256 mno345... thunderdb_1.3.0_amd64.deb Full Changelog See CHANGELOG.md for the complete list of changes.\n### Creating a GitHub Release ```bash # Create a GitHub release from the tag gh release create v1.3.0 \\ --title \"ThunderDB v1.3.0\" \\ --notes-file release-notes-1.3.0.md \\ target/release-artifacts/thunderdb-1.3.0-linux-amd64.tar.gz \\ target/release-artifacts/thunderdb-1.3.0-linux-arm64.tar.gz \\ target/release-artifacts/thunderdb-1.3.0-darwin-amd64.tar.gz \\ target/release-artifacts/thunderdb-1.3.0-darwin-arm64.tar.gz \\ target/release-artifacts/thunderdb_1.3.0_amd64.deb \\ target/release-artifacts/SHA256SUMS # For pre-release versions gh release create v1.3.0-beta.1 \\ --title \"ThunderDB v1.3.0-beta.1\" \\ --prerelease \\ --notes-file release-notes-1.3.0-beta.1.md \\ target/release-artifacts/* Publishing Crates If ThunderDB publishes individual crates to crates.io, they must be published in dependency order (leaf crates first):\n# 1. Publish the leaf crate first cargo publish -p thunder-common # 2. Publish crates that depend only on thunder-common cargo publish -p thunder-storage cargo publish -p thunder-sql cargo publish -p thunder-client # 3. Continue up the dependency graph cargo publish -p thunder-txn cargo publish -p thunder-cluster cargo publish -p thunder-cdc cargo publish -p thunder-vector cargo publish -p thunder-fdw # 4. Publish crates with many dependencies cargo publish -p thunder-query cargo publish -p thunder-protocol cargo publish -p thunder-api # 5. Publish the top-level binary last cargo publish -p thunder-server Pre-Publish Verification Before publishing to crates.io:\n# Dry run: verify the crate can be packaged cargo publish -p thunder-common --dry-run # Check what files will be included in the package cargo package -p thunder-common --list Important Notes Once published to crates.io, a version cannot be unpublished (only yanked). Ensure all Cargo.toml metadata is correct: license, repository, description, readme, keywords, categories. All public APIs should have documentation (/// doc comments). Run cargo doc --no-deps to verify documentation builds without warnings. Release Automation The release process is partially automated through GitHub Actions:\nRelease Workflow (.github/workflows/release.yml) Triggered when a tag matching v* is pushed:\nv* tag pushed | +-- Build release binaries (parallel matrix) | +-- Linux x86_64 | +-- Linux aarch64 | +-- macOS x86_64 | +-- macOS aarch64 | +-- Run full test suite against release binaries | +-- Build Docker image (multi-arch) | +-- Build Debian package | +-- Create GitHub Release with artifacts | +-- Push Docker image to registry | +-- Publish crates to crates.io (manual approval) Manual Steps Even with automation, some steps require manual action:\nVersion bump and changelog update must be done manually before tagging. Release notes should be reviewed and edited by a maintainer. crates.io publishing requires manual approval in the CI pipeline. Release announcement (blog post, social media, mailing list) is done manually. Post-Release Verification After a release is published, verify that all artifacts work correctly:\nBinary Verification # Download the release binary on a clean machine curl -LO https://github.com/thunderdb/thunderdb/releases/download/v1.3.0/thunderdb-1.3.0-linux-amd64.tar.gz # Verify checksum sha256sum -c SHA256SUMS # Extract and run tar xzf thunderdb-1.3.0-linux-amd64.tar.gz ./thunder-server --version ./thunder-server --config config/prod.toml \u0026 # Verify health curl http://localhost:8080/api/v1/health # Run basic queries psql -h localhost -p 5432 -U admin -d thunderdb -c \" CREATE TABLE test (id INT PRIMARY KEY, name TEXT); INSERT INTO test VALUES (1, 'hello'); SELECT * FROM test; DROP TABLE test; \" Docker Verification # Pull and run the released Docker image docker pull ghcr.io/thunderdb/thunderdb:1.3.0 docker run -d --name thunder-verify -p 5432:5432 ghcr.io/thunderdb/thunderdb:1.3.0 # Verify docker logs thunder-verify psql -h localhost -p 5432 -U admin -d thunderdb -c \"SELECT version();\" # Clean up docker stop thunder-verify \u0026\u0026 docker rm thunder-verify Debian Package Verification # Install on a clean Ubuntu/Debian system sudo dpkg -i thunderdb_1.3.0_amd64.deb # Verify service starts sudo systemctl start thunderdb sudo systemctl status thunderdb # Verify connectivity psql -h localhost -p 5432 -U admin -d thunderdb -c \"SELECT version();\" # Uninstall sudo dpkg -r thunderdb Upgrade Path Verification For MINOR and PATCH releases, verify the upgrade path:\n# Start the previous version with data docker run -d --name thunder-old -v thunder-data:/var/lib/thunderdb \\ ghcr.io/thunderdb/thunderdb:1.2.0 # Load test data psql -h localhost -p 5432 -U admin -d thunderdb -c \" CREATE TABLE upgrade_test (id INT PRIMARY KEY, data TEXT); INSERT INTO upgrade_test SELECT generate_series(1, 10000), 'data'; \" # Stop the old version docker stop thunder-old \u0026\u0026 docker rm thunder-old # Start the new version with the same data volume docker run -d --name thunder-new -v thunder-data:/var/lib/thunderdb \\ ghcr.io/thunderdb/thunderdb:1.3.0 # Verify data is intact psql -h localhost -p 5432 -U admin -d thunderdb -c \" SELECT COUNT(*) FROM upgrade_test; \" # Expected: 10000 Hotfix Process For critical bugs that need to be fixed immediately:\nCreate a release branch from the last release tag:\ngit checkout -b release/1.2.1 v1.2.0 Cherry-pick the fix from main:\ngit cherry-pick \u003ccommit-hash\u003e Update version and changelog on the release branch.\nTag and release following the standard process.\nMerge the release branch back to main to ensure the fix is included:\ngit checkout main git merge release/1.2.1 Release Schedule ThunderDB follows a time-based release cadence:\nRelease Type Frequency Description MAJOR Annually (approximately) Breaking changes, major new features MINOR Quarterly New features, improvements PATCH As needed Bug fixes, security patches The release schedule is approximate. Releases may be delayed if critical bugs are discovered during the release candidate phase, or accelerated for security patches.\nRoles and Responsibilities Role Responsibility Release Manager Coordinates the release process, manages the checklist, creates the tag Build Engineer Builds and verifies release artifacts, manages CI/CD pipeline Documentation Lead Updates documentation, writes release notes QA Lead Runs the full test suite, performs manual verification Security Lead Reviews security-related changes, verifies security fixes The Release Manager role rotates among senior maintainers for each release.\n","categories":"","description":"How ThunderDB versions, builds, packages, and publishes releases -- covering version numbering, release checklists, binary builds, Docker images, Debian packages, changelogs, and post-release verification.","excerpt":"How ThunderDB versions, builds, packages, and publishes releases -- …","ref":"/docs/docs/contributor/release-process/","tags":"","title":"Release Process"},{"body":"Contributor Guide Welcome to the ThunderDB Contributor Guide. ThunderDB is a distributed HTAP (Hybrid Transactional/Analytical Processing) database written in Rust, comprising 14 crates and approximately 75,600 lines of code. This guide provides everything you need to start contributing effectively.\nWhy Contribute to ThunderDB? ThunderDB is building the next generation of distributed databases that unify transactional and analytical workloads under a single system. By contributing, you will:\nWork on cutting-edge distributed systems problems (consensus, distributed transactions, MVCC) Gain deep experience with Rust systems programming at scale Help shape the architecture of a modern HTAP database Join a community passionate about performance, correctness, and reliability Code of Conduct All contributors are expected to adhere to the ThunderDB Code of Conduct. We are committed to providing a welcoming and inclusive experience for everyone. Key principles:\nBe respectful. Treat all community members with dignity and respect, regardless of background or experience level. Be constructive. Provide helpful feedback. Critique ideas, not people. Be collaborative. Work together toward shared goals. Help newcomers get oriented. Be professional. Harassment, discrimination, and toxic behavior will not be tolerated. Violations of the Code of Conduct should be reported to the maintainers at conduct@thunderdb.io. All reports will be reviewed promptly and confidentially.\nTypes of Contributions ThunderDB welcomes contributions in many forms. You do not need to be a database internals expert to make a meaningful impact.\nCode Contributions Code contributions are the most direct way to improve ThunderDB. Areas include:\nBug fixes: Investigate and fix issues reported on the issue tracker. New features: Implement new capabilities such as new SQL functions, storage optimizations, protocol support, or API endpoints. Performance improvements: Profile, benchmark, and optimize hot paths in the query executor, storage engine, or networking layer. Refactoring: Improve code clarity, reduce duplication, and modernize patterns without changing behavior. All code contributions must include appropriate tests and pass the full CI pipeline before merging.\nDocumentation Contributions Good documentation is essential for a database system. Contributions include:\nUser-facing documentation: Tutorials, how-to guides, configuration references, and SQL syntax documentation. Developer documentation: Architecture documents, crate-level documentation, inline code comments, and design decision records. API documentation: Rust doc comments (///), OpenAPI specs for REST endpoints, and protocol documentation. Examples and samples: Working code samples that demonstrate ThunderDB features and integrations. Test Contributions Expanding test coverage improves reliability and catches regressions. Test contributions include:\nUnit tests: Fine-grained tests for individual functions and modules. Integration tests: End-to-end tests that exercise multiple components working together. Property-based tests: Tests using proptest to verify invariants across randomly generated inputs. Chaos tests: Tests that simulate failures (network partitions, disk errors, node crashes) to verify resilience. Benchmarks: Performance benchmarks using criterion to track regressions and validate optimizations. Compliance tests: Tests that verify ACID properties, SQL standard conformance, and wire protocol compatibility. Issue Contributions Even without writing code, you can contribute by improving the issue tracker:\nBug reports: File detailed bug reports with reproduction steps, expected behavior, actual behavior, and environment information. Feature requests: Propose new features with clear use cases and design considerations. Triage: Help categorize, reproduce, and prioritize existing issues. Discussion: Participate in design discussions on RFCs and architectural proposals. Contribution Workflow The standard workflow for contributing to ThunderDB is:\nFind or create an issue. Browse the issue tracker for issues labeled good-first-issue, help-wanted, or up-for-grabs. Alternatively, create a new issue describing what you want to work on.\nFork and clone. Fork the ThunderDB repository to your GitHub account and clone it locally.\nCreate a branch. Create a feature branch from main:\ngit checkout -b feature/your-feature-name Develop. Make your changes, following the Development Setup guide and the coding conventions described in the Codebase Guide.\nTest. Run the full test suite and add new tests for your changes. See the Testing guide for details.\nCommit. Write clear, descriptive commit messages. Use conventional commit format:\nfeat(storage): add prefix compression for B+Tree leaf pages fix(protocol): handle malformed MySQL handshake packets docs(contributor): add codebase architecture diagram test(txn): add property tests for MVCC snapshot isolation Push and open a pull request. Push your branch and open a PR against main. Fill out the PR template completely:\nDescription of the change Related issue(s) Test plan Performance impact (if applicable) Breaking changes (if applicable) Code review. Address review feedback. Maintainers will review for correctness, performance, code style, and test coverage.\nMerge. Once approved and all CI checks pass, a maintainer will merge your PR.\nCoding Conventions ThunderDB follows these coding conventions:\nFormatting: All code must be formatted with cargo fmt using the project .rustfmt.toml configuration. Linting: All code must pass cargo clippy with no warnings. Documentation: All public APIs must have doc comments. Complex internal functions should also be documented. Error handling: Use the project error types defined in thunder-common/src/error.rs. Avoid unwrap() and expect() in production code paths. Naming: Follow Rust naming conventions. Use descriptive names. Abbreviations should be well-known (e.g., txn for transaction, wal for write-ahead log). Unsafe code: Minimize use of unsafe. All unsafe blocks must include a // SAFETY: comment explaining why the invariants are upheld. Dependencies: New dependencies must be discussed in the PR. Prefer well-maintained, widely-used crates. All dependencies must have compatible licenses. Getting Help If you need help at any point:\nGitHub Discussions: Ask questions in the Discussions tab of the repository. Discord: Join the ThunderDB Discord server for real-time help from maintainers and other contributors. Office Hours: Maintainers hold weekly office hours (check the community calendar) for live Q\u0026A and pair programming. What’s Next? Development Setup: Set up your local development environment. Codebase Guide: Understand the architecture and navigate the 14-crate workspace. Testing: Learn the testing strategy and how to write effective tests. Release Process: Understand how ThunderDB versions and releases are managed. ","categories":"","description":"Everything you need to know to contribute to ThunderDB development -- from setting up your environment to understanding the codebase, testing, and release processes.","excerpt":"Everything you need to know to contribute to ThunderDB development -- …","ref":"/docs/docs/contributor/","tags":"","title":"Contributor Guide"},{"body":"Security This guide covers all aspects of securing a ThunderDB deployment, from client authentication and TLS encryption to role-based access control, audit logging, and encryption at rest. Follow these practices to protect your data in production environments.\nAuthentication ThunderDB supports authentication across all wire protocols, using protocol-native mechanisms that maintain compatibility with existing client libraries and tools.\nEnabling Authentication [security] authentication_enabled = true superuser = \"admin\" superuser_password = \"change-me-in-production\" For production, use a hashed password via environment variable instead of plaintext in the configuration file:\nexport THUNDERDB_SUPERUSER_PASSWORD_HASH=\"argon2:\\$argon2id\\$v=19\\$m=65536,t=3,p=4\\$randomsalt\\$hashedpassword\" PostgreSQL Authentication ThunderDB supports PostgreSQL-compatible authentication methods:\nMethod Description Security Level md5 MD5 challenge-response Moderate (legacy compatibility) scram-sha-256 SCRAM-SHA-256 (RFC 5802) High (recommended) Connecting with SCRAM-SHA-256 (default):\npsql \"host=localhost port=5432 user=admin password=mypassword sslmode=require\" Connecting with MD5 (legacy):\n# MD5 is supported for backward compatibility but SCRAM-SHA-256 is preferred. # The client library negotiates the strongest available method automatically. psql \"host=localhost port=5432 user=admin password=mypassword\" MySQL Authentication ThunderDB supports MySQL-compatible authentication plugins:\nPlugin Description Security Level mysql_native_password SHA1-based authentication Moderate (legacy compatibility) caching_sha2_password SHA-256 based authentication High (recommended) Connecting with SHA-256:\nmysql -h localhost -P 3306 -u admin -p --ssl-mode=REQUIRED Connecting with native password (legacy):\nmysql -h localhost -P 3306 -u admin -p --default-auth=mysql_native_password Password Hashing ThunderDB uses Argon2id for internal password storage, which is the current state-of-the-art password hashing algorithm. Argon2id is resistant to both side-channel attacks and GPU-based cracking.\nGenerate a password hash:\nthunderdb --hash-password # Enter password: ******** # Confirm password: ******** # Hash: argon2:$argon2id$v=19$m=65536,t=3,p=4$c2FsdHNhbHRzYWx0$hash... Use the hash in configuration:\n# Via environment variable (recommended) export THUNDERDB_SUPERUSER_PASSWORD_HASH=\"argon2:\\$argon2id\\$v=19\\$m=65536,t=3,p=4\\$c2FsdHNhbHRzYWx0\\$hash...\" # Or via configuration file (less secure, as the hash is stored in a file) # [security] # superuser_password_hash = \"argon2:$argon2id$v=19$m=65536,t=3,p=4$c2FsdHNhbHRzYWx0$hash...\" Argon2id parameters used by ThunderDB:\nParameter Value Description Memory (m) 65536 KB (64 MB) Memory cost Iterations (t) 3 Time cost (number of passes) Parallelism (p) 4 Degree of parallelism Salt length 16 bytes Random salt per password Hash length 32 bytes Output hash length Creating Additional Users After connecting as the superuser, create additional users via SQL:\n-- Create a user with a password CREATE USER app_user WITH PASSWORD 'secure-password-here'; -- Create a read-only user CREATE USER readonly_user WITH PASSWORD 'another-password'; GRANT SELECT ON ALL TABLES IN SCHEMA public TO readonly_user; -- Create an admin user CREATE USER dba_user WITH PASSWORD 'dba-password' SUPERUSER; TLS/SSL Configuration TLS encrypts all traffic between clients and ThunderDB, protecting data in transit. ThunderDB applies TLS uniformly across all wire protocols (PostgreSQL, MySQL, RESP, HTTP, and gRPC).\nGenerating Certificates For production, use certificates signed by a trusted Certificate Authority. For development and testing, generate self-signed certificates:\n# Generate a CA key and certificate openssl genrsa -out ca.key 4096 openssl req -new -x509 -days 3650 -key ca.key -out ca.crt \\ -subj \"/CN=ThunderDB CA/O=ThunderDB/C=US\" # Generate a server key and certificate signing request openssl genrsa -out server.key 2048 openssl req -new -key server.key -out server.csr \\ -subj \"/CN=thunderdb.example.com/O=ThunderDB/C=US\" # Create a SAN (Subject Alternative Name) extension file cat \u003e san.ext \u003c\u003c EOF authorityKeyIdentifier=keyid,issuer basicConstraints=CA:FALSE keyUsage=digitalSignature,nonRepudiation,keyEncipherment,dataEncipherment subjectAltName=@alt_names [alt_names] DNS.1 = thunderdb.example.com DNS.2 = *.thunderdb.example.com DNS.3 = localhost IP.1 = 127.0.0.1 IP.2 = 10.0.1.1 IP.3 = 10.0.1.2 IP.4 = 10.0.1.3 EOF # Sign the server certificate openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key \\ -CAcreateserial -out server.crt -days 365 -extfile san.ext # Set permissions chmod 600 server.key chmod 644 server.crt ca.crt chown thunder:thunder server.key server.crt Enabling TLS [security] tls_enabled = true tls_cert_path = \"/etc/thunderdb/tls/server.crt\" tls_key_path = \"/etc/thunderdb/tls/server.key\" Connecting with TLS PostgreSQL:\npsql \"host=localhost port=5432 user=admin sslmode=verify-full sslrootcert=ca.crt\" sslmode Description disable No TLS (not recommended) require TLS required, no certificate verification verify-ca TLS required, verify server certificate against CA verify-full TLS required, verify certificate and hostname (recommended) MySQL:\nmysql -h localhost -P 3306 -u admin -p \\ --ssl-mode=VERIFY_IDENTITY \\ --ssl-ca=ca.crt RESP (Redis):\nredis-cli -h localhost -p 6379 --tls --cacert ca.crt HTTP:\ncurl --cacert ca.crt https://localhost:8088/admin/health gRPC:\ngrpcurl -cacert ca.crt localhost:9090 thunderdb.v1.ThunderDB/Health Certificate Rotation ThunderDB supports certificate rotation without downtime:\nPlace the new certificate and key files at the configured paths.\nSend a reload signal:\nsudo systemctl reload thunderdb # or curl -X POST http://localhost:8088/admin/reload-tls New connections use the updated certificate. Existing connections continue with the old certificate until they reconnect.\nRole-Based Access Control (RBAC) ThunderDB implements a role-based access control system that controls what operations users can perform on which database objects.\nBuilt-in Roles Role Description SUPERUSER Full access to all operations and objects. Can manage users and roles. ADMIN Can create/drop databases, manage schemas and users (except superusers). READ_WRITE Can SELECT, INSERT, UPDATE, DELETE on granted objects. READ_ONLY Can SELECT on granted objects. Managing Roles -- Create a custom role CREATE ROLE analytics_team; -- Grant permissions to the role GRANT SELECT ON ALL TABLES IN SCHEMA public TO analytics_team; GRANT SELECT ON ALL TABLES IN SCHEMA analytics TO analytics_team; GRANT USAGE ON SCHEMA analytics TO analytics_team; -- Assign the role to a user GRANT analytics_team TO analyst_user; -- Revoke permissions REVOKE INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public FROM analytics_team; -- Drop a role DROP ROLE analytics_team; Object-Level Permissions -- Grant table-level access GRANT SELECT, INSERT ON TABLE orders TO app_user; GRANT SELECT ON TABLE products TO readonly_user; -- Grant schema-level access GRANT ALL PRIVILEGES ON SCHEMA app TO app_user; GRANT USAGE ON SCHEMA app TO readonly_user; -- Grant database-level access GRANT CONNECT ON DATABASE production TO app_user; -- View current grants SELECT * FROM information_schema.role_table_grants WHERE grantee = 'app_user'; Row-Level Security (Future) Row-level security policies are planned for a future release, enabling fine-grained access control at the row level.\nAudit Logging Audit logging records security-relevant events for compliance and forensic analysis.\nEnabling Audit Logging [security] audit_log_enabled = true audit_log_path = \"/var/log/thunderdb/audit.log\" # Events to audit: # \"auth\" - Authentication attempts (success and failure) # \"ddl\" - Data Definition Language (CREATE, ALTER, DROP) # \"dml\" - Data Manipulation Language (INSERT, UPDATE, DELETE) # \"dcl\" - Data Control Language (GRANT, REVOKE) # \"admin\" - Administrative operations (backup, restore, config changes) # \"all\" - All events audit_log_events = [\"auth\", \"ddl\", \"dcl\", \"admin\"] Audit Log Format Audit events are written as JSON lines:\n{\"timestamp\":\"2026-01-15T10:30:45.123Z\",\"event\":\"auth\",\"status\":\"success\",\"user\":\"admin\",\"client\":\"10.0.1.50:54321\",\"protocol\":\"pg\",\"method\":\"scram-sha-256\"} {\"timestamp\":\"2026-01-15T10:30:46.456Z\",\"event\":\"auth\",\"status\":\"failure\",\"user\":\"unknown_user\",\"client\":\"10.0.1.99:12345\",\"protocol\":\"pg\",\"method\":\"scram-sha-256\",\"reason\":\"user not found\"} {\"timestamp\":\"2026-01-15T10:31:15.789Z\",\"event\":\"ddl\",\"user\":\"admin\",\"client\":\"10.0.1.50:54321\",\"protocol\":\"pg\",\"statement\":\"CREATE TABLE orders (id BIGINT PRIMARY KEY, customer_id BIGINT, amount DECIMAL(10,2))\"} {\"timestamp\":\"2026-01-15T10:32:00.012Z\",\"event\":\"dcl\",\"user\":\"admin\",\"client\":\"10.0.1.50:54321\",\"protocol\":\"pg\",\"statement\":\"GRANT SELECT ON orders TO readonly_user\"} {\"timestamp\":\"2026-01-15T10:33:00.345Z\",\"event\":\"admin\",\"user\":\"admin\",\"client\":\"10.0.1.50:54321\",\"protocol\":\"http\",\"action\":\"backup_started\",\"backup_id\":\"bk-20260115-103300\"} Audit Log Fields Field Description timestamp ISO 8601 timestamp of the event. event Event category: auth, ddl, dml, dcl, admin. status success or failure (for auth events). user Username that performed the action. client Client IP address and port. protocol Wire protocol used (pg, mysql, resp, http, grpc). method Authentication method (for auth events). statement SQL statement (for DDL/DML/DCL events). action Administrative action (for admin events). reason Failure reason (for failed events). Audit Log Rotation Configure log rotation to prevent the audit log from consuming excessive disk space:\n# /etc/logrotate.d/thunderdb-audit /var/log/thunderdb/audit.log { daily rotate 90 compress delaycompress missingok notifempty create 0640 thunder thunder } Encryption at Rest ThunderDB supports encrypting data files at rest using AES-256-GCM, protecting data even if physical storage media is compromised.\nEnabling Encryption at Rest [security] encryption_at_rest = true # Encryption key source: # \"file\" - Read the key from a file # \"env\" - Read the key from an environment variable # \"kms\" - Use AWS KMS, GCP KMS, or Azure Key Vault encryption_key_source = \"file\" # Path to the encryption key file (256-bit key, base64 encoded) encryption_key_path = \"/etc/thunderdb/encryption.key\" # For KMS: # encryption_kms_key_id = \"arn:aws:kms:us-east-1:123456789:key/abcd-1234\" Generating an Encryption Key # Generate a 256-bit (32-byte) encryption key openssl rand -base64 32 \u003e /etc/thunderdb/encryption.key chmod 600 /etc/thunderdb/encryption.key chown thunder:thunder /etc/thunderdb/encryption.key How Encryption at Rest Works ThunderDB uses AES-256-GCM (Galois/Counter Mode) for authenticated encryption. Each data page is encrypted with a unique nonce (initialization vector) derived from the page ID and a counter. WAL records are also encrypted before being written to disk. The encryption key is held in memory and never written to unencrypted storage. GCM mode provides both confidentiality and integrity (tamper detection). Key Rotation To rotate encryption keys:\nGenerate a new encryption key.\nRun the key rotation command:\nthunderdb --rotate-encryption-key \\ --old-key /etc/thunderdb/encryption.key.old \\ --new-key /etc/thunderdb/encryption.key This re-encrypts all data pages and WAL segments with the new key in the background without downtime.\nNetwork Security Best Practices Firewall Configuration Restrict access to ThunderDB ports using firewall rules:\n# Allow PostgreSQL from application servers only sudo ufw allow from 10.0.1.0/24 to any port 5432 # Allow MySQL from application servers only sudo ufw allow from 10.0.1.0/24 to any port 3306 # Allow RESP from application servers only sudo ufw allow from 10.0.1.0/24 to any port 6379 # Allow HTTP admin from monitoring network only sudo ufw allow from 10.0.2.0/24 to any port 8088 # Allow gRPC from cluster nodes only sudo ufw allow from 10.0.1.1 to any port 9090 sudo ufw allow from 10.0.1.2 to any port 9090 sudo ufw allow from 10.0.1.3 to any port 9090 # Deny everything else sudo ufw default deny incoming sudo ufw enable Network Segmentation For production environments, segment networks to isolate different types of traffic:\n+-------------------+ +-------------------+ +-------------------+ | Application | | Database | | Management | | Network | | Network | | Network | | 10.0.1.0/24 | | 10.0.2.0/24 | | 10.0.3.0/24 | | | | | | | | App Servers |----\u003e| ThunderDB Nodes |\u003c----| Monitoring | | (PG/MySQL/RESP) | | (inter-node gRPC) | | (HTTP admin) | +-------------------+ +-------------------+ +-------------------+ Kubernetes Network Policies apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: thunderdb-network-policy namespace: thunderdb spec: podSelector: matchLabels: app: thunderdb policyTypes: - Ingress - Egress ingress: # Allow client traffic from application namespace - from: - namespaceSelector: matchLabels: name: application ports: - protocol: TCP port: 5432 - protocol: TCP port: 3306 - protocol: TCP port: 6379 # Allow monitoring traffic - from: - namespaceSelector: matchLabels: name: monitoring ports: - protocol: TCP port: 8088 # Allow inter-node traffic within the cluster - from: - podSelector: matchLabels: app: thunderdb ports: - protocol: TCP port: 9090 egress: # Allow inter-node communication - to: - podSelector: matchLabels: app: thunderdb ports: - protocol: TCP port: 9090 # Allow DNS - to: - namespaceSelector: {} ports: - protocol: UDP port: 53 Superuser Configuration The superuser is the initial administrative account created during ThunderDB setup. It has full access to all operations.\nInitial Setup [security] superuser = \"admin\" superuser_password = \"initial-password\" Production Setup For production, avoid storing the password in the configuration file:\n# 1. Generate a password hash thunderdb --hash-password # Enter password: ******** # Hash: argon2:$argon2id$v=19$m=65536,t=3,p=4$... # 2. Set via environment variable export THUNDERDB_SUPERUSER_PASSWORD_HASH=\"argon2:\\$argon2id\\$v=19\\$m=65536,t=3,p=4\\$...\" # 3. Start ThunderDB thunderdb --config /etc/thunderdb/thunderdb.toml Changing the Superuser Password -- Connect as the current superuser ALTER USER admin WITH PASSWORD 'new-secure-password'; Or regenerate the hash and update the environment variable:\nthunderdb --hash-password # Update THUNDERDB_SUPERUSER_PASSWORD_HASH and restart Security Hardening Checklist Use this checklist to verify your ThunderDB deployment is properly secured:\nAuthentication and Access Control authentication_enabled = true is set in the configuration. The default superuser password has been changed. The superuser password is set via THUNDERDB_SUPERUSER_PASSWORD_HASH environment variable, not in the TOML file. Application users are created with minimal required privileges (principle of least privilege). SCRAM-SHA-256 (PostgreSQL) or caching_sha2_password (MySQL) is used for authentication. Unused protocols have their ports disabled or firewalled. Encryption TLS is enabled (tls_enabled = true) for all client-facing protocols. TLS certificates are signed by a trusted CA (not self-signed in production). TLS certificate expiry is monitored and certificates are rotated before expiry. Encryption at rest is enabled for sensitive data. Encryption keys are stored securely (KMS or encrypted file system). Network Firewall rules restrict access to only required source IPs/networks. The gRPC port (9090) is only accessible from other cluster nodes. The HTTP admin port (8088) is only accessible from the monitoring/management network. Network segmentation separates application, database, and management traffic. In Kubernetes, NetworkPolicy resources are applied. Auditing and Monitoring Audit logging is enabled for authentication, DDL, and DCL events. Audit logs are shipped to a centralized, tamper-resistant log store. Failed authentication attempts trigger alerts. Monitoring is configured for security-relevant metrics. Operational ThunderDB runs as a dedicated non-root user (thunder). The systemd service file includes security hardening directives (NoNewPrivileges, ProtectSystem, etc.). File permissions on data, WAL, and configuration directories are restricted to the thunder user. Configuration files are not world-readable (chmod 640). The ThunderDB binary and dependencies are regularly updated for security patches. Backups are encrypted and access-controlled. A disaster recovery plan is documented and tested. ","categories":"","description":"Secure ThunderDB with authentication, TLS encryption, role-based access control, audit logging, and encryption at rest.","excerpt":"Secure ThunderDB with authentication, TLS encryption, role-based …","ref":"/docs/docs/administrator/security/","tags":"","title":"Security"},{"body":"Troubleshooting This guide helps you diagnose and resolve common issues with ThunderDB. It covers connection problems, performance degradation, storage issues, cluster failures, and emergency procedures.\nDiagnostic Tools Before diving into specific issues, familiarize yourself with the diagnostic tools available.\nDebug Logging Enable verbose logging to gather detailed information about internal operations:\n# Via environment variable (most detailed) RUST_LOG=trace ./thunderdb --config /etc/thunderdb/thunderdb.toml # For specific subsystems only RUST_LOG=thunderdb::storage=debug,thunderdb::cluster=trace ./thunderdb --config /etc/thunderdb/thunderdb.toml # Via runtime API (does not require restart) curl -X PUT http://localhost:8088/admin/config/log_level -d '{\"level\": \"debug\"}' Useful Log Targets Target Description thunderdb::server Server startup, shutdown, and connection handling. thunderdb::query Query parsing, planning, and execution. thunderdb::storage Buffer pool, page I/O, compaction. thunderdb::wal Write-ahead log operations. thunderdb::cluster Raft consensus, region management, replication. thunderdb::txn Transaction management, MVCC, locking. thunderdb::protocol::pg PostgreSQL wire protocol handling. thunderdb::protocol::mysql MySQL wire protocol handling. thunderdb::protocol::resp RESP (Redis) wire protocol handling. thunderdb::security Authentication, authorization, TLS. Health and Status Endpoints # Overall health curl http://localhost:8088/admin/health # Readiness status curl http://localhost:8088/admin/ready # Cluster membership curl http://localhost:8088/admin/cluster/members # Raft status curl http://localhost:8088/admin/cluster/raft # Region distribution curl http://localhost:8088/admin/cluster/regions # Active connections curl http://localhost:8088/admin/connections # Current queries curl http://localhost:8088/admin/queries # Storage statistics curl http://localhost:8088/admin/storage/stats # WAL status curl http://localhost:8088/admin/wal/status Common Issues and Solutions ThunderDB Fails to Start Symptom: ThunderDB exits immediately after startup with an error.\nCheck the logs:\njournalctl -u thunderdb --no-pager -n 50 # or RUST_LOG=debug ./thunderdb --config /etc/thunderdb/thunderdb.toml 2\u003e\u00261 | head -100 Common causes:\nError Message Cause Solution Address already in use Another process is using a required port. Check ss -tlnp | grep \u003cport\u003e and stop the conflicting process or change the port. Permission denied: /var/lib/thunderdb/data ThunderDB does not have write access to the data directory. Fix ownership: chown -R thunder:thunder /var/lib/thunderdb. Invalid configuration Syntax error or invalid value in thunderdb.toml. Validate the TOML file and check against the configuration reference. Failed to open WAL WAL directory is missing or corrupted. Verify the directory exists and has correct permissions. If corrupted, see WAL corruption recovery. Cannot bind to address The listen_addr is not available on this host. Use 0.0.0.0 or a valid IP address assigned to the host. Incompatible page size page_size differs from the existing data files. Use the same page_size as when the data was created. ThunderDB Starts but Clients Cannot Connect Symptom: ThunderDB is running but clients receive connection refused or timeout errors.\nDiagnostic steps:\n# 1. Verify ThunderDB is listening on the expected ports ss -tlnp | grep thunderdb # 2. Check if the node is ready curl http://localhost:8088/admin/ready # 3. Test local connectivity psql -h 127.0.0.1 -p 5432 -U admin # 4. Test remote connectivity psql -h \u003cthunderdb-ip\u003e -p 5432 -U admin # 5. Check firewall rules sudo ufw status sudo iptables -L -n Connection Problems by Protocol PostgreSQL Connection Issues “Connection refused”:\n# Verify pg_port is configured and ThunderDB is listening curl http://localhost:8088/admin/health ss -tln | grep 5432 “Authentication failed”:\n# Verify the user exists and password is correct # Check audit log for details tail -20 /var/log/thunderdb/audit.log | grep auth # Verify authentication is configured correctly grep authentication_enabled /etc/thunderdb/thunderdb.toml “SSL required” or TLS handshake errors:\n# If TLS is enabled, clients must use SSL psql \"host=localhost port=5432 user=admin sslmode=require\" # Verify certificate paths are correct openssl x509 -in /etc/thunderdb/tls/server.crt -noout -dates Connection timeout:\n# Check network path traceroute \u003cthunderdb-host\u003e # Check for connection limits curl http://localhost:8088/admin/connections | python3 -m json.tool MySQL Connection Issues “Access denied for user”:\n# Verify credentials mysql -h localhost -P 3306 -u admin -p # Check if the MySQL protocol handler is running curl http://localhost:8088/admin/health | python3 -m json.tool “Plugin caching_sha2_password could not be loaded”:\nThis indicates the client is too old to support SHA-256 authentication. Either upgrade the client or connect using the legacy plugin:\nmysql -h localhost -P 3306 -u admin -p --default-auth=mysql_native_password RESP (Redis) Connection Issues “NOAUTH Authentication required”:\n# Authenticate after connecting redis-cli -h localhost -p 6379 \u003e AUTH admin mypassword “Connection reset by peer”:\n# Check if TLS is required redis-cli -h localhost -p 6379 --tls --cacert ca.crt HTTP API Connection Issues “Connection refused” on port 8088:\n# This is the admin/API port; verify it is enabled grep http_port /etc/thunderdb/thunderdb.toml ss -tln | grep 8088 gRPC Connection Issues “Unavailable” or “Transport closing”:\n# Verify gRPC port is accessible grpcurl -plaintext localhost:9090 list # If TLS is enabled grpcurl -cacert ca.crt localhost:9090 list Performance Degradation Slow Queries Symptoms: Increasing query latency, slow query log entries, user complaints about response times.\nDiagnostic steps:\n# 1. Check current slow queries curl http://localhost:8088/admin/queries # 2. Review slow query log grep \"Slow query\" /var/log/thunderdb/thunderdb.log | tail -20 # 3. Check buffer pool hit rate curl -s http://localhost:8088/admin/metrics | grep buffer_pool_hit_ratio # Target: \u003e 0.95. If lower, buffer pool is too small. # 4. Check for lock contention curl http://localhost:8088/admin/locks # 5. Check compaction backlog curl -s http://localhost:8088/admin/metrics | grep compaction_pending Solutions:\nCause Metric Indicator Solution Buffer pool too small buffer_pool_hit_ratio \u003c 0.90 Increase buffer_pool_size. Missing indexes High rows_examined in slow queries Create appropriate indexes. Lock contention High lock wait times Optimize transaction scope, reduce transaction size. Compaction backlog compaction_pending \u003e 50 Increase compaction_threads. Large result sets High rows_returned Add LIMIT clauses, use pagination. Full table scans Sequential scan on large tables Create indexes, rewrite queries. High CPU Usage # 1. Check active queries for expensive operations curl http://localhost:8088/admin/queries # 2. Check compaction thread activity curl -s http://localhost:8088/admin/metrics | grep compaction # 3. Profile the process (requires perf tools) sudo perf top -p $(pgrep thunderdb) Solutions:\nKill expensive queries: curl -X POST http://localhost:8088/admin/queries/\u003cquery_id\u003e/cancel Reduce compaction_threads if compaction is consuming too much CPU. Check for runaway analytics queries consuming excessive CPU. High Memory Usage # 1. Check memory breakdown curl http://localhost:8088/admin/storage/stats # 2. Check buffer pool usage curl -s http://localhost:8088/admin/metrics | grep memory_usage # 3. Check OS-level memory free -h cat /proc/$(pgrep thunderdb)/status | grep VmRSS Solutions:\nReduce buffer_pool_size if the system is under memory pressure. Reduce wal_buffer_size. Check for memory leaks by monitoring memory growth over time. WAL Corruption Recovery WAL corruption is rare but can occur due to hardware failures, abrupt power loss, or disk errors.\nDetecting WAL Corruption Symptoms:\nThunderDB fails to start with WAL-related errors. Recovery phase reports checksum mismatches. Log messages like WAL segment corrupted or Invalid WAL record at LSN. Check WAL integrity:\nthunderdb --verify-wal --config /etc/thunderdb/thunderdb.toml Recovery from WAL Corruption Option 1: Skip corrupted WAL records (potential data loss):\n# WARNING: This may result in loss of recent transactions. thunderdb --recover-wal --skip-corrupted --config /etc/thunderdb/thunderdb.toml This skips corrupted WAL records during recovery. Transactions that depended on corrupted records may be lost.\nOption 2: Restore from backup:\nIf data integrity is critical, restore from the most recent backup and replay WAL archives up to the point of corruption:\n# 1. Stop ThunderDB sudo systemctl stop thunderdb # 2. Restore from backup thunderdb --restore-pitr \"2026-01-15T10:00:00Z\" \\ --restore-backup /backups/thunderdb/full-2026-01-15 # 3. Start ThunderDB sudo systemctl start thunderdb Option 3: Re-replicate from cluster peers:\nIf the node is part of a healthy cluster, remove its data and let it re-replicate:\n# 1. Stop the node sudo systemctl stop thunderdb # 2. Remove data and WAL directories sudo rm -rf /var/lib/thunderdb/data/* sudo rm -rf /var/lib/thunderdb/wal/* # 3. Start the node -- it will rejoin the cluster and re-replicate sudo systemctl start thunderdb Cluster Split-Brain Handling A split-brain occurs when network partitions cause cluster nodes to diverge, potentially electing multiple leaders.\nDetecting Split-Brain Symptoms:\nMultiple nodes report themselves as leaders. Clients connected to different nodes see different data. Raft term increases rapidly (frequent elections). # Check Raft status on each node for node in 10.0.1.1 10.0.1.2 10.0.1.3; do echo \"--- Node: $node ---\" curl -s http://$node:8088/admin/cluster/raft | python3 -m json.tool done Prevention ThunderDB’s Raft implementation prevents split-brain through quorum-based consensus:\nA leader must have support from a majority of nodes (quorum). In a 3-node cluster, a leader needs 2 votes (tolerates 1 failure). In a 5-node cluster, a leader needs 3 votes (tolerates 2 failures). Best practices:\nAlways use an odd number of nodes (3, 5, 7). Ensure reliable network connectivity between all nodes. Set appropriate raft_election_timeout (increase for unreliable networks). Monitor Raft term changes to detect election storms. Resolution If a split-brain does occur (e.g., due to a symmetric network partition):\nIdentify the partition: Determine which nodes can communicate with which.\nResolve the network issue: Restore connectivity between all nodes.\nThe Raft protocol will self-heal: Once connectivity is restored, nodes will converge on a single leader with the highest term and most up-to-date log.\nVerify data consistency:\ncurl http://localhost:8088/admin/cluster/consistency-check If data inconsistency is detected: The minority partition’s writes (if any were accepted without quorum) are automatically rolled back when the partition heals.\nMemory Pressure and OOM Detecting Memory Pressure # Check if OOM killer was invoked dmesg | grep -i \"out of memory\" journalctl -k | grep -i oom # Check ThunderDB memory usage curl -s http://localhost:8088/admin/metrics | grep memory_usage # Check system memory free -h vmstat 1 5 Preventing OOM Size the buffer pool appropriately: Do not set buffer_pool_size to more than 70% of total system RAM.\nSet memory limits:\nFor systemd:\n[Service] MemoryMax=12G MemoryHigh=10G For Kubernetes:\nresources: limits: memory: 12Gi requests: memory: 8Gi Monitor memory trends: Set up alerting for memory usage above 80%.\nDisable swap to avoid performance degradation:\nsudo swapoff -a Recovery from OOM If ThunderDB is killed by the OOM killer:\n# 1. Check if the process was OOM-killed dmesg | tail -20 # 2. Restart ThunderDB (ARIES recovery will handle crash recovery) sudo systemctl start thunderdb # 3. Monitor recovery progress journalctl -u thunderdb -f # 4. After recovery, reduce memory configuration to prevent recurrence # Edit /etc/thunderdb/thunderdb.toml: reduce buffer_pool_size sudo systemctl restart thunderdb Disk Space Management Monitoring Disk Usage # ThunderDB disk usage breakdown curl http://localhost:8088/admin/storage/stats # System-level disk usage df -h /var/lib/thunderdb/data df -h /var/lib/thunderdb/wal du -sh /var/lib/thunderdb/data/* du -sh /var/lib/thunderdb/wal/* Reclaiming Disk Space Force a checkpoint and compact:\n# Force a checkpoint to flush dirty pages and allow WAL truncation curl -X POST http://localhost:8088/admin/checkpoint # Trigger manual compaction curl -X POST http://localhost:8088/admin/storage/compact Clean up WAL archives:\n# Remove old WAL archive files beyond retention find /backups/thunderdb/wal-archive -mtime +7 -delete Drop unused tables or databases:\nDROP TABLE IF EXISTS old_data_table; DROP DATABASE IF EXISTS staging; Emergency: Disk Full If the disk is completely full, ThunderDB will stop accepting writes to prevent data corruption.\n# 1. Free space immediately by removing old WAL archive files or temp files sudo rm -f /var/lib/thunderdb/wal/*.tmp sudo rm -rf /tmp/thunderdb-* # 2. If WAL directory is full, force a checkpoint to allow WAL truncation # (This requires enough space for the checkpoint itself) curl -X POST http://localhost:8088/admin/checkpoint # 3. Add more disk space (expand volume, attach additional disk) # Then restart if ThunderDB entered read-only mode: sudo systemctl restart thunderdb Log Analysis Guide Finding Errors # Search for errors in the last hour journalctl -u thunderdb --since \"1 hour ago\" -p err # Search for specific error patterns journalctl -u thunderdb | grep -i \"panic\\|error\\|fatal\" # For JSON-formatted logs, use jq journalctl -u thunderdb --output=cat | jq 'select(.level == \"error\")' Analyzing Slow Queries # Extract slow query entries journalctl -u thunderdb --output=cat | jq 'select(.target == \"thunderdb::query::slow\")' # Get the top 10 slowest queries journalctl -u thunderdb --output=cat | \\ jq 'select(.target == \"thunderdb::query::slow\") | {duration_ms, query}' | \\ jq -s 'sort_by(.duration_ms) | reverse | .[:10]' Tracking Connection Events # Connection events journalctl -u thunderdb --output=cat | jq 'select(.message | test(\"connection|disconnect\"))' # Authentication failures journalctl -u thunderdb --output=cat | jq 'select(.event == \"auth\" and .status == \"failure\")' Cluster Event Timeline # Raft elections and leader changes journalctl -u thunderdb --output=cat | jq 'select(.target == \"thunderdb::cluster\" and (.message | test(\"election|leader\")))' # Region splits and merges journalctl -u thunderdb --output=cat | jq 'select(.message | test(\"region.*split|region.*merge\"))' Emergency Procedures The following procedures are derived from the operational runbook (deploy/runbook.md).\nEmergency: Node Unresponsive # 1. Check if the process is running pgrep -f thunderdb # 2. Check for resource exhaustion top -p $(pgrep thunderdb) free -h df -h # 3. If the process is stuck (not responding to signals) sudo kill -SIGQUIT $(pgrep thunderdb) # Generates a thread dump in logs sleep 5 # 4. Force kill if necessary sudo kill -9 $(pgrep thunderdb) # 5. Restart sudo systemctl start thunderdb # 6. Monitor recovery journalctl -u thunderdb -f Emergency: Cluster Lost Quorum If the cluster has lost quorum (majority of nodes are down), it cannot accept writes.\n# 1. Determine cluster state for node in 10.0.1.1 10.0.1.2 10.0.1.3; do echo \"--- $node ---\" curl -s --connect-timeout 2 http://$node:8088/admin/health || echo \"UNREACHABLE\" done # 2. Restore failed nodes as quickly as possible # On each failed node: sudo systemctl start thunderdb # 3. If nodes cannot be restored, and you need emergency write access, # force a single-node cluster (DANGER: data loss possible) thunderdb --force-new-cluster --config /etc/thunderdb/thunderdb.toml # 4. After quorum is restored, verify data consistency curl http://localhost:8088/admin/cluster/consistency-check Emergency: Data Corruption Detected # 1. Stop writes immediately curl -X POST http://localhost:8088/admin/read-only # 2. Run integrity check thunderdb --verify-data --config /etc/thunderdb/thunderdb.toml # 3. If corruption is limited: # - Identify affected pages from the verification output # - If the node is in a cluster, the affected regions will be re-replicated from healthy replicas # 4. If corruption is widespread: # - Stop ThunderDB sudo systemctl stop thunderdb # - Restore from backup thunderdb --restore-pitr \"latest\" --restore-backup /backups/thunderdb/full-latest # - Start ThunderDB sudo systemctl start thunderdb # 5. Investigate root cause (disk errors, firmware bugs, etc.) sudo smartctl -a /dev/sda dmesg | grep -i \"error\\|i/o\\|sector\" Emergency: Security Breach Suspected # 1. Review audit logs for suspicious activity tail -1000 /var/log/thunderdb/audit.log | \\ jq 'select(.event == \"auth\" and .status == \"failure\")' # 2. Check for unauthorized users psql -h localhost -U admin -c \"SELECT * FROM pg_catalog.pg_user;\" # 3. Rotate all passwords thunderdb --hash-password # Generate new hash for superuser # Update THUNDERDB_SUPERUSER_PASSWORD_HASH # 4. Rotate TLS certificates # Generate new certificates and reload: sudo systemctl reload thunderdb # 5. Rotate encryption keys (if encryption at rest is enabled) thunderdb --rotate-encryption-key \\ --old-key /etc/thunderdb/encryption.key.old \\ --new-key /etc/thunderdb/encryption.key # 6. Review and restrict network access sudo ufw status # Tighten firewall rules as needed Frequently Asked Troubleshooting Questions How do I check the ThunderDB version? thunderdb --version How do I check cluster membership from any node? curl http://localhost:8088/admin/cluster/members How do I see active queries? curl http://localhost:8088/admin/queries How do I kill a long-running query? curl -X POST http://localhost:8088/admin/queries/\u003cquery_id\u003e/cancel How do I check why a specific query is slow? -- Via PostgreSQL protocol EXPLAIN ANALYZE SELECT * FROM orders WHERE customer_id = 42; How do I check replication lag? curl -s http://localhost:8088/admin/metrics | grep replication_lag How do I drain a node for maintenance? # 1. Mark the node as draining (stops accepting new region replicas) curl -X POST http://localhost:8088/admin/drain # 2. Wait for existing regions to migrate to other nodes curl http://localhost:8088/admin/drain/status # 3. Once drained, stop for maintenance sudo systemctl stop thunderdb # 4. After maintenance, rejoin the cluster sudo systemctl start thunderdb How do I recover from a failed configuration change? # ThunderDB keeps a backup of the last working configuration cp /etc/thunderdb/thunderdb.toml.bak /etc/thunderdb/thunderdb.toml sudo systemctl restart thunderdb Where do I get help? Documentation: https://thunderdb.io/docs\nGitHub Issues: https://github.com/thunderdb/thunderdb/issues\nCommunity Discord: https://discord.gg/thunderdb\nDebug bundle: Generate a diagnostic bundle for support:\nthunderdb --diagnostic-bundle --output /tmp/thunderdb-diag.tar.gz This collects logs, metrics, configuration (with secrets redacted), and system information.\n","categories":"","description":"Diagnose and resolve common issues with ThunderDB including connection problems, performance degradation, WAL corruption, and cluster failures.","excerpt":"Diagnose and resolve common issues with ThunderDB including connection …","ref":"/docs/docs/administrator/troubleshooting/","tags":"","title":"Troubleshooting"},{"body":"What Is ThunderDB? ThunderDB is a production-grade distributed HTAP (Hybrid Transactional/Analytical Processing) database written entirely in Rust. It combines transactional workloads (OLTP), analytical workloads (OLAP), and AI-native vector search into a single, unified system.\nThunderDB natively speaks PostgreSQL, MySQL, and Redis wire protocols, meaning your existing applications, drivers, ORMs, and tools connect without any code changes. It also exposes REST, gRPC, GraphQL, and WebSocket APIs for modern application architectures.\nRather than demanding a full migration, ThunderDB is designed to be deployed alongside your existing databases using Change Data Capture (CDC) and Foreign Data Wrappers (FDW), allowing you to adopt it incrementally and migrate workloads at your own pace.\nVision: Universal Database Companion for the AI Era The database landscape is undergoing a fundamental shift. Applications increasingly require:\nTransactional consistency for user-facing operations Analytical power for dashboards, reporting, and business intelligence Vector search for AI/ML embeddings, RAG pipelines, and semantic retrieval Multi-protocol access because teams use diverse tools and languages Real-time data federation across multiple data sources Today, teams cobble together PostgreSQL for transactions, ClickHouse or BigQuery for analytics, Pinecone or Milvus for vectors, Redis for caching, and a constellation of ETL pipelines to keep everything in sync. This fragmentation creates operational complexity, data inconsistency, increased latency, and skyrocketing infrastructure costs.\nThunderDB’s vision is to eliminate this fragmentation. A single system that handles transactional queries, analytical scans, and vector similarity search – with native protocol compatibility so you never have to rewrite your application.\nWe call this the Universal Database Companion philosophy: ThunderDB slots into your existing infrastructure, speaks the protocols your applications already use, and progressively absorbs workloads that currently require separate specialized systems.\nWhy ThunderDB Exists The Problem: Fragmented Data Infrastructure Modern data architectures suffer from several compounding problems:\nDatabase Sprawl. A typical organization runs 5-10 different database systems. Each requires its own operational expertise, monitoring, backup procedures, and security hardening.\nData Synchronization Nightmares. Moving data between OLTP and OLAP systems involves complex ETL/ELT pipelines that introduce latency (minutes to hours), create consistency gaps, and break silently.\nThe AI/ML Gap. Vector databases are yet another system to deploy and synchronize. Keeping embeddings in sync with source-of-truth data is a significant engineering burden.\nProtocol Lock-In. Switching from PostgreSQL to a new database means rewriting every application, ORM configuration, and database tool integration.\nOperational Overhead. Each database system has different scaling mechanisms, failure modes, upgrade procedures, and monitoring approaches.\nThe Solution: One Engine, Multiple Protocols, Zero Migration ThunderDB solves these problems by:\nUnifying OLTP + OLAP + Vector in a single storage and query engine, eliminating ETL pipelines and synchronization complexity. Speaking existing protocols (PostgreSQL, MySQL, Redis) so applications connect without code changes. Supporting incremental adoption through CDC and FDW – start with one workload, expand over time. Being written in Rust for memory safety, predictable performance, and zero-cost abstractions that deliver C/C++ speed without the footguns. Key Differentiators ThunderDB vs CockroachDB Dimension ThunderDB CockroachDB Processing model True HTAP (row + columnar + vector) OLTP-focused with limited analytics Wire protocols PostgreSQL, MySQL, Redis PostgreSQL only Vector search Native HNSW + IVF indexes Not supported natively CDC / FDW Built-in CDC consumer and FDW Limited CDC; no built-in FDW Language Rust Go API surface SQL + REST + gRPC + GraphQL + WebSocket SQL + REST (limited) License Apache 2.0 / BSL 1.1 BSL 1.1 (converts to Apache) Key-value access Native Redis/RESP protocol Not available CockroachDB is an excellent distributed SQL database for OLTP workloads. ThunderDB differentiates by offering true HTAP processing with columnar storage and vectorized execution, native vector search for AI/ML workloads, and multi-protocol support that avoids PostgreSQL lock-in.\nThunderDB vs TiDB Dimension ThunderDB TiDB Processing model Unified row + columnar + vector Separate TiKV (row) + TiFlash (columnar) Wire protocols PostgreSQL, MySQL, Redis MySQL only Vector search Native HNSW + IVF indexes Not supported Architecture Single binary, integrated engine Multiple components (TiDB, TiKV, PD, TiFlash) Language Rust Go (TiDB) + Rust (TiKV) + C++ (TiFlash) Deployment complexity Single binary or simple Docker Requires orchestrating 4+ components CDC / FDW Built-in bidirectional TiCDC (outbound only) TiDB pioneered the HTAP model with its TiKV + TiFlash architecture. ThunderDB builds on this concept but simplifies deployment by integrating row storage, columnar storage, and vector indexing into a single engine. ThunderDB also supports multiple wire protocols and has a significantly simpler operational footprint.\nThunderDB vs YugabyteDB Dimension ThunderDB YugabyteDB Processing model True HTAP (row + columnar + vector) OLTP-focused (row store) Wire protocols PostgreSQL, MySQL, Redis PostgreSQL, YCQL (Cassandra-like) Vector search Native HNSW + IVF indexes Via pgvector extension Analytical queries Native columnar store + vectorized execution Limited; relies on PostgreSQL executor Language Rust C / C++ CDC / FDW Built-in CDC consumer + FDW CDC via Debezium; PostgreSQL FDW Memory safety Rust ownership model Manual C/C++ memory management YugabyteDB provides strong PostgreSQL compatibility and a Cassandra-compatible API. ThunderDB differentiates with its integrated HTAP engine (columnar + row + vector), native MySQL and Redis protocol support, and the memory safety guarantees that come from being written entirely in Rust.\nRoadmap ThunderDB follows a 42-month development roadmap divided into seven phases. Each phase builds upon the previous one, progressively expanding capabilities while maintaining production stability.\nPhase 1: Foundation (Months 1-6) Goal: Core single-node database engine with basic SQL support.\nRust-based storage engine with B-tree and LSM-tree hybrid SQL parser and query planner (PostgreSQL-compatible subset) PostgreSQL wire protocol implementation Basic data types: integers, floats, strings, booleans, timestamps ACID transactions with MVCC (Multi-Version Concurrency Control) Write-ahead log (WAL) for crash recovery Basic configuration system (TOML-based) Unit and integration test framework CI/CD pipeline and release automation Phase 2: Multi-Protocol and API Layer (Months 7-12) Goal: Expand protocol support and build the API surface.\nMySQL wire protocol implementation Redis/RESP protocol for key-value operations REST API with OpenAPI specification gRPC API with Protocol Buffers definitions Connection pooling and session management Authentication (password, SCRAM-SHA-256) TLS/SSL for all protocols Basic role-based access control (RBAC) Query result caching layer Prepared statements and parameterized queries Phase 3: Distributed Engine (Months 13-18) Goal: Scale beyond a single node with distributed consensus.\nRaft consensus protocol implementation Automatic sharding with consistent hashing Distributed transactions with two-phase commit (2PC) Multi-node cluster formation and discovery Leader election and failover Distributed query routing and execution Cross-shard query coordination Node membership management (add/remove nodes) Rebalancing and data migration Cluster-aware connection routing Phase 4: HTAP Engine (Months 19-24) Goal: True HTAP with columnar storage and vectorized execution.\nColumnar storage engine (Apache Arrow-based) Vectorized query execution engine Automatic workload classification (OLTP vs OLAP) Row-to-columnar data transformation pipeline Hybrid query optimizer (cost-based) Parallel query execution Window functions and advanced aggregations Materialized views with incremental refresh Query result streaming Resource isolation between OLTP and OLAP workloads Phase 5: AI-Native Features (Months 25-30) Goal: Native vector search and AI/ML integration.\nVECTOR data type with configurable dimensions HNSW (Hierarchical Navigable Small World) index IVF (Inverted File) index for billion-scale datasets Cosine, Euclidean, and inner-product distance functions Hybrid search (vector + metadata filtering) Built-in embedding generation via ONNX Runtime RAG (Retrieval-Augmented Generation) pipeline helpers Full-text search with BM25 scoring GraphQL API with subscription support WebSocket API for real-time streaming Phase 6: Data Integration (Months 31-36) Goal: Seamless integration with the broader data ecosystem.\nChange Data Capture (CDC) consumer for PostgreSQL CDC consumer for MySQL (binlog) CDC consumer for MongoDB (change streams) Foreign Data Wrappers (FDW) for PostgreSQL, MySQL, SQLite FDW for S3 / Parquet / CSV / JSON files FDW for REST APIs (generic HTTP wrapper) Outbound CDC (ThunderDB as source) Kafka Connect integration Apache Spark connector dbt adapter Phase 7: Enterprise and Ecosystem (Months 37-42) Goal: Enterprise-grade features and ecosystem maturity.\nMulti-region replication with conflict resolution Encryption at rest (AES-256) Comprehensive audit logging Fine-grained access control (column-level, row-level) Online schema changes (non-blocking DDL) Point-in-time recovery (PITR) Automated backup to S3 / GCS / Azure Blob Web-based management console (ThunderDB Studio) Kubernetes Operator for declarative cluster management Terraform and Pulumi providers Grafana and Datadog integration packages Comprehensive benchmarking suite (TPC-C, TPC-H, ANN-Benchmarks) Team and Community ThunderDB is built by a team of database engineers, systems programmers, and distributed systems researchers passionate about solving the data fragmentation problem.\nContributing ThunderDB is an open-source project and welcomes contributions of all kinds:\nCode contributions – Bug fixes, features, performance improvements Documentation – Guides, tutorials, API docs, translations Testing – Bug reports, test cases, benchmarks Community – Answering questions, writing blog posts, giving talks See the Contributor Guide for instructions on setting up your development environment, understanding the codebase, and submitting pull requests.\nCommunity Channels Channel Link GitHub Discussions github.com/thunderdb/thunderdb/discussions Discord discord.gg/thunderdb Twitter / X @thunderabordb Monthly Community Call Second Thursday of each month, 10:00 AM PT Blog thunderdb.io/blog Code of Conduct ThunderDB follows the Contributor Covenant Code of Conduct. We are committed to providing a welcoming, inclusive, and harassment-free environment for everyone.\nLicense ThunderDB is dual-licensed:\nApache License 2.0 – For the core database engine, client libraries, and developer tools. This allows unrestricted use, modification, and distribution in both open-source and commercial projects.\nBusiness Source License 1.1 (BSL 1.1) – For certain enterprise features (multi-region replication, advanced audit logging, management console). The BSL automatically converts to Apache 2.0 after 36 months, ensuring all code eventually becomes fully open source.\nThe client libraries (SDKs for Python, Go, Java, Node.js, Rust) and the CLI tools are always Apache 2.0 licensed.\nCopyright 2024-2026 ThunderDB Contributors Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. ","categories":"","description":"Learn about ThunderDB's vision, roadmap, and the team behind it.\n","excerpt":"Learn about ThunderDB's vision, roadmap, and the team behind it.\n","ref":"/docs/about/","tags":"","title":"About ThunderDB"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/tags/","tags":"","title":"Tags"},{"body":" ThunderDB Get Started GitHub The Distributed HTAP Database for the AI Era\nThunderDB is a production-grade distributed HTAP database written in Rust that unifies transactional processing, analytical queries, and vector search in a single system. Deploy alongside your existing PostgreSQL, MySQL, MongoDB, or Redis — no rip-and-replace required.\nBlazing Fast HTAP Combine OLTP and OLAP workloads in a single engine with row store, columnar store, and vectorized execution — powered by Rust’s zero-cost abstractions.\nMulti-Protocol Connect using PostgreSQL, MySQL, or Redis wire protocols. Use REST, gRPC, GraphQL, or WebSocket APIs. Your existing tools and drivers just work.\nAI-Native Vector Search Built-in HNSW and IVF vector indexes for semantic search, RAG pipelines, and AI/ML embedding storage with native SQL integration.\nZero-Downtime Adoption Deploy as a companion to existing databases using Change Data Capture (CDC) and Foreign Data Wrappers (FDW). Migrate gradually without disruption.\nDistributed by Design Raft consensus, automatic sharding, multi-region replication, and distributed transactions with two-phase commit — scale horizontally with confidence.\nEnterprise Security TLS encryption, SCRAM-SHA-256 authentication, role-based access control, audit logging, and encryption at rest for production deployments.\n","categories":"","description":"","excerpt":" ThunderDB Get Started GitHub The Distributed HTAP Database for the AI …","ref":"/docs/","tags":"","title":"ThunderDB Documentation"}]